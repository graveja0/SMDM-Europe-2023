[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "What They Didn’t Teach You About Decision Modeling",
    "section": "",
    "text": "This workshop will reinforce and expand advanced techniques not frequently taught in decision modeling courses. The course content centers around an applied exercise whereby a modeler seeks to back-convert an existing discrete-time Markov model, add additional health states and parameters (with uncertainty distributions), and adapt background mortality based on modeled life-table data from a different country, population, or setting. We will demonstrate how the augmented discrete time Markov model can be structured to accurately capture competing events and event dynamics that reflect the underlying continuous-time disease process. The course content will utilize the R programming language, though we will also provide Excel templates for some exercises.\nCourse Description and Objectives (max 300 words) (Provide a brief course description and state in bulleted format the objectives of the course.\nThis workshop will focus on important-but-infrequently-taught advanced skills and methods to facilitate the timely and efficient construction, execution, and adaptation of Markov models for health technology assessment and health policy decision-making. We will focus on discrete-time Markov models, though much of the course content applies to other modeling types as well. All course content will be taught in the R statistical programming language, though we will provide additional optional material for how the methods could be adapted to an Excel-based model.\nThe workshop will center around an applied exercise with the following objectives:\n\nBack-convert an existing discrete time Markov model to accommodate the inclusion of additional health states and literature-based parameters.\nAdapt background mortality based on modeled life-table data from a different country, population, or setting.\nInclusion of event accumulators in the embedded transition probability matrix to accurately capture competing events and event dynamics that reflect the underlying continuous-time process.\nMatch probabilistic sensitivity analysis (PSA) uncertainty distribution parameters for the augmented model (e.g., parameters governing a normal, lognormal, beta, gamma, etc. distribution) to match values and quantiles ascertained through expert opinion surveys, prior research, etc.\n\nTo execute the above objectives, the workshop will provide didactic content, case-studies, and web-based (Shiny) tools for the following topics and methods:\nA. Back-converting a discrete-time Markov model into an underlying generator rate matrix using eigenvalue decomposition.\nB. Augmenting an underlying rate matrix with new parameters and health states.\nC. Including accumulators within an embedded transition probability matrix to accurately account for “jumpover” states that occur when a continuous time process is captured in a discrete-time model.\nD. Fitting and characterizing background mortality using a Gompertz model fit to life-table data.\nE. Algorithms to solve for uncertainty distribution parameters that match values and quantiles ascertained through expert opinions, prior research, etc.\nF. Capturing correlation among uncertain model parameters using PSA sampling via copulas.\nCourse Background: In 150 words or less, please provide a brief background on the skills taught in this course and how they are used.\nParticipants should have some experience designing and executing discrete-time Markov models. This workshop will build and extend upon these skills so that participants can efficiently adapt expand existing models to (a) include new health states and/or parameters (with associated uncertainty distributions); (b) convert the model to match population characteristics in alternative countries, settings, or contexts; (c) properly structure discrete-time models so that the transition probabilities and modeled outcomes accurately reflect an underlying continuous-time process.\nFormat and Requirements: In 150 words or less, describe the format of the class and include any prerequisites for participation, especially for intermediate and advanced level courses.\nParticipants should have some experience designing and executing discrete-time Markov models, including experience (a) converting rates to probabilities; (b) constructing a Markov trace from an underlying transition probability matrix; (c) structuring and executing a probabilistic sensitivity analysis (PSA). As the course content will be taught almost exclusively in R, prior experience with Markov models, microsimulation, or discrete event simulation in R is strongly encouraged.\nAM:\nStucturing the Markov model (from Bangkok and blend in content from blog posting)\nGroup Exercise (from Bangkok)\nIndivdiual/Small Group Case study (from appendix) — incorporate new evidence.\nPM:\n\nAdapting background mortality\nIndividual / Small Group Case Study (adapt background mortality)\nSolving for uncertainty distributions (put PSA distribution around new parameters in earlier case study)\nCorrelated PSA distributions via copula sampling"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "roster.html",
    "href": "roster.html",
    "title": "Instructors, Facilitators and Participants",
    "section": "",
    "text": "Instructors\n\nShawn Garbett (Vanderbilt University Medical Center)\n\n\n\n\n\nShawn Garbett, MS is faculty at Vanderbilt University Medical Center, where he holds an appointment in the Department of Biostatistics. Mr. Garbett is the director for informatics software development.\nGarbett has a diverse career background starting as an engineer for the Tennessee Valley Authority doing load grid optimization and data collection and modeling of the reservoir system. He worked as a consultant for many years, designing high confidence medical and nuclear software systems. He designed the first FDA approved closed loop medical device for Walter Reed with installations in Air Force One.\nHis research career began when he joined Vanderbilt in 2009. He began working with the department of Health Policy at Vanderbilt in 2016 and has participated in research on two publications which got listed in the top 10 papers in genomics. He has coauthored a book chapter on pharmacogenomics.\n\n\nJohn Graves (Vanderbilt University)\n\n\n\n\n\nJohn Graves, Ph.D. is Associate Professor at Vanderbilt University School of Medicine, where he holds appointments in the Department of Health Policy and the Department of Medicine. Dr. Graves directs the Center for Health Economic Modeling at Vanderbilt University Medical Center, and is a faculty affiliate of the Vanderbilt Institute for Global Health (VIGH) and the Vanderbilt Ingram Cancer Center.\nGraves’ career spans nearly 20 years conducting interdisciplinary research at the intersection of health economics and health care policy. The focus of his work is on the use of econometric and decision analytic methodologies to inform the development, implementation and evaluation of health care reforms at the state and federal level. His research contributions include modeling efforts that informed both the 2006 Massachusetts health reform legislation and the 2010 Affordable Care Act, for which he served as lead modeler for the White House Office of Health Reform.\nSince joining Vanderbilt in 2011, Graves has led and published research projects on novel methods for identifying provider shortages, on the returns to hospital spending and quality, and on the value of genetic screening in diverse health system populations. He currently leads two large federally-funded research grants on the health effects of insurance coverage expansion among safety net patients in the South, and on the implications of provider network design for access and competition in health insurance markets.\nGraves earned his BA in Economics and English from The University of the South in Sewanee, Tennessee. He holds a Ph.D. in Health Policy from Harvard University and is the recipient of fellowships and awards from the Agency for Health Care Research and Quality, the National Institute on Aging, the National Bureau of Economic Research, the American Statistical Association, and the National Academy of Social Insurance. He has taught and consulted for the Master’s in Public Administration in International Development at the Harvard Kennedy School, and is an affiliate of the Abdul Latif Jameel Poverty Action Lab at MIT.\n\n\n\nCourse Development\n\nHanxuan Yu (Vanderbilt University Medical Center)\n\n\n\n\n\nHanxuan (Astrid) Yu is a Health Policy Data Analyst in the Department of Health Policy at Vanderbilt University. Working with Dr. Ashley Leech, Prof. John Graves, and Dr. Jinyi Zhu, she applies a range of analytical methods, including discrete event simulation, microsimulation, and Markov model, to address practical questions and support decision-making in the public health field. She also focuses on methodological advances to enhance the accuracy, speed and quality of decision analysis. Her ongoing projects include: 1) applying model-based cost-effectiveness analysis in the healthcare for pregnant women with opioid use disorder and global health questions like childhood epilepsy patients in Nigeria, 2) evaluating the clinical value and application method of polygenic risk scores for atherosclerotic cardiovascular disease based on cost-effectiveness techniques, 3) developing methodology implementations like common random numbers in specific disease simulation models.\n\n\nAshley Leech (Vanderbilt University)\n\n\n\n\n\nAshley Leech is an Assistant Professor in the Department of Health Policy at the Vanderbilt University School of Medicine. Dr. Leech’s research combines health services research and health economic methods to answer questions related to healthcare access, delivery, resource allocation, and use, and outcomes for reproductive-age women and their children. She is the Principal Investigator of an NIH/NIDA-funded career development award on Advancing Treatment Outcomes for Pregnant Women with Opioid Use Disorder where she is using decision science methodology to promote the coverage and adoption of high-value healthcare for pregnant women with opioid use disorder, a population that disproportionately faces major impediments to care.\nDr. Leech completed her post-doctoral training in Health Economics at the Center for the Evaluation of Value and Risk in Health (CEVR) at Tufts University School of Medicine where she focused on decision science methodology and received her Ph.D. in Health Services Research at Boston University School of Public Health."
  },
  {
    "objectID": "blog/posts/embedding-a-transition-probability-matrix.html",
    "href": "blog/posts/embedding-a-transition-probability-matrix.html",
    "title": "Embedding A Transition Probability Matrix for a Discrete Time Markov Model",
    "section": "",
    "text": "Define \\(r_{HS}\\) and \\(r_{HD}\\) as the hazard rate of two independent competing risks from a given (Healthy) health state (to Sick and Dead, respectively), and \\(\\Delta t\\) the cycle length (e.g., \\(1\\)=1 year, \\(1/12\\)=1 month, etc.). We can also define a third rate \\(r_{SD} = hr_{S}*r_{HD}\\) for transitioning from sick to dead, i.e., the standard (healthy-to-dead) rate multiplied by the hazard ratio \\(hr_{S}\\).\nThe underlying Markov model takes the following form:\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nHealthy\n\n Healthy   \n\nHealthy-&gt;Healthy\n\n    \n\nSick\n\n Sick   \n\nHealthy-&gt;Sick\n\n  r_HS   \n\nDead\n\n Dead   \n\nHealthy-&gt;Dead\n\n  r_HD   \n\nSick-&gt;Sick\n\n    \n\nSick-&gt;Dead\n\n  hr_S * r_HD   \n\nDead-&gt;Dead\n\n   \n\n\nFigure 1: Model Diagram\n\n\n\n\n\n\n\nCode\nlibrary(Matrix)\nlibrary(tidyverse)\nlibrary(expm)\nlibrary(knitr)\nlibrary(gt)\nlibrary(directlabels)\nlibrary(glue)\nlibrary(ggsci)\nlibrary(ggthemes)\n\n# Better accuracy that \"life-table\" aka trapezoidal method\nalt_simp_coef &lt;- function(i) c(17, 59, 43, 49, rep(48, i-8), 49, 43, 59, 17) / 48\nalt_simp      &lt;- function(x,h) h*sum(alt_simp_coef(length(x)) * x)\n\nr_HS &lt;- 0.15\nr_HD &lt;- .006\nhr_S &lt;- 10\nr_SD &lt;- hr_S*r_HD\ncycle &lt;- 1\n\n# 1-exp(-r_HS*cycle)\n# 1-exp(-r_HD*cycle)\n\nget_P &lt;- function(r_HS,r_HD,r_SD,cycle) {\n  P_st &lt;- \n  matrix(\n  c(exp(-r_HS*cycle) + exp(-r_HD*cycle) -1 ,  (1-exp(-r_HS*cycle)) ,  1-exp(-r_HD*cycle), \n  0, exp(-r_SD*cycle), 1-exp(-r_SD*cycle),\n  0,0,1),\n  nrow = 3, \n  ncol = 3,\n  byrow=TRUE,\n  dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) %&gt;% \n    data.frame() %&gt;% \n    rownames_to_column(var = \"from\") %&gt;% \n    mutate(name = \"P_st\")\n\n  P_eQ &lt;- matrix(\n    c(-(r_HS*cycle+r_HD*cycle),r_HS*cycle,r_HD*cycle,\n      0,-r_SD*cycle,r_SD*cycle,\n      0,0,0),\n      nrow=3,\n      ncol=3,\n      byrow=TRUE,\n    dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) %&gt;% expm() %&gt;% as.matrix() %&gt;% \n    data.frame() %&gt;% \n    rownames_to_column(var = \"from\") %&gt;% \n    mutate(name = \"P_eQ\")\n\n\n  P_cr &lt;- \n    matrix(\n    c(exp(-(r_HS+r_HD)*cycle) , (r_HS/(r_HS+r_HD)) * (1-exp(-(r_HS+r_HD)*cycle))   ,(r_HD/(r_HS+r_HD)) * (1-exp(-(r_HS+r_HD)*cycle))   , \n    0, exp(-r_SD*cycle), 1-exp(-r_SD*cycle),\n    0,0,1),\n    nrow = 3, \n    ncol = 3,\n    byrow=TRUE,\n    dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) %&gt;% \n    data.frame() %&gt;% \n    rownames_to_column(var = \"from\") %&gt;% mutate(name = \"P_cr\")\n  \n  \n  \n  out &lt;- bind_rows( P_st, P_cr , P_eQ)\n  return(out)\n}\n\n\n\n\nCode\ncheck_sens &lt;- function(r_HD,r_HS,r_SD,cycle) {\n  \nQ &lt;- matrix(\n    c(-(r_HS*cycle+r_HD*cycle),r_HS*cycle,r_HD*cycle,\n      0,-r_SD*cycle,r_SD*cycle,\n      0,0,0),\n      nrow=3,\n      ncol=3,\n      byrow=TRUE,\n    dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) \n\n# Q_ &lt;- rbind(cbind(Q,c(r_HS*cycle,0,0)),c(0,0,0,0)) \n# Q_ &lt;- rbind(cbind(Q_,c(r_HD*cycle,0,0,0)),c(0,0,0,0,0))\n# dimnames(Q_) = list(c(\"Healthy\",\"Sick\",\"Dead\",\"accS\",\"accHD\"),\n#                    c(\"Healthy\",\"Sick\",\"Dead\",\"accS\",\"accHD\"))\n\nQ_ &lt;- Q\n\nP &lt;- Q_ %&gt;% expm() %&gt;% as.matrix() \nres &lt;- get_P(r_HS=r_HS,r_HD=r_HD,r_SD=r_SD,cycle=cycle)\n\nP_cr &lt;- res %&gt;% filter(name==\"P_cr\") %&gt;% select(from,Healthy,Sick,Dead) %&gt;% \n  data.frame() %&gt;% \n  column_to_rownames(var = \"from\") %&gt;% \n  as.matrix()\n\nP_st &lt;- res %&gt;% filter(name==\"P_st\") %&gt;% select(from,Healthy,Sick,Dead) %&gt;% \n  data.frame() %&gt;% \n  column_to_rownames(var = \"from\") %&gt;% \n  as.matrix()\n\nle1 &lt;- \n  0:(60/cycle) %&gt;% map(~(c(1000,0,0) %*% (P[1:3,1:3] %^% (.x)))) %&gt;% \n  map(~(.x %&gt;% data.frame)) %&gt;% \n  bind_rows() %&gt;% \n  as.matrix() %&gt;%  \n  {.[,-3]} %&gt;% \n  alt_simp(.,1) %&gt;% \n  {. * cycle} %&gt;% {./1000} %&gt;% \n  data.frame() %&gt;% \n  set_names(\"life_exp\")\n\nres1 &lt;- 0:(60/cycle) %&gt;% map_df(~(c(1000,0,0) %*% (P %^%.x) %&gt;% data.frame())) %&gt;% \n  mutate(cycle = 0:(60/cycle)) %&gt;% \n  select(cycle, everything()) %&gt;% \n  tibble() %&gt;% \n  tail(n=1) %&gt;% \n  bind_cols(le1) %&gt;% \n  mutate(method = \"P_eQ\") \n\nle2 &lt;- \n  0:(60/cycle) %&gt;% map(~(c(1000,0,0) %*% (P_cr[1:3,1:3] %^% (.x)))) %&gt;% \n  map(~(.x %&gt;% data.frame)) %&gt;% \n  bind_rows() %&gt;% \n   as.matrix() %&gt;%  \n  {.[,-3]} %&gt;% \n  alt_simp(.,1) %&gt;% \n  {. * cycle} %&gt;% {./1000} %&gt;% \n  data.frame() %&gt;% \n  set_names(\"life_exp\")\n  \nres2 &lt;- 0:(60/cycle) %&gt;% map_df(~(c(1000,0,0) %*% (P_cr %^%.x) %&gt;% data.frame())) %&gt;% \n  mutate(cycle = 0:(60/cycle)) %&gt;% \n  select(cycle, everything()) %&gt;% \n  tibble() %&gt;% \n  tail(n=1) %&gt;% \n  bind_cols(le2) %&gt;% \n  mutate(method = \"P_cr\")\n\n\nle3 &lt;- \n 0:(60/cycle) %&gt;% map(~(c(1000,0,0) %*% (P_st[1:3,1:3] %^% (.x)))) %&gt;% \n  map(~(.x %&gt;% data.frame)) %&gt;% \n  bind_rows() %&gt;% \n   as.matrix() %&gt;%  \n  {.[,-3]} %&gt;% \n  alt_simp(.,1) %&gt;% \n  {. * cycle} %&gt;% {./1000} %&gt;% \n  data.frame() %&gt;% \n  set_names(\"life_exp\")\n\nres3 &lt;- 0:(60/cycle) %&gt;% map_df(~(c(1000,0,0) %*% (P_st %^%.x) %&gt;% data.frame())) %&gt;% \n  mutate(cycle = 0:(60/cycle)) %&gt;% \n  select(cycle, everything()) %&gt;% \n  tibble() %&gt;% \n  tail(n=1) %&gt;% \n  bind_cols(le3) %&gt;% \n  mutate(method = \"P_st\")\n  \n  out &lt;- res1 %&gt;% bind_rows(res2) %&gt;% bind_rows(res3)\n  return(out)\n\n}"
  },
  {
    "objectID": "blog/posts/embedding-a-transition-probability-matrix.html#standard-rate-to-transition-conversion",
    "href": "blog/posts/embedding-a-transition-probability-matrix.html#standard-rate-to-transition-conversion",
    "title": "Embedding A Transition Probability Matrix for a Discrete Time Markov Model",
    "section": "Standard Rate-to-Transition Conversion",
    "text": "Standard Rate-to-Transition Conversion\nLet’s first convert the supplied rates to probabilities using the same standard formulas, as above:\n\\[\np_{HS}= 1 - e^{-r_{HS}\\cdot \\Delta t}\n\\]\n\\[\np_{HD} = 1 - e^{-r_{HD}\\cdot \\Delta t}\n\\]\nWe can also define the probability of remaining healthy (i.e., transitioning to neither the sick or dead state) as:\n\\[\np_{HH} = 1 - p_{HS} - p_{HD}= e^{-r_{HS}\\Delta t}  + e^{-r_{HD}\\Delta t} - 1\n\\]\nAnd finally the probability of dying among sick people is defined as\n\\[\np_{SD} = 1 - e^{-hr_{HD}\\cdot r_{HD}\\cdot \\Delta t}\n\\]\nFigure 6 shows the corresponding transition probability matrix:\n\n\nCode\nr_HD &lt;- 0.006\nr_SD &lt;- 10*0.006\n\nget_P(r_HS=r_HS,r_HD=r_HD,r_SD=r_SD,cycle=cycle) %&gt;% \nfilter(name==\"P_st\") %&gt;% \nselect(-name) %&gt;% \n#column_to_rownames(\"from\") %&gt;% \nmutate_at(vars(-from), ~round(.,4)) %&gt;% \ngt() %&gt;% \n  cols_label(\"from\"=\"\")\n\n\n\n\n\n\n\n\n\n\n\nHealthy\nSick\nDead\n\n\n\n\nHealthy\n0.8547\n0.1393\n0.0060\n\n\nSick\n0.0000\n0.9418\n0.0582\n\n\nDead\n0.0000\n0.0000\n1.0000\n\n\n\n\n\nFigure 6: Transition Probability Matrix Using Standard Rate-to-Probability Conversion Formulas\n\n\n\nGiven this transition probability matrix, how many healthy, sick and dead individuals do we have in our cohort after a 60-year time horizon? Figure 7 summarizes state occupancy at the end of 60 years:\n\n\nCode\nres_60yst &lt;- \n  check_sens(r_HD= r_HD, r_HS = r_HS, r_SD = r_SD, cycle=1) %&gt;% \n  filter(method==\"P_st\") \nres_60yst %&gt;% \n  select(cycle,Healthy,Sick,Dead,life_exp) %&gt;% \n  gt::gt() %&gt;% \n  sub_missing(missing_text=\"-\") %&gt;% \n  fmt_number(columns = c(Healthy,Sick,Dead,life_exp),decimals=1) %&gt;% \n  cols_label(\"life_exp\" = \"Life Expectancy\")\n\n\n\n\n\n\n\n\n\n\ncycle\nHealthy\nSick\nDead\nLife Expectancy\n\n\n\n\n60\n0.1\n43.6\n956.3\n22.1\n\n\n\n\n\nFigure 7: 1-Year Cycle\n\n\n\nAs Figure 7 shows, after 60 years, 43.6 are recorded as being in the sick state and life expectancy has reduced to 22.1 years.\nAs above, let’s now repeat the same exercise using a daily cycle length:\n\n\nCode\nres_60yst_daily &lt;- \n  check_sens(r_HD= r_HD, r_HS = r_HS, r_SD = r_SD,cycle=1/365) %&gt;% \n  filter(method==\"P_st\") \n\nres_60yst_daily %&gt;% \n  select(cycle,Healthy,Sick,Dead,life_exp) %&gt;% \n  gt::gt() %&gt;% \n  sub_missing(missing_text=\"-\") %&gt;% \n  fmt_number(columns = c(Healthy,Sick,Dead,life_exp),decimals=1) %&gt;% \n  cols_label(\"life_exp\" = \"Life Expectancy\")\n\n\n\n\n\n\n\n\n\n\ncycle\nHealthy\nSick\nDead\nLife Expectancy\n\n\n\n\n21900\n0.1\n42.6\n957.4\n21.7\n\n\n\n\n\nFigure 8: Daily Cycle\n\n\n\nBy switching to a daily cycle we now have 42.6 recorded as being in the sick state after 60 years (=21,900 days) and life expectancy is 21.7 years.\n\nSigns of Trouble\nLet’s recap what we have found after introducing background mortality as a competing risk:\n\nUsing a 1-year cycle length, life expectancy is 22.11 years.\nUsing a daily cycle length, life expectancy is 21.73 years.\n\nThe only difference above is the cycle length used, yet we obtain a 0.38 year difference in life expectancy. What causes this difference?\n\n\nDiscretizing a Continuous Time Process\nThe answer boils down to the fact that with longer cycle lengths we “hide” some deaths that occur because a full healthy sick dead transition occurs within a single cycle.\nWhen we use the standard rate-to-probability conversion formula (i.e., \\(p_{HS}= 1 - e^{-r_{HS}\\Delta t}\\)) we obtain the marginal probability of transition. This marginal probability reflects the union of all possible transitions that start Healthy and then transition to and from the sick state in the cycle.\nThat is, \\(p_{HS}= 1 - e^{-r_{HS}\\Delta t}\\) captures the probability of following scenarios occurring in a cycle:\n\nIndividual transitions from healthy to sick.\nIndividual transitions from healthy to sick to dead.\n\nBy including case 2 in the healthy sick transition probability, we effectively rule out the possibility of becoming sick and dying within the same cycle. This implicit assumption means that we are no longer modeling a continuous time process, since we effectively “hide” some (quick) deaths that occur within a cycle due to the disease:\n\n\n\n\n\n\n\n\nG\n\n  \n\nHealthy\n\n Healthy   \n\nHealthy-&gt;Healthy\n\n    \n\nSick\n\n Sick   \n\nHealthy-&gt;Sick\n\n    \n\nDead\n\n Dead   \n\nHealthy-&gt;Dead\n\n    \n\nSick-&gt;Sick\n\n    \n\nSick-&gt;Dead\n\n    \n\nDead-&gt;Dead\n\n   \n\n\nFigure 9: compound Transition Patterns Using Standard Rate to Probability Conversion Formulas\n\n\n\n\nIn Figure 9, and using standard rate-to-probability conversion formulas, the recorded states of a healthy sick dead transition are recorded in blue; the “hidden” transition is shown in red.\n\nAlternative Rate-to-Probability Conversion\nAnother set of formulas often used to account for competing risks are as follows:\n\\[\np_{HS}= \\frac{r_{HS}}{r_{HS}+r_{HD}}\\big ( 1 - e^{-(r_{HS}+r_{HD})\\Delta t}\\big )\n\\]\n\\[\np_{HD}= \\frac{r_{HD}}{r_{HS}+r_{HD}}\\big ( 1 - e^{-(r_{HS}+r_{HD})\\Delta t}\\big )\n\\]\n\\[\np_{HH} = e^{-(r_{HS}+r_{HD})\\Delta t}\n\\]\nLet’s now use these formulas instead.\nFigure 10 shows the corresponding transition probability matrix:\n\n\nCode\nr_HD &lt;- 0.006\nr_SD &lt;- 10*0.006\n\nget_P(r_HS=r_HS,r_HD=r_HD,r_SD=r_SD,cycle=cycle) %&gt;% \nfilter(name==\"P_cr\") %&gt;% \nselect(-name) %&gt;% \n#column_to_rownames(\"from\") %&gt;% \nmutate_at(vars(-from), ~round(.,4)) %&gt;% \ngt() %&gt;% \n  cols_label(\"from\"=\"\")\n\n\n\n\n\n\n\n\n\n\n\nHealthy\nSick\nDead\n\n\n\n\nHealthy\n0.8556\n0.1389\n0.0056\n\n\nSick\n0.0000\n0.9418\n0.0582\n\n\nDead\n0.0000\n0.0000\n1.0000\n\n\n\n\n\nFigure 10: Transition Probability Matrix Using Alternative Rate-to-Probability Conversion Formulas\n\n\n\nComparing Figure 6 and Figure 10, notice that a few things have changed. First, the probability of Healthy Sick transition declined. This would seem to be consistent with a world in which there are fewer alive sick individuals observed at the end of the cycle–which we would expect if acute illness results in a nontrivial number of quick deaths after illness onset in a cycle.\nHowever, look at the Healthy Dead transition probability change; it went down, too. If we were recording more acute deaths from the disease, we should see more Healthy Dead transitions from individuals sojourning through the Sick state on their way to death in a single cycle.\nWhat about state occupancy and life expectancy under different cycle lengths?\n\n\nCode\nres_60yst_cr &lt;- \n  check_sens(r_HD= r_HD, r_HS = r_HS, r_SD = r_SD, cycle=1) %&gt;% \n  filter(method==\"P_cr\") %&gt;% \n  mutate(cycle = \"1y\") %&gt;% \n  mutate(cycle_t = 60)\n\nres_60yst_daily_cr &lt;- \n  check_sens(r_HD= r_HD, r_HS = r_HS, r_SD = r_SD,cycle=1/365) %&gt;% \n  filter(method==\"P_cr\") %&gt;% \n  mutate(cycle_t = cycle) %&gt;% \n  mutate(cycle = \"Daily\")\n\nres_60yst_cr %&gt;% \n  bind_rows(res_60yst_daily_cr) %&gt;% \n  select(cycle,cycle_t,Healthy,Sick,Dead,life_exp) %&gt;% \n  gt::gt() %&gt;% \n  sub_missing(missing_text=\"-\") %&gt;% \n  fmt_number(columns = c(Healthy,Sick,Dead,life_exp),decimals=1) %&gt;% \n  cols_label(\"life_exp\" = \"Life Expectancy\")\n\n\n\n\n\n\n\n\n\n\ncycle\ncycle_t\nHealthy\nSick\nDead\nLife Expectancy\n\n\n\n\n1y\n60\n0.1\n43.9\n956.0\n22.2\n\n\nDaily\n21900\n0.1\n42.6\n957.4\n21.7\n\n\n\n\n\nFigure 11: 1-Year vs. Daily Cycle\n\n\n\nCode\ndiff_st_cr &lt;- \n  res_60yst_cr %&gt;% \n    bind_rows(res_60yst_daily_cr) %&gt;% mutate(life_exp = life_exp-lead(life_exp)) %&gt;% pull(life_exp) %&gt;% na.omit() %&gt;% as.vector()\n\n\nAgain, we have a difference in life expectancy of 0.462 years. So switching to the alternative formulas has not fundamentally solved our problem.\n\n\nHow do transition probabilities change as the Likelihood of Disease-related death varies?\nAnother way to see the issue is to plot how the transition probabilities change (or not) at different levels of disease acuity. Figure 12 plots the relevant transition probabilities under a yearly time cycle, and while allowing the underlying hazard rate of death from the disease (hr_S) to vary.\nAs the hazard rate increases, the likelihood of ending up dead within a given cycle increases. Indeed, in the most extreme case, imagine the disease has a near instantaneous death rate. In that case we should see almost no Healthy Sick transitions within a yearly cycle, because nearly everyone who became sick within the cycle died within 1 day.\nWe see in Figure 12 that the Healthy Sick probabilities remain flat for transitions under which background mortality is a competing event. However, the Sick Dead transition probabilities rise as the likelihood of fatal disease increases.\n\n\nCode\n1:10 %&gt;% map(~get_P(r_HS=.15,r_HD=.006,r_SD=.006*.x,cycle=1) %&gt;% mutate(hr_S=.x)) %&gt;% \n  bind_rows() %&gt;% \n  gather(transition,value,-from,-name,-hr_S) %&gt;% \n  spread(name,value) %&gt;% \n  filter(P_cr!=1 & P_cr!=0) %&gt;% \n  gather(method,value,-from,-hr_S,-transition) %&gt;% \n    filter(method!=\"P_eQ\") %&gt;% \n  tibble() %&gt;% \n  mutate_at(vars(transition), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  mutate_at(vars(from), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"),\n                                           labels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  filter(from!=transition) %&gt;% \n  ggplot(aes(x = hr_S, y = value)) + \n  geom_point(aes(colour=method, shape=method),size=3) + \n  scale_shape_manual(values = c(19,17)) +\n  scale_color_manual(values= c(\"blue\",\"red\")) +\n  facet_wrap(from~transition, scales=\"free\") + \n  ggthemes::theme_base() + \n  scale_x_continuous(expand = expansion(mult=.5))+\n  scale_y_continuous(expand = expansion(mult=.5))+\n  theme(legend.position = \"bottom\") +\n  directlabels::geom_dl(aes(label = glue::glue(\"  {method}\")), method=\"last.bumpup\",hjust=1) + \n  labs(x = \"hr_S (Hazard Ratio for Sick-to-Dead)\",y = \"Value\")\n\n\n\n\n\nFigure 12: Yearly Cycle - Transition Probabilities by Sick-to-Dead Hazard Rate (P_st uses standard conversion formula; P_cr uses the formula that accounts for competing risks.)\n\n\n\n\nIt is common practice to address these issues using the following guidelines:\n\nSelect a cycle length where the probability of remaining in a given state is at least 95%.\nPick a cycle length that aligns with the clinical/disease timelines of the decision problem.\n\nTreatment schedules.\nAcute vs. chronic condition.\n\n\nBut do these actually solve the issue? No. Figure 13 shows how the transition probabilities change when we switch to a daily cycle length. Again, we see the problem: as disease acuity increases, the probability of a Healthy Dead transition does not change; even though we shortened the cycle length, we have not fundamentally addressed the issue.\n\n\nCode\n1:10 %&gt;% map(~get_P(r_HS=.15,r_HD=.006,r_SD=.006*.x,cycle=1/365) %&gt;% mutate(hr_S=.x)) %&gt;% \n  bind_rows() %&gt;% \n  gather(transition,value,-from,-name,-hr_S) %&gt;% \n  spread(name,value) %&gt;% \n  filter(P_cr!=1 & P_cr!=0) %&gt;% \n  gather(method,value,-from,-hr_S,-transition) %&gt;% \n  filter(method!=\"P_eQ\") %&gt;% \n  tibble() %&gt;% \n  mutate_at(vars(transition), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  mutate_at(vars(from), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"),\n                                           labels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  filter(from!=transition) %&gt;% \n  ggplot(aes(x = hr_S, y = value)) + \n  geom_point(aes(colour=method, shape=method),size=3) + \n    scale_shape_manual(values = c(19,17)) +\n  scale_color_manual(values= c(\"blue\",\"red\")) +\n  facet_wrap(from~transition, scales=\"free\") + \n  ggthemes::theme_base() + \n  scale_x_continuous(expand = expansion(mult=.5))+\n  scale_y_continuous(expand = expansion(mult=.5))+\n  theme(legend.position = \"bottom\") +\n  directlabels::geom_dl(aes(label = glue::glue(\"  {method}\")), method=\"last.bumpup\",hjust=1) + \n  labs(x = \"hr_S (Hazard Ratio for Sick-to-Dead)\",y = \"Value\")\n\n\n\n\n\nFigure 13: Daily Cycle - Transition Probabilities by Sick-to-Dead Hazard Rate (P_st uses standard conversion formula; P_cr uses the formula that accounts for competing risks.)\n\n\n\n\nHow does this all translate into model outputs, such as life expectancy? Figure 14 plots life-expectancy (y-axis) against the underlying disease hazard rate for death. Each line provides the life-expectancy curve under a different cycle length, with everything else in the model held fixed.\nNot surprisingly, we see that as the likelihood of fatal disease increases, life expectancy declines.\nBut the most important takeaway is that the modeled life expectancy differs depending on the cycle length used. For a given hazard rate the underlying disease process is exactly the same – but we get different answers depending on our cycle length.\nThe pattern of results is instructive, too. Essentially, with longer cycle lengths and incorrect transition probabilities, we will “miss” more compound within-cycle Healthy Sick Dead transitions and instead record them as Healthy Sick transitions. This has a net effect of “hiding” more disease-related death in our model – and life-expectancy is inflated as a result.\n\n\n\n\n\nFigure 14: Life Expectancy by Sick-to-Dead Hazard Rate and Cycle Length. The left panel uses the formula that accounts for competing risks. The right panel uses standard conversion formula."
  },
  {
    "objectID": "blog/posts/embedding-a-transition-probability-matrix.html#embed-the-transition-probability-matrix",
    "href": "blog/posts/embedding-a-transition-probability-matrix.html#embed-the-transition-probability-matrix",
    "title": "Embedding A Transition Probability Matrix for a Discrete Time Markov Model",
    "section": "1. Embed the Transition Probability Matrix",
    "text": "1. Embed the Transition Probability Matrix\nOur rate matrix Q is constructed by including the relevant transition rates in the off-diagonal cells. The diagonal of Q is the negative sum of off-diagonal elements in the same row:\n\n\n\n\n\n\n\n\n\n\nHealthy\nSick\nDead\n\n\n\n\nHealthy\n-(\\(r_{HS}\\) + \\(r_{HD}\\))\n\\(r_{HS}\\)\n\\(r_{HD}\\)\n\n\nSick\n0\n-(\\(hr_{S} \\cdot r_{HD}\\))\n\\(hr_{S} \\cdot r_{HD}\\)\n\n\nDead\n0\n0\n0\n\n\n\nHere is the rate matrix for the Healthy-Sick-Dead model:\n\n\nCode\nparams &lt;- \n  list(r_HS = 0.15,\n       r_HD = 0.006,\n       hr_S = 10,\n       cycle = 1)\n\nQ &lt;- \n  with(params,{\n    matrix(\n    c(-(r_HS*cycle+r_HD*cycle),r_HS*cycle,r_HD*cycle,\n      0,-r_SD*cycle,r_SD*cycle,\n      0,0,0),\n      nrow=3,\n      ncol=3,\n      byrow=TRUE,\n    dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) \n  })\nQ\n\n\n        Healthy  Sick  Dead\nHealthy  -0.156  0.15 0.006\nSick      0.000 -0.06 0.060\nDead      0.000  0.00 0.000\n\n\nWe next embed the transition probability matrix P by taking the matrix exponential of Q:\n\nlibrary(expm)\nP &lt;- expm(Q)\nP\n\n          Healthy      Sick        Dead\nHealthy 0.8555592 0.1346958 0.009744961\nSick    0.0000000 0.9417645 0.058235466\nDead    0.0000000 0.0000000 1.000000000\n\n\nAn alternative way of exponentiating a matrix is to perform a Taylor series expansion:\n\n# Identity matrix with same dimensions and names as Q \nQ_I &lt;- diag(3)\ndimnames(Q_I) = dimnames(Q)\n\n# Note the %^% operator is in the expm package. \n\nQ2 = Q %^% 2   # Q-squared\nQ3 = Q %^% 3   # Q-cubed\nQ4 = Q %^% 4   # etc.\n\nQ_I + Q + (1/factorial(2))*Q2 + (1/factorial(3))*Q3 + (1/factorial(4))*Q4 \n\n          Healthy      Sick        Dead\nHealthy 0.8555599 0.1346947 0.009745373\nSick    0.0000000 0.9417645 0.058235460\nDead    0.0000000 0.0000000 1.000000000\n\n\nHow does this approach (P_eQ) perform relative to the other transition probability matrices (P_st and P_cr)? Figure 15 shows how the transition probabilities vary by hazard rate.\nWe can now see we’ve achieved what we need: Healthy Dead transition probabilities that rise as the hazard rate of death from disease increases. Again, this occurs because as the likelihood of death after becoming ill increases, we increase the likelihood of a compound Healthy Sick Dead transition within a cycle. We need these to be recorded (accurately) as Healthy Dead transitions, rather than Healthy Sick transitions. Correspondingly, as the probability of a compound transition increases with an increasing hazard rate, the probability of a single Healthy Sick transition declines; we see this in Figure 15 as well.\n\n\nCode\n1:10 %&gt;% map(~get_P(r_HS=.15,r_HD=.006,r_SD=.006*.x,cycle=1) %&gt;% mutate(hr_S=.x)) %&gt;% \n  bind_rows() %&gt;% \n  gather(transition,value,-from,-name,-hr_S) %&gt;% \n  spread(name,value) %&gt;% \n  filter(P_cr!=1 & P_cr!=0) %&gt;% \n  gather(method,value,-from,-hr_S,-transition) %&gt;% \n  #filter(method!=\"P_eQ\") %&gt;% \n  tibble() %&gt;% \n  mutate_at(vars(transition), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  mutate_at(vars(from), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"),\n                                           labels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  filter(from!=transition) %&gt;% \n  ggplot(aes(x = hr_S, y = value)) + \n  geom_point(aes(colour=method, shape=method),size=3) + \n  scale_shape_manual(values = c(19,17,3)) +\n  facet_wrap(from~transition, scales=\"free\") + \n  ggthemes::theme_base() + \n  scale_x_continuous(expand = expansion(mult=.5))+\n  scale_y_continuous(expand = expansion(mult=.5))+\n  theme(legend.position = \"bottom\") +\n  scale_color_manual(values= c(\"blue\",\"darkgreen\",\"red\")) +\n  directlabels::geom_dl(aes(label = glue::glue(\"  {method}\")), method=\"last.bumpup\",hjust=1) + \n  labs(x = \"hr_S (Hazard Ratio for Sick-to-Dead)\",y = \"Value\")\n\n\n\n\n\nFigure 15: 1-Year Cycle - Transition Probabilities by Sick-to-Dead Hazard Rate (P_st uses standard conversion formula; P_cr uses the formula that accounts for competing risks, and P_eQ is embedded using the transition rate matrix Q.)\n\n\n\n\nWe also see that regardless of the cycle length used, we always end up with the same calculated life expectancy:\n\n\n\n\n\nFigure 16: Life Expectancy by Sick-to-Dead Hazard Rate and Cycle Length\n\n\n\n\nWe have thus “fixed” our problem of hidden disease-related deaths!\n\nWhy is this important?\nThe use of an embedded transition probability matrix is important for a number of reasons:\n\nThe Markov model accurately reflects the underlying continuous time process.\nWe get an accurate accounting of disease-related deaths.\nWe can use whatever cycle length we need – this facilitates computationally intensive processes such as probabilistic sensitivity analyses, which may not be feasible with a short (e.g., daily) cycle length.\nWe also avoid “state explosion” in the event our model has tunnel states. For example, if there is a one-year tunnel state for costs or utilities following disease onset, if we switched to a monthly or daily cycle we’d have to build in dozens or more health states into our Markov model. Beacuse we can stick with a one-year cycle, this makes use of tunnel states much more feasible.\n\nThe primary “cost” of using this approach over standard rate-to-probability conversion formulas is that we must be a bit more careful in structuring our transition probability matrix to include accumulators used to aggregate model outputs. We will cover this process in the section directly below."
  },
  {
    "objectID": "blog/posts/embedding-a-transition-probability-matrix.html#include-non-markovian-accumulators-to-record-event-transitions",
    "href": "blog/posts/embedding-a-transition-probability-matrix.html#include-non-markovian-accumulators-to-record-event-transitions",
    "title": "Embedding A Transition Probability Matrix for a Discrete Time Markov Model",
    "section": "2. Include Non-Markovian Accumulators to Record Event Transitions",
    "text": "2. Include Non-Markovian Accumulators to Record Event Transitions\nWe now have the correct transition probabilities to model the underlying continuous-time process, but how do we account for these compound transitions in our aggregation of model outputs?\nFundamentally, what we have now is a model that will correctly records the “true” number of deaths at the end of the cycle, because all the compound Healthy Sick Dead transitions are included in the Healthy Dead transition probability.\nTo track the total number of transitions to Sick, we must augment our transition probability matrix with non-Markovian accumulators. This accumulator shows up as a purple edge in our model diagram below:\n\n\n\n\n\n\n\nG\n\n  \n\nHealthy\n\n Healthy   \n\nHealthy-&gt;Healthy\n\n    \n\nSick\n\n Sick   \n\nHealthy-&gt;Sick\n\n    \n\nDead\n\n Dead   \n\nHealthy-&gt;Dead\n\n    \n\nSick-&gt;Sick\n\n    \n\nSick-&gt;Dead\n\n    \n\nDead-&gt;Dead\n\n   \n\n\n\n\n\nFortunately, accumulators are easy to build in. We simply add the relevant transition rate in a new column in the transition rate matrix Q, while leaving everything else the same.\nSuppose we want to count up all the Healthy Sick transitions in the model. To do this we simply add the appropriate transition rate (\\(r_{HS}\\)) in as an accumulator column:\n\n\n\n\n\n\n\n\n\n\n\nHealthy\nSick\nDead\naccHS\n\n\n\n\nHealthy\n-(\\(r_{HS}\\) + \\(r_{HD}\\))\n\\(r_{HS}\\)\n\\(r_{HD}\\)\n\\(r_{HS}\\)\n\n\nSick\n0\n-(\\(hr_{S} \\cdot r_{HD}\\))\n\\(hr_{S} \\cdot r_{HD}\\)\n0\n\n\nDead\n0\n0\n0\n0\n\n\naccHS\n0\n0\n0\n0\n\n\n\nNote the following:\n\nAn extra row of 0’s was added so that we balance the matrix, and ensure that we do not lose (or create!) anyone who becomes Sick.\nWe did not update the diagonal elements (i.e., the negative sum of transition rates); these stay the same as before.\nIf we wanted to add additional accumulators, we can just expand the matrix with more columns and rows as needed.\n\nHere is the augmented transition rate matrix for our example:\n\n\nCode\nQ_ &lt;- data.frame(Q)\nQ_[\"Healthy\",\"accHS\"] &lt;- params$r_HS\nQ_[\"accHS\",\"accHS\"] &lt;- 0\nQ_[is.na(Q_)] &lt;- 0\nQ_ &lt;- as.matrix(Q_)\nQ_ \n\n\n        Healthy  Sick  Dead accHS\nHealthy  -0.156  0.15 0.006  0.15\nSick      0.000 -0.06 0.060  0.00\nDead      0.000  0.00 0.000  0.00\naccHS     0.000  0.00 0.000  0.00\n\n\nWe next embed the transition probability matrix, as before:Notice that the accumulator (accHS) value is identical to the Healthy Sick transition probability we obtained using the alternative rate-to-probability conversion formula that accounted for competing risks (e.g., see Figure 10).\n\nP_ &lt;- expm(Q_)\nP_\n\n          Healthy      Sick        Dead     accHS\nHealthy 0.8555592 0.1346958 0.009744961 0.1388854\nSick    0.0000000 0.9417645 0.058235466 0.0000000\nDead    0.0000000 0.0000000 1.000000000 0.0000000\naccHS   0.0000000 0.0000000 0.000000000 1.0000000\n\n\nUsing the accumulator we can accurately count up how many individuals transition to the Sick state over our time horizon:\n\nm_trace &lt;- \n  0:(horizon/cycle) %&gt;% \n  map_df(~(c(1000,0,0,0) %*% (P_%^%.x) %&gt;% data.frame()))\n\n\n\nCode\nm_trace[3,] %&gt;% \n  round(.,2) %&gt;% \n  rownames_to_column(var=\"cycle\") %&gt;% \n  select(-cycle) %&gt;% \n  kable() %&gt;% \n  kableExtra::kable_styling()\n\n\n\n\n\n\n\n\nHealthy\n\n\nSick\n\n\nDead\n\n\naccHS\n\n\n\n\n\n\n731.98\n\n\n242.09\n\n\n25.93\n\n\n257.71\n\n\n\n\n\nFigure 17: State Occupancy after Two Years\n\n\n\nWe see in Figure 17 that after 2 years, 257.7 people (out of 1,000) have become sick, which is slightly less than the 259 who became sick after 2 years in our world without death as a competing risk. Moreover, we see that state occupancy in the Sick category is lower, at 242.1. This lower value reflects the fact some people had a compound transition through Sick and ended up dead in the same cycle. The difference (15.6) amounts to the total number of individual deaths we “hid” in the model when we used the incorrect rate-to-probability conversion formulas.This, of course, makes sense, since there are a small number of people who die before they could become ill once we add background mortality to the model"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Health Economics Workshop Blog",
    "section": "",
    "text": "Replication of Didactic Model\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lectures/lec_welcome.html",
    "href": "lectures/lec_welcome.html",
    "title": "Welcome and Introductions",
    "section": "",
    "text": "https://vchem-vital-workshop-2022.netlify.app\n\n\n\nAll course materials (slides, case studies, capstone exercises) are posted here.\nOur (likely evolving) schedule will also be posted here, and updated regularly.\n\n\n\n\n\n\nAll materials can be translated using the Google Translate Chrome extension!\n\n\n\n\n\n\nPlease introduce yourself!\n\n\n\n\n\nWe’re flexible – if there is a topic that is unclear to you, or that you would like expanded upon, please let us know!\nMixed content\n\n\nLectures\nSmall group case studies\nLarge group case studies and “hands-on” Excel exercises\nCapstone projects (small group or individual)\n\n\nBuilt from “ground up” for this workshop!\n\n\n\n\n\nBasics of decision analysis\n\n\nConcepts and theories (Day 1)\nMarkov modeling (Day 2)\nSummarizing and presenting results and sensitivity analysis (Days 3-4)\nAdvanced modeling techniques\n\n\n\n\n\nCase studies\n\n\nCumulative: each will build on the last\nAnswer keys (.xls and video) will be made available, and we will cover each as a group as well.\nDesigned in Excel, but structured in our (developing) “Pan-Decision-Analysis” (PAN-DA) framework.\n\n\n\n\nWhat does Pan-DA Mean?\n\n\nOur model structure template can be used for both Excel, and also extends into a (developing) R framework.\nThis means you can parameterize & develop your model in Excel, but ultimately run the model in R.\nNote that this is a developing framework—you are a very early “Alpha” tester!"
  },
  {
    "objectID": "lectures/lec_welcome.html#course-website",
    "href": "lectures/lec_welcome.html#course-website",
    "title": "Welcome and Introductions",
    "section": "",
    "text": "https://vchem-vital-workshop-2022.netlify.app\n\n\n\nAll course materials (slides, case studies, capstone exercises) are posted here.\nOur (likely evolving) schedule will also be posted here, and updated regularly."
  },
  {
    "objectID": "lectures/lec_welcome.html#course-website-1",
    "href": "lectures/lec_welcome.html#course-website-1",
    "title": "Welcome and Introductions",
    "section": "",
    "text": "All materials can be translated using the Google Translate Chrome extension!"
  },
  {
    "objectID": "lectures/lec_welcome.html#introductions",
    "href": "lectures/lec_welcome.html#introductions",
    "title": "Welcome and Introductions",
    "section": "",
    "text": "Please introduce yourself!"
  },
  {
    "objectID": "lectures/lec_welcome.html#workshop-format",
    "href": "lectures/lec_welcome.html#workshop-format",
    "title": "Welcome and Introductions",
    "section": "",
    "text": "We’re flexible – if there is a topic that is unclear to you, or that you would like expanded upon, please let us know!\nMixed content\n\n\nLectures\nSmall group case studies\nLarge group case studies and “hands-on” Excel exercises\nCapstone projects (small group or individual)\n\n\nBuilt from “ground up” for this workshop!"
  },
  {
    "objectID": "lectures/lec_welcome.html#workshop-content",
    "href": "lectures/lec_welcome.html#workshop-content",
    "title": "Welcome and Introductions",
    "section": "",
    "text": "Basics of decision analysis\n\n\nConcepts and theories (Day 1)\nMarkov modeling (Day 2)\nSummarizing and presenting results and sensitivity analysis (Days 3-4)\nAdvanced modeling techniques"
  },
  {
    "objectID": "lectures/lec_welcome.html#workshop-content-1",
    "href": "lectures/lec_welcome.html#workshop-content-1",
    "title": "Welcome and Introductions",
    "section": "",
    "text": "Case studies\n\n\nCumulative: each will build on the last\nAnswer keys (.xls and video) will be made available, and we will cover each as a group as well.\nDesigned in Excel, but structured in our (developing) “Pan-Decision-Analysis” (PAN-DA) framework."
  },
  {
    "objectID": "lectures/lec_welcome.html#worskthop-content",
    "href": "lectures/lec_welcome.html#worskthop-content",
    "title": "Welcome and Introductions",
    "section": "",
    "text": "What does Pan-DA Mean?\n\n\nOur model structure template can be used for both Excel, and also extends into a (developing) R framework.\nThis means you can parameterize & develop your model in Excel, but ultimately run the model in R.\nNote that this is a developing framework—you are a very early “Alpha” tester!"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html",
    "href": "lectures/SLIDE_TEMPLATES.html",
    "title": "slide templates",
    "section": "",
    "text": "Block quote\n\n\n– [@neumann2016]\n\n\n\n\nAutomatically animate matching elements across slides with Auto-Animate.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomatically animate matching elements across slides with Auto-Animate.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n This list\n Doesn’t have bullets"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#auto-animate",
    "href": "lectures/SLIDE_TEMPLATES.html#auto-animate",
    "title": "slide templates",
    "section": "",
    "text": "Automatically animate matching elements across slides with Auto-Animate."
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#auto-animate-1",
    "href": "lectures/SLIDE_TEMPLATES.html#auto-animate-1",
    "title": "slide templates",
    "section": "",
    "text": "Automatically animate matching elements across slides with Auto-Animate."
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#replace-bullet-points-with-fontawesome",
    "href": "lectures/SLIDE_TEMPLATES.html#replace-bullet-points-with-fontawesome",
    "title": "slide templates",
    "section": "",
    "text": "This list\n Doesn’t have bullets"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#original-image",
    "href": "lectures/SLIDE_TEMPLATES.html#original-image",
    "title": "slide templates",
    "section": "Original Image",
    "text": "Original Image"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#resized-image",
    "href": "lectures/SLIDE_TEMPLATES.html#resized-image",
    "title": "slide templates",
    "section": "Resized Image",
    "text": "Resized Image"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#resized-image2",
    "href": "lectures/SLIDE_TEMPLATES.html#resized-image2",
    "title": "slide templates",
    "section": "Resized Image2",
    "text": "Resized Image2"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#multi-column-list",
    "href": "lectures/SLIDE_TEMPLATES.html#multi-column-list",
    "title": "slide templates",
    "section": "Multi-Column list",
    "text": "Multi-Column list\n\n\n\nOne\nTwo\nThree\nFour\n\n\n\nFive\nSix\nSeven"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#fade-in---left-column-first-right-column-with-image-second-1",
    "href": "lectures/SLIDE_TEMPLATES.html#fade-in---left-column-first-right-column-with-image-second-1",
    "title": "slide templates",
    "section": "Fade In - Left Column First, Right Column (with image second)",
    "text": "Fade In - Left Column First, Right Column (with image second)\n\n\n\n\nText 1.\nText 2"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#fade-in---left-column-first-right-column-with-image-second-2",
    "href": "lectures/SLIDE_TEMPLATES.html#fade-in---left-column-first-right-column-with-image-second-2",
    "title": "slide templates",
    "section": "Fade In - Left Column First, Right Column (with image second)",
    "text": "Fade In - Left Column First, Right Column (with image second)\n\n\n\nText 1.\nText 2"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#colored-text",
    "href": "lectures/SLIDE_TEMPLATES.html#colored-text",
    "title": "slide templates",
    "section": "Colored text",
    "text": "Colored text\n\nShow this word in red.\nShow this word in blue.\nShow this word in green."
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#probabilities",
    "href": "lectures/SLIDE_TEMPLATES.html#probabilities",
    "title": "slide templates",
    "section": "Probabilities",
    "text": "Probabilities"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#section-3",
    "href": "lectures/SLIDE_TEMPLATES.html#section-3",
    "title": "slide templates",
    "section": "",
    "text": "Text 1\nText 2\nText 3"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#slide-with-plot-and-padding",
    "href": "lectures/SLIDE_TEMPLATES.html#slide-with-plot-and-padding",
    "title": "slide templates",
    "section": "Slide with Plot and Padding",
    "text": "Slide with Plot and Padding"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#kaiser-health-insurance-quiz",
    "href": "lectures/SLIDE_TEMPLATES.html#kaiser-health-insurance-quiz",
    "title": "slide templates",
    "section": "Kaiser Health Insurance Quiz",
    "text": "Kaiser Health Insurance Quiz"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#embed-a-youtube-video",
    "href": "lectures/SLIDE_TEMPLATES.html#embed-a-youtube-video",
    "title": "slide templates",
    "section": "Embed a Youtube Video",
    "text": "Embed a Youtube Video"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#re-size-tables-before-re-sizing",
    "href": "lectures/SLIDE_TEMPLATES.html#re-size-tables-before-re-sizing",
    "title": "slide templates",
    "section": "Re-size tables – Before re-sizing",
    "text": "Re-size tables – Before re-sizing\n\n\n\n\n\n\n\n\n\nType of study\nMeasurement/Valuation of costs both alternative\nIdentification of consequences\nMeasurement / valuation of consequences\n\n\n\n\nCost analysis\nMonetary units\nNone\nNone\n\n\nCost-effectiveness analysis\nMonetary units\nSingle effect of interest, common to both alternatives, but achieved to different degrees.\nNatural units (e.g., life-years gained, disability days saved, points of blood pressure reduction, etc.)\n\n\nCost-utility analysis\nMonetary units\nSingle or multiple effects, not necessarily common to both alternatives.\nHealthy years (typically measured as quality-adjusted life-years)\n\n\nCost-benefit analysis\nMonetary units\nSingle or multiple effects, not necessarily common to both alternatives\nMonetary units"
  },
  {
    "objectID": "lectures/SLIDE_TEMPLATES.html#re-size-tables-after-re-sizing",
    "href": "lectures/SLIDE_TEMPLATES.html#re-size-tables-after-re-sizing",
    "title": "slide templates",
    "section": "Re-size tables – After re-sizing",
    "text": "Re-size tables – After re-sizing\n\n\n\n\n\n\n\n\n\n\nType of study\nMeasurement/Valuation of costs both alternative\nIdentification of consequences\nMeasurement / valuation of consequences\n\n\n\n\nCost analysis\nMonetary units\nNone\nNone\n\n\nCost-effectiveness analysis\nMonetary units\nSingle effect of interest, common to both alternatives, but achieved to different degrees.\nNatural units (e.g., life-years gained, disability days saved, points of blood pressure reduction, etc.)\n\n\nCost-utility analysis\nMonetary units\nSingle or multiple effects, not necessarily common to both alternatives.\nHealthy years (typically measured as quality-adjusted life-years)\n\n\nCost-benefit analysis\nMonetary units\nSingle or multiple effects, not necessarily common to both alternatives\nMonetary units"
  },
  {
    "objectID": "lectures/exercise_structure.html",
    "href": "lectures/exercise_structure.html",
    "title": "Structuring the Markov Model: Group Exercise",
    "section": "",
    "text": "H\n\n Asympomatic (A)   \n\nH-&gt;H\n\n    \n\nS\n\n Progressive Disease (P)   \n\nH-&gt;S\n\n    \n\nDb\n\n Death from other causes (Db)   \n\nH-&gt;Db\n\n    \n\nS-&gt;S\n\n    \n\nS-&gt;Db\n\n    \n\nDd\n\n Death from disease (Dd)   \n\nS-&gt;Dd\n\n    \n\nDb-&gt;Db\n\n    \n\nDd-&gt;Dd"
  },
  {
    "objectID": "lectures/exercise_structure.html#model-diagram",
    "href": "lectures/exercise_structure.html#model-diagram",
    "title": "Structuring the Markov Model: Group Exercise",
    "section": "",
    "text": "H\n\n Asympomatic (A)   \n\nH-&gt;H\n\n    \n\nS\n\n Progressive Disease (P)   \n\nH-&gt;S\n\n    \n\nDb\n\n Death from other causes (Db)   \n\nH-&gt;Db\n\n    \n\nS-&gt;S\n\n    \n\nS-&gt;Db\n\n    \n\nDd\n\n Death from disease (Dd)   \n\nS-&gt;Dd\n\n    \n\nDb-&gt;Db\n\n    \n\nDd-&gt;Dd"
  },
  {
    "objectID": "lectures/exercise_structure.html#natural-history-parameters",
    "href": "lectures/exercise_structure.html#natural-history-parameters",
    "title": "Structuring the Markov Model: Group Exercise",
    "section": "Natural History Parameters",
    "text": "Natural History Parameters\n\nProgressive disease incidence rate (r_AP): 0.4 over 10 years\nBackground mortality rate (r_Db): 0.006 per year\nHazard rate of death from progressive disease relative to background mortality (HR_PDd): 3.0"
  },
  {
    "objectID": "lectures/exercise_structure.html#strategy-a-preventive-measure",
    "href": "lectures/exercise_structure.html#strategy-a-preventive-measure",
    "title": "Structuring the Markov Model: Group Exercise",
    "section": "Strategy A: Preventive Measure",
    "text": "Strategy A: Preventive Measure\n\nRelative risk of developing progressive disease (RR_AP): 0.75"
  },
  {
    "objectID": "lectures/exercise_structure.html#strategy-b-disease-treatment",
    "href": "lectures/exercise_structure.html#strategy-b-disease-treatment",
    "title": "Structuring the Markov Model: Group Exercise",
    "section": "Strategy B: Disease Treatment",
    "text": "Strategy B: Disease Treatment\n\nOdds-ratio of death from progressive disease (OR_PDd): 0.80\nBaseline annual probability of death in underlying clinical trial (p0_OR_PDd): 0.03"
  },
  {
    "objectID": "lectures/exercise_structure.html#strategy-c-cure",
    "href": "lectures/exercise_structure.html#strategy-c-cure",
    "title": "Structuring the Markov Model: Group Exercise",
    "section": "Strategy C: Cure",
    "text": "Strategy C: Cure\n\n10-year disease remission rate (i.e., return to asymptomatic state; r_PA_trtC): 0.50"
  },
  {
    "objectID": "lectures/exercise_structure.html#parameter-table",
    "href": "lectures/exercise_structure.html#parameter-table",
    "title": "Structuring the Markov Model: Group Exercise",
    "section": "Parameter Table",
    "text": "Parameter Table\n\n\n\n\n\n\n\n\n\nParameter\nDescription\nValue\n\n\n\n\nr_AP\n10-year progressive disease incidence rate\n0.40\n\n\nr_Db\nBackground mortality rate\n0.006\n\n\nHR_PDd\nHazard rate of death from progressive disease relative to background mortality\n3.0\n\n\nRR_AP\nRelative risk of developing progressive disease (Strategy A)\n0.75\n\n\nOR_PDd\nOdds-ratio of death from progressive disease (Strategy B)\n0.80\n\n\np0_OR_PDd\nBaseline probability of death in underlying clinical trial (Strategy B)\n0.03\n\n\nr_PA_trtC\n10-year disease remission rate (Strategy C)\n0.50\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(Matrix)\n\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nr_AP &lt;- 0.40\nr_Db &lt;- 0.006\nHR_PDd &lt;- 3.0\nRR_AP &lt;- 0.75\nOR_PDd &lt;- 0.80\np0_OR_PDd &lt;- 0.03\nr_PA_trtC &lt;- 0.50\n\nm_R0 &lt;- m_RA &lt;- m_RB &lt;- m_RC &lt;-   \n  matrix(0, nrow=4, ncol = 4, dimnames=list(c(\"Asymptomatic\",\"Progressive Disease\",\"Disease Mortality\", \"Background Mortality\"),\n                                               c(\"Asymptomatic\",\"Progressive Disease\",\"Disease Mortality\", \"Background Mortality\")))\n\n# Step 1: Natural History  (i.e., m_R0 and m_P0)\n\nm_R0[\"Asymptomatic\",\"Asymptomatic\"] &lt;- -(r_AP/10+r_Db)\nm_R0[\"Asymptomatic\",\"Progressive Disease\"] &lt;- r_AP/10\nm_R0[\"Asymptomatic\",\"Background Mortality\"] &lt;- r_Db\n\nm_R0[\"Progressive Disease\",\"Progressive Disease\"] &lt;- -(HR_PDd * r_Db + r_Db)\nm_R0[\"Progressive Disease\",\"Disease Mortality\"] &lt;- HR_PDd * r_Db\nm_R0[\"Progressive Disease\",\"Background Mortality\"] &lt;- r_Db\n\nm_P0 &lt;- expm(m_R0)\nm_P0[is.na(m_P0)] &lt;- 0\n\n# Strategy A\n\nm_PA &lt;- m_P0 \nm_PA[\"Asymptomatic\",\"Progressive Disease\"] &lt;- RR_AP * m_P0[\"Asymptomatic\",\"Progressive Disease\"] \nm_PA[\"Asymptomatic\",\"Asymptomatic\"] &lt;- 1 - m_PA[\"Asymptomatic\",\"Progressive Disease\"]  - m_PA[\"Asymptomatic\",\"Disease Mortality\"] - m_PA[\"Asymptomatic\",\"Background Mortality\"]\n\n# Strategy B\nm_PB &lt;- m_P0 \nm_PB[\"Progressive Disease\",\"Disease Mortality\"] &lt;- (OR_PDd / (1 - p0_OR_PDd + (p0_OR_PDd *OR_PDd  ))) * m_PB[\"Progressive Disease\",\"Disease Mortality\"]\nm_PB[\"Progressive Disease\",\"Progressive Disease\"] &lt;- 1 - m_PB[\"Progressive Disease\",\"Asymptomatic\"] - m_PB[\"Progressive Disease\",\"Disease Mortality\"] - m_PB[\"Progressive Disease\",\"Background Mortality\"]\n\n# Strategy C\n\nm_RC &lt;- m_R0 \nm_RC[\"Progressive Disease\",\"Asymptomatic\"]  &lt;- (r_PA_trtC/10)\nm_RC[\"Progressive Disease\",\"Progressive Disease\"] &lt;- -(m_RC[\"Progressive Disease\",\"Asymptomatic\"] + m_RC[\"Progressive Disease\",\"Disease Mortality\"] + m_RC[\"Progressive Disease\",\"Background Mortality\"])\nm_PC &lt;- expm(m_RC)"
  },
  {
    "objectID": "lectures/exercise_structure.html#key",
    "href": "lectures/exercise_structure.html#key",
    "title": "Structuring the Markov Model: Group Exercise",
    "section": "Key",
    "text": "Key\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells\n\n\n\n\ncolor_lut &lt;- \n  c(\"rate\" = \"#ff498c\",\n    \"hazard_ratio\" = \"#fcb08a\",\n    \"probability\" = \"#ffc922\",\n    \"relative_risk\" = \"#cdea24\", \n    \"odds_ratio\" = \"#9dd8da\", \n    \"constructed\" = \"#ab59cf\")"
  },
  {
    "objectID": "lectures/exercise_structure.html#goal-natural-history-transition-probability-matrix",
    "href": "lectures/exercise_structure.html#goal-natural-history-transition-probability-matrix",
    "title": "Structuring the Markov Model: Group Exercise",
    "section": "Goal: Natural History Transition Probability Matrix",
    "text": "Goal: Natural History Transition Probability Matrix\nm_P0 =\n\n\n\n\n\n\n\n\n\n\n\n\nAsymptomatic\nProgressive Disease\nDisease Mortality\nBackground Mortality\n\n\n\n\nAsymptomatic\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nProgressive Disease\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nDisease Mortality\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nBackground Mortality\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\n\n\n\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells"
  },
  {
    "objectID": "lectures/lec_structure.html",
    "href": "lectures/lec_structure.html",
    "title": "5. Structuring the Markov Model",
    "section": "",
    "text": "library(knitr)\nlibrary(kableExtra)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.2.1     ✔ dplyr   1.1.1\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::group_rows() masks kableExtra::group_rows()\n✖ dplyr::lag()        masks stats::lag()\n\n\n\n\n\n\nUnderstand differences between rates and probabilities, hazard rates, relative risks, and other relevant model inputs.\nUnderstand rate-to-probability conversion formulas and competing rates.\nEmbedding a continuous transition rate matrix into a discrete timestep resulting in a transition probability matrix.\nEmbedding of non-stationary rates as a function of time.\nUnderstand additional non-Markovian components: accumulators, tunnel states."
  },
  {
    "objectID": "lectures/lec_structure.html#learning-objectives",
    "href": "lectures/lec_structure.html#learning-objectives",
    "title": "5. Structuring the Markov Model",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\n\nUnderstand differences between rates and probabilities, hazard rates, relative risks, and other relevant model inputs.\nUnderstand rate-to-probability conversion formulas and competing rates.\nEmbedding a continuous transition rate matrix into a discrete timestep resulting in a transition probability matrix.\nEmbedding of non-stationary rates as a function of time.\nUnderstand additional non-Markovian components: accumulators, tunnel states."
  },
  {
    "objectID": "lectures/lec_structure.html#goal",
    "href": "lectures/lec_structure.html#goal",
    "title": "5. Structuring the Markov Model",
    "section": "Goal",
    "text": "Goal"
  },
  {
    "objectID": "lectures/lec_structure.html#what-never-happens",
    "href": "lectures/lec_structure.html#what-never-happens",
    "title": "5. Structuring the Markov Model",
    "section": "What Never Happens",
    "text": "What Never Happens"
  },
  {
    "objectID": "lectures/lec_structure.html#problem",
    "href": "lectures/lec_structure.html#problem",
    "title": "5. Structuring the Markov Model",
    "section": "Problem",
    "text": "Problem\n\nNeed transition probabilities but literature-based parameters are reported as:\n\n\n\nRates\nHazard ratios\nOdds ratios\nRelative risks\nTransition probabilities (rare!)"
  },
  {
    "objectID": "lectures/lec_structure.html#solution",
    "href": "lectures/lec_structure.html#solution",
    "title": "5. Structuring the Markov Model",
    "section": "Solution",
    "text": "Solution\n\n\nNeed “common ground” where we can combine and transform different model inputs.\nThis “common ground” is often found in a transition rate matrix."
  },
  {
    "objectID": "lectures/lec_structure.html#solution-1",
    "href": "lectures/lec_structure.html#solution-1",
    "title": "5. Structuring the Markov Model",
    "section": "Solution",
    "text": "Solution"
  },
  {
    "objectID": "lectures/lec_structure.html#solution-2",
    "href": "lectures/lec_structure.html#solution-2",
    "title": "5. Structuring the Markov Model",
    "section": "Solution",
    "text": "Solution"
  },
  {
    "objectID": "lectures/lec_structure.html#solution-3",
    "href": "lectures/lec_structure.html#solution-3",
    "title": "5. Structuring the Markov Model",
    "section": "Solution",
    "text": "Solution"
  },
  {
    "objectID": "lectures/lec_structure.html#solution-4",
    "href": "lectures/lec_structure.html#solution-4",
    "title": "5. Structuring the Markov Model",
    "section": "Solution",
    "text": "Solution"
  },
  {
    "objectID": "lectures/lec_structure.html#transition-rate-matrix",
    "href": "lectures/lec_structure.html#transition-rate-matrix",
    "title": "5. Structuring the Markov Model",
    "section": "Transition Rate Matrix",
    "text": "Transition Rate Matrix\n\n\nThe central “hub” of a Markov model.\nStraightforward to convert rate matrix into a transition probability matrix.\nCan be used to change the cycle length.\nFacilitates modeling using alternative techniques:\n\nContinuous time Markov\nDiscrete event simulation\nMicrosimulation"
  },
  {
    "objectID": "lectures/lec_structure.html#four-step-process",
    "href": "lectures/lec_structure.html#four-step-process",
    "title": "5. Structuring the Markov Model",
    "section": "Four-Step Process",
    "text": "Four-Step Process\n\n\nUse data inputs/published literature to define a rate matrix \\(\\mathbf{R}\\).\nMake strategy-specific adjustments to \\(\\mathbf{R}\\) as needed.\n“Embed” the transition probability matrix using the rate matrix\nMake further overall or strategy-specific adjustments to \\(\\mathbf{P}\\) as needed."
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities",
    "text": "Rates vs. Probabilities\n\n\nRate: number of occurrences of an event per unit of time. These are additive and subtractive–i.e. simple algebra for manipulation.\nProbability: Likelihood that an event will occur for an in individual over a defined time period.\nMajor difference is in denominator: rates take into account time at risk while probabilities do not."
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities-1",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities-1",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities",
    "text": "Rates vs. Probabilities"
  },
  {
    "objectID": "lectures/lec_structure.html#rates",
    "href": "lectures/lec_structure.html#rates",
    "title": "5. Structuring the Markov Model",
    "section": "Rates",
    "text": "Rates\n\n\nNumber of events divided by the total time at risk experienced by all people followed.\nRanges from 0 to \\(\\infty\\).\n\\(\\frac{\\# \\text{events in time period}}{\\text{Total time period experienced by all subjects followed}}\\)"
  },
  {
    "objectID": "lectures/lec_structure.html#rates-1",
    "href": "lectures/lec_structure.html#rates-1",
    "title": "5. Structuring the Markov Model",
    "section": "Rates",
    "text": "Rates"
  },
  {
    "objectID": "lectures/lec_structure.html#probabilities",
    "href": "lectures/lec_structure.html#probabilities",
    "title": "5. Structuring the Markov Model",
    "section": "Probabilities",
    "text": "Probabilities"
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities-example1",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities-example1",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities: Example1",
    "text": "Rates vs. Probabilities: Example1\n\n\nSuppose a study followed 100 people with congestive heart failure for 4 years.\nAt the end of 4 years, 40 had died.\nThe probability of death over 4 years is \\(40/100=0.40\\).\n\n\nSource: Gidwani and Russell (2020)"
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities-example2",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities-example2",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities: Example1",
    "text": "Rates vs. Probabilities: Example1\n\n\nA rate takes into acccount the time each person was at risk.\nThe 60 who survived were at risk the entire 4 years and contributed \\(60 \\times 4 = 240\\) years at risk.\nOnce a person dies, he/she is no longer at risk.\n\n\nSource: Gidwani and Russell (2020)"
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities-example3",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities-example3",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities: Example1",
    "text": "Rates vs. Probabilities: Example1\n\n\nWhen a study does not report time at risk, the conventional assumption is that the events were spread evenly over the time period.\nUsing this assumption, the average time at risk for the 40 who died was 2 years, adding 40 × 2 = 80 years at risk.\n\n\nSource: Gidwani and Russell (2020)"
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities-example4",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities-example4",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities: Example1",
    "text": "Rates vs. Probabilities: Example1\n\n\nTotal time at risk for the cohort of 100 people is 320 person-years (240+80).\nThus, the rate of death from CHF is 40/320 = 0.125 deaths per person-year.\nLet’s now construct a rate matrix with three states: CHF, Death from CHF, and Death from other causes.\n\n\nSource: Gidwani and Russell (2020)"
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities-example",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities-example",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities: Example",
    "text": "Rates vs. Probabilities: Example\n\n\n0.125 per person year is the rate we’d enter into our rate matrix.\nWe could also think of a separate death rate from background causes (e.g., 0.006 per person-year).1\n\n\nThis often comes from separate vital statistics / life-table data sources."
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities-example-1",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities-example-1",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities: Example",
    "text": "Rates vs. Probabilities: Example\n\n\n\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n0\n0.125\n0.006\n\n\nD_CHF\n0\n0.000\n0.000\n\n\nD_OTH\n0\n0.000\n0.000"
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities-example-2",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities-example-2",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities: Example",
    "text": "Rates vs. Probabilities: Example\n\n\n\n\nThe diagonal elements in a rate matrix are just the negative sum of the off-diagonal elements. (Markovian)\nIn this example, the diagonal value for the 1st row would be -0.131 = -(0.125+0.006)\nWe can leave all other rate matrix values at 0 because the rate of progression from death to other states is zero.\n\n\n\n\n\n\n\n\n\n\nCHF\nDeath_CHF\nDeath_Other\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nDeath_CHF\n0\n0.000\n0.000\n\n\nDeath_Other\n0\n0.000\n0.000"
  },
  {
    "objectID": "lectures/lec_structure.html#rates-vs.-probabilities-example-3",
    "href": "lectures/lec_structure.html#rates-vs.-probabilities-example-3",
    "title": "5. Structuring the Markov Model",
    "section": "Rates vs. Probabilities: Example",
    "text": "Rates vs. Probabilities: Example\n\n\n\n\nThe diagonal elements in a rate matrix are just the negative sum of the off-diagonal elements.\nIn this example, the diagonal value for the 1st row would be -0.131 = -(0.125+0.006)\nWe can leave all other rate matrix values at 0 because the rate of progression from death to other states is zero.\n\n\n\n\n\n\n\n\n\n\nCHF\nDeath_CHF\nDeath_Other\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nDeath_CHF\n0\n0.000\n0.000\n\n\nDeath_Other\n0\n0.000\n0.000"
  },
  {
    "objectID": "lectures/lec_structure.html#summary-rates-vs.-probabilities",
    "href": "lectures/lec_structure.html#summary-rates-vs.-probabilities",
    "title": "5. Structuring the Markov Model",
    "section": "Summary: Rates vs. Probabilities",
    "text": "Summary: Rates vs. Probabilities\n\n\n\n\n\n\n\n\n\n\nStatistic\nEvaluates\nRange\nApplicable Domain\n\n\n\n\nRate\n\\(\\frac{\\# \\text{events in time period}}{\\text{Total time period experienced by all subjects followed}}\\)\n0 to \\(\\infty\\)\nRate matrix\n\n\nProbability/risk\n\\(\\frac{\\# \\text{events in time period}}{\\# \\text{people followed for time period}}\\)\n0-1\nProbability matrix"
  },
  {
    "objectID": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.",
    "href": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.",
    "title": "5. Structuring the Markov Model",
    "section": "1. Place rates in a rate matrix \\(\\mathbf{R}\\).",
    "text": "1. Place rates in a rate matrix \\(\\mathbf{R}\\)."
  },
  {
    "objectID": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.-1",
    "href": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.-1",
    "title": "5. Structuring the Markov Model",
    "section": "1. Place rates in a rate matrix \\(\\mathbf{R}\\).",
    "text": "1. Place rates in a rate matrix \\(\\mathbf{R}\\).\n\n\n\n\nCountry/region-specific background mortality rate (0.006)\nDisease mortality rates from existing population-based epidemiological study. (e.g., 0.125 = 40 cases per 320 person-years)\nDiagonal value that is the negative sum of the off-diagonal values in each row (-0.131).\n\n\n\n\n“Natural History” (i.e., “do nothing”) rate matrix:\n\n\n\n\n\n\nCHF\nDeath_CHF\nDeath_Other\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nDeath_CHF\n0.000\n0.000\n0.000\n\n\nDeath_Other\n0.000\n0.000\n0.000"
  },
  {
    "objectID": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.-2",
    "href": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.-2",
    "title": "5. Structuring the Markov Model",
    "section": "1. Place rates in a rate matrix \\(\\mathbf{R}\\).",
    "text": "1. Place rates in a rate matrix \\(\\mathbf{R}\\).\n\n\nWhat we have just done is contruct a rate matrix for a “natural history” model of the disease (CHF).\nThis is a version of the model in which we allow the disease process to play out naturally, with no further intervention.\nSometimes called a “do nothing” strategy."
  },
  {
    "objectID": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.-3",
    "href": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.-3",
    "title": "5. Structuring the Markov Model",
    "section": "1. Place rates in a rate matrix \\(\\mathbf{R}\\).",
    "text": "1. Place rates in a rate matrix \\(\\mathbf{R}\\).\n\n\nThe “natural history” model is useful because it can help us verify that the model matches what we see in the “real world.”\nThe “natural history” model also can be used to calibrate transition rates to different countries/contexts.\nFor example, we could recalibrate the model so the CHF mortality transition rate matches our country-specific data."
  },
  {
    "objectID": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.-4",
    "href": "lectures/lec_structure.html#place-rates-in-a-rate-matrix-mathbfr.-4",
    "title": "5. Structuring the Markov Model",
    "section": "1. Place rates in a rate matrix \\(\\mathbf{R}\\).",
    "text": "1. Place rates in a rate matrix \\(\\mathbf{R}\\).\n\n\nAlternatively, suppose we “borrow” a model developed in another country/context.\nThat model will be based on underlying rates specific to that context.\nThe underlying rate matrix can be used to “swap in” transition rates that apply to our country/context.\n\nExample: change the background mortality rate to match you country’s."
  },
  {
    "objectID": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.",
    "href": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.",
    "title": "5. Structuring the Markov Model",
    "section": "2. Make adjustments to \\(\\mathbf{R}\\) as needed.",
    "text": "2. Make adjustments to \\(\\mathbf{R}\\) as needed."
  },
  {
    "objectID": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.-1",
    "href": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.-1",
    "title": "5. Structuring the Markov Model",
    "section": "2. Make adjustments to \\(\\mathbf{R}\\) as needed.",
    "text": "2. Make adjustments to \\(\\mathbf{R}\\) as needed.\n\n\n\n\nSuppose that a new strategy can reduces the risk of CHF mortality by 20% (i.e., hazard ratio = 0.8).\nWe can simply apply this hazard ratio directly to construct a rate matrix for strategy A.\nFor the Strategy A rate matrix, the rate of CHF death is \\(0.8 * 0.125 = 0.1\\)\nMake sure that the diagonal element is adjusted to account for this change!\n\n\n\n\n“Natural History” rate matrix\n\n\n\n\n\n\nCHF\nDeath_CHF\nDeath_Other\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nDeath_CHF\n0.000\n0.000\n0.000\n\n\nDeath_Other\n0.000\n0.000\n0.000"
  },
  {
    "objectID": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.-2",
    "href": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.-2",
    "title": "5. Structuring the Markov Model",
    "section": "2. Make adjustments to \\(\\mathbf{R}\\) as needed.",
    "text": "2. Make adjustments to \\(\\mathbf{R}\\) as needed.\n\n\n\n\nSuppose that a new strategy can reduces the risk of CHF mortality by 20% (i.e., hazard ratio = 0.8).\nWe can simply apply this hazard ratio directly to construct a rate matrix for strategy A.\nFor the Strategy A rate matrix, the rate of CHF death is \\(0.8 * 0.125 = 0.1\\)\nMake sure that the diagonal element is adjusted to account for this change!\n\n\n\n\n“Natural History” rate matrix\n\n\n\n\n\n\nCHF\nDeath_CHF\nDeath_Other\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nDeath_CHF\n0.000\n0.000\n0.000\n\n\nDeath_Other\n0.000\n0.000\n0.000\n\n\n\n\n\n\n\n“Strategy A” rate matrix\n\n\n\n\n\n\nCHF\nDeath_CHF\nDeath_Other\n\n\n\n\nCHF\n-0.106\n0.1\n0.006\n\n\nDeath_CHF\n0\n0\n0.000\n\n\nDeath_Other\n0\n0\n0.000"
  },
  {
    "objectID": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.-3",
    "href": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.-3",
    "title": "5. Structuring the Markov Model",
    "section": "2. Make adjustments to \\(\\mathbf{R}\\) as needed.",
    "text": "2. Make adjustments to \\(\\mathbf{R}\\) as needed.\n\n\n\n\nAnother adjustment we could make at this stage is the time cycle length.\nSuppose our rate matrix is defined in terms of a one-year time cycle, but we want to convert to a monthly cycle.\nIn that event, we’d simply divide each rate in the matrix by 12, and the resulting matrix would be for a monthly timestep.\n\n\n\n\n“Natural History” rate matrix (one-year timestep)\n\n\n\n\n\n\nCHF\nDeath_CHF\nDeath_Other\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nDeath_CHF\n0.000\n0.000\n0.000\n\n\nDeath_Other\n0.000\n0.000\n0.000"
  },
  {
    "objectID": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.-4",
    "href": "lectures/lec_structure.html#make-adjustments-to-mathbfr-as-needed.-4",
    "title": "5. Structuring the Markov Model",
    "section": "2. Make adjustments to \\(\\mathbf{R}\\) as needed.",
    "text": "2. Make adjustments to \\(\\mathbf{R}\\) as needed.\n\n\n\nAnother adjustment we could make at this stage is the time cycle length.\nSuppose our rate matrix is defined in terms of a one-year time cycle, but we want to convert to a monthly cycle.\nIn that event, we’d simply divide each rate in the matrix by 12, and the resulting matrix would be for a monthly timestep.\n\n\n\n“Natural History” rate matrix (one-year timestep)\n\n\n\n\n\n\nCHF\nDeath_CHF\nDeath_Other\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nDeath_CHF\n0.000\n0.000\n0.000\n\n\nDeath_Other\n0.000\n0.000\n0.000\n\n\n\n\n\n\n\n“Natural History” rate matrix (one-month timestep)\n\n\n\n\n\n\nCHF\nDeath_CHF\nDeath_Other\n\n\n\n\nCHF\n-0.0109\n0.0104\n5e-04\n\n\nDeath_CHF\n0\n0\n0\n\n\nDeath_Other\n0\n0\n0"
  },
  {
    "objectID": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix",
    "href": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix",
    "title": "5. Structuring the Markov Model",
    "section": "3. “Embed” the transition probability matrix using the rate matrix",
    "text": "3. “Embed” the transition probability matrix using the rate matrix"
  },
  {
    "objectID": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-1",
    "href": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-1",
    "title": "5. Structuring the Markov Model",
    "section": "3. “Embed” the transition probability matrix using the rate matrix",
    "text": "3. “Embed” the transition probability matrix using the rate matrix\n\n\nOur next step is to convert the transition rate matrix into a transition probability matrix.\nCommon practice is to use rate-to-probability conversion formulas"
  },
  {
    "objectID": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-2",
    "href": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-2",
    "title": "5. Structuring the Markov Model",
    "section": "3. “Embed” the transition probability matrix using the rate matrix",
    "text": "3. “Embed” the transition probability matrix using the rate matrix\n\nOur next step is to convert the transition rate matrix into a transition probability matrix.\nCommon practice is to use rate-to-probability conversion formulas\n\n\\[\np = 1 - \\exp(-rt)\n\\] where \\(r\\) is the rate and \\(t\\) is the time-step."
  },
  {
    "objectID": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-3",
    "href": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-3",
    "title": "5. Structuring the Markov Model",
    "section": "3. “Embed” the transition probability matrix using the rate matrix",
    "text": "3. “Embed” the transition probability matrix using the rate matrix\n\n\nThis formula works fine when there is only one possible state an individual can transition to.\nThe formula will not calculate the correct transition probability if there are two or more states someone can transition to.\nSee the workshop blog posting for more."
  },
  {
    "objectID": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-4",
    "href": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-4",
    "title": "5. Structuring the Markov Model",
    "section": "3. “Embed” the transition probability matrix using the rate matrix",
    "text": "3. “Embed” the transition probability matrix using the rate matrix\n\n\nWe will cover two approaches for constructing a transition probability matrix.\nThe first is technically incorrect, but is widely used and easier to implement because it ignores compound transitions (i.e., multiple transitions within a cycle)."
  },
  {
    "objectID": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-5",
    "href": "lectures/lec_structure.html#embed-the-transition-probability-matrix-using-the-rate-matrix-5",
    "title": "5. Structuring the Markov Model",
    "section": "3. “Embed” the transition probability matrix using the rate matrix",
    "text": "3. “Embed” the transition probability matrix using the rate matrix\nThe two approaches\n\n\n\n3a. Construct a transition probability matrix using rate-to-probability conversion formulas.\n3b. Embed the transition probability matrix using the rate matrix exponential (i.e., \\(\\mathbf{P}=e^{\\mathbf{R}}\\))."
  },
  {
    "objectID": "lectures/lec_structure.html#a.-rate-to-probability-conversion",
    "href": "lectures/lec_structure.html#a.-rate-to-probability-conversion",
    "title": "5. Structuring the Markov Model",
    "section": "3a. Rate-to-probability conversion",
    "text": "3a. Rate-to-probability conversion\nThe probability of transitioning from health state \\(A\\) to health state \\(B\\) is:\n\\[\np_{AB}= \\frac{r_{AB}}{\\sum_S r_{AS}}\\big ( 1 - e^{-(\\sum_S r_{AS}) t}\\big )\n\\] where \\(S\\) captures all the health states (i.e., columns) in the transition rate matrix, and \\(t\\) is the time-step (e.g., \\(t=1\\) if 1 year, \\(t=1/12\\) if one month, etc.)."
  },
  {
    "objectID": "lectures/lec_structure.html#a.-rate-to-probability-conversion-1",
    "href": "lectures/lec_structure.html#a.-rate-to-probability-conversion-1",
    "title": "5. Structuring the Markov Model",
    "section": "3a. Rate-to-probability conversion",
    "text": "3a. Rate-to-probability conversion\nLet’s build on our chronic heart failure example from earlier. Here is the transition rate matrix we constructed:\n\n\n\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nD_CHF\n0.000\n0.000\n0.000\n\n\nD_OTH\n0.000\n0.000\n0.000"
  },
  {
    "objectID": "lectures/lec_structure.html#a.-rate-to-probability-conversion-2",
    "href": "lectures/lec_structure.html#a.-rate-to-probability-conversion-2",
    "title": "5. Structuring the Markov Model",
    "section": "3a. Rate-to-probability conversion",
    "text": "3a. Rate-to-probability conversion\nLet’s now calculate the probability of transitioning from the CHF state to D_CHF (death from heart failure)."
  },
  {
    "objectID": "lectures/lec_structure.html#a.-rate-to-probability-conversion-3",
    "href": "lectures/lec_structure.html#a.-rate-to-probability-conversion-3",
    "title": "5. Structuring the Markov Model",
    "section": "3a. Rate-to-probability conversion",
    "text": "3a. Rate-to-probability conversion\nAnnual probability of transitioning from CHF to death from CHF:\n\\[\np_{\\text{CHF,D_CHF}}= \\frac{r_{\\text{CHF,D_CHF}}}{r_{\\text{CHF,D_CHF}} + r_{\\text{CHF,D_OTH}}}\\big ( 1 - e^{-(r_{\\text{CHF,D_CHF}} + r_{\\text{CHF,D_OTH}}) \\times 1}\\big )\n\\]\nWe can find each of these rates in our transition rate matrix…"
  },
  {
    "objectID": "lectures/lec_structure.html#a.-rate-to-probability-conversion-4",
    "href": "lectures/lec_structure.html#a.-rate-to-probability-conversion-4",
    "title": "5. Structuring the Markov Model",
    "section": "3a. Rate-to-probability conversion",
    "text": "3a. Rate-to-probability conversion\nAnnual probability of transitioning from CHF to death from CHF:\n\\[\np_{\\text{CHF,D_CHF}}= \\frac{\\color{red}{0.125}}{\\color{red}{0.125}+\\color{green}{0.006}}\\big ( 1 - e^{-(\\color{red}{0.125}+\\color{green}{0.006}) \\times 1}\\big ) = 0.1172\n\\]\n\n\n\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nD_CHF\n0.000\n0\n0\n\n\nD_OTH\n0.000\n0\n0"
  },
  {
    "objectID": "lectures/lec_structure.html#a.-rate-to-probability-conversion-5",
    "href": "lectures/lec_structure.html#a.-rate-to-probability-conversion-5",
    "title": "5. Structuring the Markov Model",
    "section": "3a. Rate-to-probability conversion",
    "text": "3a. Rate-to-probability conversion\nLet’s now calculate the probability of transitioning from the CHF state to D_OTH (death from other causes)."
  },
  {
    "objectID": "lectures/lec_structure.html#a.-rate-to-probability-conversion-6",
    "href": "lectures/lec_structure.html#a.-rate-to-probability-conversion-6",
    "title": "5. Structuring the Markov Model",
    "section": "3a. Rate-to-probability conversion",
    "text": "3a. Rate-to-probability conversion\nAnnual probability of transitioning from CHF to death from other causes:\n\\[\np_{\\text{CHF,D_CHF}}= \\frac{\\color{green}{0.006}}{\\color{red}{0.125}+\\color{green}{0.006}}\\big ( 1 - e^{-(\\color{red}{0.125}+\\color{green}{0.006}) \\times 1}\\big ) = 0.00562\n\\]\n\n\n\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n-0.131\n0.125\n0.006\n\n\nD_CHF\n0.000\n0\n0\n\n\nD_OTH\n0.000\n0\n0"
  },
  {
    "objectID": "lectures/lec_structure.html#a.-rate-to-probability-conversion-7",
    "href": "lectures/lec_structure.html#a.-rate-to-probability-conversion-7",
    "title": "5. Structuring the Markov Model",
    "section": "3a. Rate-to-probability conversion",
    "text": "3a. Rate-to-probability conversion\n\n\nWe now have the quantities needed to complete the first row of our transition rate matrix.\nRecall that the diagonal elements of the transition probability matrix are just 1 minus the other transition probabilities."
  },
  {
    "objectID": "lectures/lec_structure.html#a.-rate-to-probability-conversion-8",
    "href": "lectures/lec_structure.html#a.-rate-to-probability-conversion-8",
    "title": "5. Structuring the Markov Model",
    "section": "3a. Rate-to-probability conversion",
    "text": "3a. Rate-to-probability conversion\nCalculated transition probability matrix:\n\n\n\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n0.8772\n0.1172\n0.0056\n\n\nD_CHF\n0.0000\n1.0000\n0.0000\n\n\nD_OTH\n0.0000\n0.0000\n1.0000"
  },
  {
    "objectID": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix",
    "href": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix",
    "title": "5. Structuring the Markov Model",
    "section": "3b. Exponentiate the transition rate matrix",
    "text": "3b. Exponentiate the transition rate matrix\n\n\nThe most technically correct approach for “embedding” a transition probability matrix is using the rate matrix exponential.\nThis is a matrix analogue to the cellwise rate-to-probability matrix process we just went through."
  },
  {
    "objectID": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-1",
    "href": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-1",
    "title": "5. Structuring the Markov Model",
    "section": "3b. Exponentiate the transition rate matrix",
    "text": "3b. Exponentiate the transition rate matrix\n\\[\n\\mathbf{P} = e^{\\mathbf{R}}\n\\]"
  },
  {
    "objectID": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-2",
    "href": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-2",
    "title": "5. Structuring the Markov Model",
    "section": "3b. Exponentiate the transition rate matrix",
    "text": "3b. Exponentiate the transition rate matrix\nPros:\n\n\nEmbedding the transition probability matrix in this way ensures that the correct transition probabilities are calculated.\nWithout going into too many details, this approach ensures that some compound transitions are not “hidden” in the Markov cycle.\nThis ensures that our discrete time Markov model accurately represents the underlying continuous time process."
  },
  {
    "objectID": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-3",
    "href": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-3",
    "title": "5. Structuring the Markov Model",
    "section": "3b. Exponentiate the transition rate matrix",
    "text": "3b. Exponentiate the transition rate matrix\nCons:\n\n\nA major drawback is that this approach can create some “jumpover” states that are seemingly inconsistent with the underlying model (see blog for more).\nAccounting for “hidden” transitions and jumpover states requires augmenting the transition probability matrix (again, see blog for details)."
  },
  {
    "objectID": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-4",
    "href": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-4",
    "title": "5. Structuring the Markov Model",
    "section": "3b. Exponentiate the transition rate matrix",
    "text": "3b. Exponentiate the transition rate matrix\nCons, cont’d:\n\n\nExcel does not easily do matrix exponentiation, however you can use an approximation (we’ll do this in a case study).\nModern (free) statistical software can easily exponentiate a matrix:"
  },
  {
    "objectID": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-5",
    "href": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-5",
    "title": "5. Structuring the Markov Model",
    "section": "3b. Exponentiate the transition rate matrix",
    "text": "3b. Exponentiate the transition rate matrix\nCons, cont’d:\n\nExcel does not easily do matrix exponentiation, however you can use an approximation (we’ll do this in a case study).\nModern (free) statistical software can easily exponentiate a matrix:\n\nlibrary(expm)\nm_P = expm(m_R)"
  },
  {
    "objectID": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-6",
    "href": "lectures/lec_structure.html#b.-exponentiate-the-transition-rate-matrix-6",
    "title": "5. Structuring the Markov Model",
    "section": "3b. Exponentiate the transition rate matrix",
    "text": "3b. Exponentiate the transition rate matrix\nFor our chronic heart failure example, the exponentiated matrix yields a very similar answer to the first approach:\n\n\n\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n0.8772\n0.1172\n0.0056\n\n\nD_CHF\n0.0000\n1.0000\n0.0000\n\n\nD_OTH\n0.0000\n0.0000\n1.0000"
  },
  {
    "objectID": "lectures/lec_structure.html#so-where-are-we-now",
    "href": "lectures/lec_structure.html#so-where-are-we-now",
    "title": "5. Structuring the Markov Model",
    "section": "So Where Are We Now?",
    "text": "So Where Are We Now?"
  },
  {
    "objectID": "lectures/lec_structure.html#so-where-are-we-now-1",
    "href": "lectures/lec_structure.html#so-where-are-we-now-1",
    "title": "5. Structuring the Markov Model",
    "section": "So Where Are We Now?",
    "text": "So Where Are We Now?\n\n\nBy constructing our model using the “roots” of a transition rate matrix, we can incorporate disparate sources of information.\nFacilitates country/region-specific background mortality.\nFacilitates standardizing inputs measured at different time intervals."
  },
  {
    "objectID": "lectures/lec_structure.html#so-where-are-we-now-2",
    "href": "lectures/lec_structure.html#so-where-are-we-now-2",
    "title": "5. Structuring the Markov Model",
    "section": "So Where Are We Now?",
    "text": "So Where Are We Now?\n\n\nNot all literature-based parameters operate on transition rates.\nYou will often find that the strategies you want to model have inputs based on odds ratios, relative risks, risk differences, etc."
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued",
    "href": "lectures/lec_structure.html#chf-example-continued",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\n\n\nRecall from earlier that we constructed two transition rate matrices:\n\n“Natural History” rate matrix\nStrategy A (“New Drug”) rate matrix based on a hazard ratio (for CHF mortality) of 0.8."
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued-1",
    "href": "lectures/lec_structure.html#chf-example-continued-1",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\nThese two rate matrices can be used to construct the following transition probability matrices:\n\n\n\nm_P_NH =\n\n\n\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n0.8772\n0.1172\n0.0056\n\n\nD_CHF\n0.0000\n1.0000\n0.0000\n\n\nD_OTH\n0.0000\n0.0000\n1.0000\n\n\n\n\n\n\n\n\nm_P_A =\n\n\n\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n0.8994\n0.0949\n0.0057\n\n\nD_CHF\n0.0000\n1.0000\n0.0000\n\n\nD_OTH\n0.0000\n0.0000\n1.0000"
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued-2",
    "href": "lectures/lec_structure.html#chf-example-continued-2",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\n\n\nNow suppose we wanted to model a second strategy (“B”) based on a randomized trial of another drug.\nThat trial reports an odds ratio (OR) of CHF death of 0.75.\nThe probability of CHF death in the placebo (control) arm in that trial was 0.15.1\n\n\nNote this is slightly higher than the corresponding probability in our natural history transition probability matrix (0.1172), reflecting the fact that randomized trial participants are not necessarily representative of the entire population!"
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued-3",
    "href": "lectures/lec_structure.html#chf-example-continued-3",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\n\n\nAn odds ratio is based on the odds of an outcome happening, which is directly related to the probability.\nOdds = \\(\\frac{\\text{Probability of Outcome}}{1 - \\text{Probability of Outcome}}\\)\nOdds Ratio = \\(\\frac{\\text{Odds of outcome in exposed}}{\\text{Odds of outcome in unexposed}}\\)"
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued-4",
    "href": "lectures/lec_structure.html#chf-example-continued-4",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\n\n\n\n\n\n\nImportant\n\n\nNot all literature-based parameters operate on the rate scale. Some operate on the probability scale!"
  },
  {
    "objectID": "lectures/lec_structure.html#make-adjustments-to-mathbfp-as-needed.",
    "href": "lectures/lec_structure.html#make-adjustments-to-mathbfp-as-needed.",
    "title": "5. Structuring the Markov Model",
    "section": "4. Make adjustments to \\(\\mathbf{P}\\) as needed.",
    "text": "4. Make adjustments to \\(\\mathbf{P}\\) as needed."
  },
  {
    "objectID": "lectures/lec_structure.html#make-adjustments-to-mathbfp-as-needed.-1",
    "href": "lectures/lec_structure.html#make-adjustments-to-mathbfp-as-needed.-1",
    "title": "5. Structuring the Markov Model",
    "section": "4. Make adjustments to \\(\\mathbf{P}\\) as needed.",
    "text": "4. Make adjustments to \\(\\mathbf{P}\\) as needed.\n\n\nConstructing our final transition probability matrix—for natural history or more specifically for for a stratgey under consideration–may require further adjustment.\nWe must be careful about the scale on which these parameters apply.\nOdds ratios, relative risks, and risk differences all operate on the probability scale."
  },
  {
    "objectID": "lectures/lec_structure.html#make-adjustments-to-mathbfp-as-needed.-2",
    "href": "lectures/lec_structure.html#make-adjustments-to-mathbfp-as-needed.-2",
    "title": "5. Structuring the Markov Model",
    "section": "4. Make adjustments to \\(\\mathbf{P}\\) as needed.",
    "text": "4. Make adjustments to \\(\\mathbf{P}\\) as needed.\n\n\n\n\n\n\n\n\n\n\nStatistic\nEvaluates\nRange\nApplicable Domain\n\n\n\n\nRate\n\\(\\frac{\\# \\text{events in time period}}{\\text{Total time period experienced by all subjects followed}}\\)\n0 to \\(\\infty\\)\nRate matrix\n\n\nHazard Ratio\n\\(\\frac{\\text{Hazard rate of outcome in exposed}}{\\text{Hazard rate of outcome in unexposed}}\\)\n0 to \\(\\infty\\)\nRate matrix\n\n\nProbability/risk\n\\(\\frac{\\# \\text{events in time period}}{\\# \\text{people followed for time period}}\\)\n0-1\nProbability matrix\n\n\nOdds\n\\(\\frac{\\text{Probability of Outcome}}{1 - \\text{Probability of Outcome}}\\)\n0 to \\(\\infty\\)\nProbability matrix\n\n\nOdds Ratio\n\\(\\frac{\\text{Odds of outcome in exposed}}{\\text{Odds of outcome in unexposed}}\\)\n0 to \\(\\infty\\)\nProbability matrix\n\n\nRelative Risk\n\\(\\frac{\\text{Probability of outcome in exposed}}{\\text{Probablity of outcome in unexposed}}\\)\n0 to \\(\\infty\\)\nProbability matrix\n\n\nRisk Difference\n\\(\\text{Probability of outcome in exposed}-\\text{Probablity of outcome in unexposed}\\)\n-1 to 1\nProbability matrix"
  },
  {
    "objectID": "lectures/lec_structure.html#make-adjustments-to-mathbfp_s-as-needed.",
    "href": "lectures/lec_structure.html#make-adjustments-to-mathbfp_s-as-needed.",
    "title": "5. Structuring the Markov Model",
    "section": "4. Make adjustments to \\(\\mathbf{P_s}\\) as needed.",
    "text": "4. Make adjustments to \\(\\mathbf{P_s}\\) as needed."
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued-5",
    "href": "lectures/lec_structure.html#chf-example-continued-5",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\nLet’s turn back to our CHF example.\n\n\nSuppose we wanted to model a second strategy (“B”) based on a randomized trial of another drug.\nThat trial reports an odds ratio (OR) of CHF death of 0.75.\nThe probability of CHF death in the placebo (control) arm in that trial was 0.15."
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued-6",
    "href": "lectures/lec_structure.html#chf-example-continued-6",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\n\n\nWe can convert an odds ratio to a relative risk (i.e., ratio of probabilities) if we know the baseline (unexposed) probability of the outcome, \\(p_0\\).\nIn this case we were able to find \\(p_0=0.15\\) in the underlying clinical trial.\nIf we didn’t have this information, we might assume its the same (0.1172) as in our underlying natural history probability matrix1\n\n\nThough note this is an assumption, so we should incorporate a lot of uncertainty around it in our model!"
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued-7",
    "href": "lectures/lec_structure.html#chf-example-continued-7",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\n\n\nWe can convert an odds ratio to a relative risk (RR).1\n\\(RR = \\frac{\\text{Probability of outcome in exposed}}{\\text{Probablity of outcome in unexposed}} = \\frac{p_1}{p_0} = \\frac{OR}{(1-p_0+(p_0 \\times OR))}\\)\nA relative risk is the ratio of the probability of the outcome in the exposed group to the probability of the outcome in the unexposed group.\n\n\nIf the incidence of the outcome is fairly rare (\\(p_0&lt;0.10\\)), you will often see people simply use the OR as a RR. Source for conversion formula: Zhang and Yu (1998)"
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued-8",
    "href": "lectures/lec_structure.html#chf-example-continued-8",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\n\n\n\\(RR = \\frac{p_1}{p_0}\\)\n\\(p_1 = RR \\times p_0\\)\n\\(p_{D_{CHF}} = 0.75 \\times .15 = 0.1125\\)"
  },
  {
    "objectID": "lectures/lec_structure.html#chf-example-continued-9",
    "href": "lectures/lec_structure.html#chf-example-continued-9",
    "title": "5. Structuring the Markov Model",
    "section": "CHF Example, Continued",
    "text": "CHF Example, Continued\n\n\n\n\n\n\n\nm_P =\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n0.8772\n0.1172\n0.0056\n\n\nD_CHF\n0.0000\n1.0000\n0.0000\n\n\nD_OTH\n0.0000\n0.0000\n1.0000\n\n\n\n\n\n\n\n\n\n\n\n\nm_P_A =\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n0.8994\n0.0949\n0.0057\n\n\nD_CHF\n0.0000\n1.0000\n0.0000\n\n\nD_OTH\n0.0000\n0.0000\n1.0000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nm_P_B =\n\n\n\nCHF\nD_CHF\nD_OTH\n\n\n\n\nCHF\n0.8819\n0.1125\n0.0056\n\n\nD_CHF\n0.0000\n1.0000\n0.0000\n\n\nD_OTH\n0.0000\n0.0000\n1.0000\n\n\n\n\n\n\n\n\n\nFigure 1: Transition probability matrices (NH = Natural History; A = Strategy A; B = Strategy B)"
  },
  {
    "objectID": "lectures/lec_structure.html#full-process",
    "href": "lectures/lec_structure.html#full-process",
    "title": "5. Structuring the Markov Model",
    "section": "Full Process",
    "text": "Full Process"
  },
  {
    "objectID": "lectures/lec_structure.html#transition-dynamics-1",
    "href": "lectures/lec_structure.html#transition-dynamics-1",
    "title": "5. Structuring the Markov Model",
    "section": "Transition Dynamics",
    "text": "Transition Dynamics\n\n\nWe have focused on “static” transition rate/probability matrices.\nOften, transitions vary as a function of time."
  },
  {
    "objectID": "lectures/lec_structure.html#transition-dynamics-2",
    "href": "lectures/lec_structure.html#transition-dynamics-2",
    "title": "5. Structuring the Markov Model",
    "section": "Transition Dynamics",
    "text": "Transition Dynamics\n\n\nNonstationary rates: background mortality rate rises with age.\nNonstationary rates: transition to disease status may vary over different ages.\nTime-dependent event transitions: rate of adverse events after disease onset is higher in first cycle, lower in subsequent cycles."
  },
  {
    "objectID": "lectures/lec_structure.html#age-varying-background-mortality",
    "href": "lectures/lec_structure.html#age-varying-background-mortality",
    "title": "5. Structuring the Markov Model",
    "section": "Age-Varying Background Mortality",
    "text": "Age-Varying Background Mortality\n\n\nUseful data source is life table data.\nMay be available from vital statistics division in your country.\nAlso available (by region) from the UN and other organizations."
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality",
    "href": "lectures/lec_structure.html#background-mortality",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\n\nYou can fit a Gompertz survival model to each age’s life table data.1\nThe Gompertz model will estimate two parameters: a shape (a) and a rate (b) parameter.\nGompertz parameters (by gender) are shown in the table.\n\n\nSee the workshop blog posting for R code!"
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-1",
    "href": "lectures/lec_structure.html#background-mortality-1",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\nYou can fit a Gompertz survival model to each age’s life table data.\nThe Gompertz model will estimate two parameters: a shape (a) and a rate (b) parameter.\nGompertz parameters (by gender) are shown in the table on next slide."
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-2",
    "href": "lectures/lec_structure.html#background-mortality-2",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\n\n\n\n\n\nAge\na_shape\nb_rate\n\n\n\n\n0\n0.08386\n8e-05\n\n\n1\n0.08630\n7e-05\n\n\n2\n0.08644\n8e-05\n\n\n3\n0.08653\n8e-05\n\n\n4\n0.08658\n9e-05\n\n\n5\n0.08661\n1e-04"
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-3",
    "href": "lectures/lec_structure.html#background-mortality-3",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\nGompertz fit to mortality data for two selected ages (40- and 90-year old U.S. males)\n\n\n\n\n\n\n\n\n\n(a) 40-Year Old Men\n\n\n\n\n\n\n\n\n\n(b) 90-Year Old Men\n\n\n\n\n\nFigure 2: Distribution of observed deaths (grey bars) and fitted Gompertz model (red) for two ages."
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-4",
    "href": "lectures/lec_structure.html#background-mortality-4",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\n\nSuppose we have a model of males starting at age 40.\nEach age has its own estimated shape (a) and rate (b) parameter.\nWe can find the values of \\(a\\) and \\(b\\) for our 40 year old male cohort:"
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-5",
    "href": "lectures/lec_structure.html#background-mortality-5",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\nSuppose we have a model of males starting at age 40.\nEach age has its own estimated shape (a) and rate (b) parameter.\nWe can find the values of \\(a\\) and \\(b\\) for our 40 year old male cohort:\n\n\n\n\n\n\nAge\na_shape\nb_rate\n\n\n\n\n40\n0.0908323\n0.0017132"
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-6",
    "href": "lectures/lec_structure.html#background-mortality-6",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\n\nThese shape and rate values are now fixed for our model\nThat is, we only need these two values, as they allow us to model the remaining life expectancy of our 40-year-old male cohort as it ages through our model!"
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-7",
    "href": "lectures/lec_structure.html#background-mortality-7",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\n\nAs our cohort ages through the model (40, 41, 42, …), the background death rate at each subsequent age can be calculated using a simple formula.\nGiven the \\(a\\) and \\(b\\) values for a 40-year-old males, we can calcualte the death rate at any subsequent age as \\[r_{e} =  \\frac{b}{a} (e^{at_2} - e^{at_1})\\]"
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-8",
    "href": "lectures/lec_structure.html#background-mortality-8",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\nThe Gompertz parameters for 40-year old males (US life table data) are:\n\na = 0.0908\nb = 0.0017"
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-9",
    "href": "lectures/lec_structure.html#background-mortality-9",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\n\nAt t=0 (i.e., age 40), the mortality rate for the cohort over the next year is:\n\n\n\n\\[r_{t=0} = 0.0017934 =  \\frac{0.0017132}{0.0908323} (e^{0.0908323 \\cdot 1} - e^{0.0908323 \\cdot (0))})\\]\n\n\n\nUsing a rate-to-probability conversion formula, this corresponds to a probability of death in the next year of \\[p = 1-exp(-r) = 1-exp(-0.0017934) = 0.0017918\\]"
  },
  {
    "objectID": "lectures/lec_structure.html#verifying-accuracy",
    "href": "lectures/lec_structure.html#verifying-accuracy",
    "title": "5. Structuring the Markov Model",
    "section": "Verifying Accuracy",
    "text": "Verifying Accuracy\n\n\nUsing this mortality rate, we can (randomly) draw death times (years from age 40) for 1 million 40 year old males.\nThe average life expectancy is the mean of this value.\nIn this example, the life expectancy is 38.3 years."
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-10",
    "href": "lectures/lec_structure.html#background-mortality-10",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\nThis life expectancy closely matches other published data"
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-11",
    "href": "lectures/lec_structure.html#background-mortality-11",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\n\nWe can now repeat this exercise for every cycle in our model.\nThis gives us a different background mortality rate for every cycle.\n\n\n\n\n\n\n\n\ncycle\nage\na_shape\nb_rate\nr_mort\np_death\n\n\n\n\n0\n40\n0.0908\n0.0017\n0.0018\n0.0018\n\n\n1\n41\n0.0908\n0.0017\n0.0020\n0.0020\n\n\n2\n42\n0.0908\n0.0017\n0.0022\n0.0021\n\n\n3\n43\n0.0908\n0.0017\n0.0024\n0.0024\n\n\n4\n44\n0.0908\n0.0017\n0.0026\n0.0026\n\n\n5\n45\n0.0908\n0.0017\n0.0028\n0.0028"
  },
  {
    "objectID": "lectures/lec_structure.html#background-mortality-12",
    "href": "lectures/lec_structure.html#background-mortality-12",
    "title": "5. Structuring the Markov Model",
    "section": "Background Mortality",
    "text": "Background Mortality\n\nWe can now repeat this exercise for every cycle in our model.\nThis gives us a different background mortality rate for every cycle.\n\n\n\n\n\n\n\ncycle\nage\na_shape\nb_rate\nr_mort\np_death\n\n\n\n\n50\n90\n0.0908\n0.0017\n0.1683\n0.1549\n\n\n51\n91\n0.0908\n0.0017\n0.1843\n0.1683\n\n\n52\n92\n0.0908\n0.0017\n0.2018\n0.1828\n\n\n53\n93\n0.0908\n0.0017\n0.2210\n0.1983\n\n\n54\n94\n0.0908\n0.0017\n0.2420\n0.2150\n\n\n55\n95\n0.0908\n0.0017\n0.2650\n0.2328"
  },
  {
    "objectID": "lectures/lec_structure.html#nonstationary-rates",
    "href": "lectures/lec_structure.html#nonstationary-rates",
    "title": "5. Structuring the Markov Model",
    "section": "Nonstationary Rates",
    "text": "Nonstationary Rates\n\nYou may have other parameters that vary by age.\n\nDisease specific mortality rate:\n\n\n\nSource: Russell et al. (2016)"
  },
  {
    "objectID": "lectures/lec_structure.html#nonstationary-rates-1",
    "href": "lectures/lec_structure.html#nonstationary-rates-1",
    "title": "5. Structuring the Markov Model",
    "section": "Nonstationary Rates",
    "text": "Nonstationary Rates\n\nYou may have other parameters that vary by age.\n\nDisease specific mortality rate:\nAge-specific intervention rates/probabilities\n\n\n\n\n\n\n\nSource: Russell et al. (2016)"
  },
  {
    "objectID": "lectures/lec_structure.html#nonstationary-rates-2",
    "href": "lectures/lec_structure.html#nonstationary-rates-2",
    "title": "5. Structuring the Markov Model",
    "section": "Nonstationary Rates",
    "text": "Nonstationary Rates\n\n\nIt is straightforward to incorporate these dynamics into a Markov model.\nEssentially, you recalculate the transition probability matrix in each cycle.\nThis works long as the underlying rates/probabilities change by age."
  },
  {
    "objectID": "lectures/lec_structure.html#nonstationary-rates-3",
    "href": "lectures/lec_structure.html#nonstationary-rates-3",
    "title": "5. Structuring the Markov Model",
    "section": "Nonstationary Rates",
    "text": "Nonstationary Rates\n\n\nThis makes the Excel a bit more complicated, because you have to incorporate visual basic code to recalculate.\nWe have constructed an optional case study that draws on age-specific background mortality rates – see the workshop website for more!"
  },
  {
    "objectID": "lectures/lec_structure.html#other-transition-dynamics",
    "href": "lectures/lec_structure.html#other-transition-dynamics",
    "title": "5. Structuring the Markov Model",
    "section": "Other Transition Dynamics",
    "text": "Other Transition Dynamics\n\n\nSuppose, instead, that event/transition rates, costs, quality of life vary over the course of a disease or other process in our model.\nExample: cost, quality of life weight, or risk of adverse event (e.g., death) is different in first year after disease onset, and changes thereafter.\nThese types of dynamics are more challenging to implement – but you can often do it!"
  },
  {
    "objectID": "lectures/lec_structure.html#other-transition-dynamics-1",
    "href": "lectures/lec_structure.html#other-transition-dynamics-1",
    "title": "5. Structuring the Markov Model",
    "section": "Other Transition Dynamics",
    "text": "Other Transition Dynamics\n\n\nOne option is to simply build a decision tree around events that occur at higher rates shortly after disease onset, surgery, drug initiation, etc.\nThe decision tree can follow people until they reach a “steady state” — then the Markov model can pick up from there."
  },
  {
    "objectID": "lectures/lec_structure.html#other-transition-dynamics-2",
    "href": "lectures/lec_structure.html#other-transition-dynamics-2",
    "title": "5. Structuring the Markov Model",
    "section": "Other Transition Dynamics",
    "text": "Other Transition Dynamics\n\n\nAnother option is “tunnel states” — simply expand the health state to follow people over the first few cycles of onset.\nTunnel states are “non-markovian,” so they need to be added once you have the transition probability matrix defined."
  },
  {
    "objectID": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead",
    "href": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead",
    "title": "5. Structuring the Markov Model",
    "section": "Tunnel States: Healthy, Sick, Dead",
    "text": "Tunnel States: Healthy, Sick, Dead\n\n\nLet’s take a simple healthy, sick, dead model.\nIllness onset rate = 0.0314\nBackground mortality rate = 0.0094\nIllness increases the risk of death by a hazard ratio of 5.45."
  },
  {
    "objectID": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-1",
    "href": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-1",
    "title": "5. Structuring the Markov Model",
    "section": "Tunnel States: Healthy, Sick, Dead",
    "text": "Tunnel States: Healthy, Sick, Dead\nTransition rate matrix: \\(\\mathbf{R}\\)\n\n\n\n\n\n\nH\nS\nD\n\n\n\n\nH\n-0.0408\n0.0314\n0.0094\n\n\nS\n0.0000\n-0.0513\n0.0513\n\n\nD\n0.0000\n0.0000\n0.0000"
  },
  {
    "objectID": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-2",
    "href": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-2",
    "title": "5. Structuring the Markov Model",
    "section": "Tunnel States: Healthy, Sick, Dead",
    "text": "Tunnel States: Healthy, Sick, Dead\nTransition probability matrix: \\(\\exp(\\mathbf{R})\\)\n\n\n\n\n\n\nH\nS\nD\n\n\n\n\nH\n0.96\n0.03\n0.01\n\n\nS\n0.00\n0.95\n0.05\n\n\nD\n0.00\n0.00\n1.00"
  },
  {
    "objectID": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-3",
    "href": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-3",
    "title": "5. Structuring the Markov Model",
    "section": "Tunnel States: Healthy, Sick, Dead",
    "text": "Tunnel States: Healthy, Sick, Dead\n\n\nNow suppose that the probability of death from disease varies by time since disease onset.\n\n0.08 in first year\n0.06 in second year\n0.04 in third year onwards\n\nWe can add tunnel states to our transition probability matrix to accomodate this."
  },
  {
    "objectID": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-4",
    "href": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-4",
    "title": "5. Structuring the Markov Model",
    "section": "Tunnel States: Healthy, Sick, Dead",
    "text": "Tunnel States: Healthy, Sick, Dead\n\nHere is the new transition probability matrix.\nNotice how the tunnel states “force” people to transition either to the next disease state if they do not die of the disease in the cycle.\n\n\n\n\n\n\n\n\nH\nS1\nS2\nS\nD\n\n\n\n\nH\n0.96\n0.03\n0.00\n0.00\n0.01\n\n\nS1\n0.00\n0.00\n0.92\n0.00\n0.08\n\n\nS2\n0.00\n0.00\n0.00\n0.94\n0.06\n\n\nS\n0.00\n0.00\n0.00\n0.96\n0.04\n\n\nD\n0.00\n0.00\n0.00\n0.00\n1.00"
  },
  {
    "objectID": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-5",
    "href": "lectures/lec_structure.html#tunnel-states-healthy-sick-dead-5",
    "title": "5. Structuring the Markov Model",
    "section": "Tunnel States: Healthy, Sick, Dead",
    "text": "Tunnel States: Healthy, Sick, Dead\n\nIf we run out the Markov trace for five cycles, here are the results.\n\n\n\nYou can find a nice discussion of how to incorporate tunnel states into an Excel model here.\n\n\n\n\n\n\n\n\ncycle\nH\nS1\nS2\nS\nS_total\nD\n\n\n\n\n0\n1000\n0\n0\n0\n0\n0\n\n\n1\n960\n30\n0\n0\n30\n10\n\n\n2\n922\n29\n28\n0\n57\n22\n\n\n3\n885\n28\n26\n26\n80\n35\n\n\n4\n849\n27\n25\n50\n102\n49\n\n\n5\n815\n25\n24\n72\n121\n63"
  },
  {
    "objectID": "lectures/lec_structure.html#working-backwards-1",
    "href": "lectures/lec_structure.html#working-backwards-1",
    "title": "5. Structuring the Markov Model",
    "section": "Working Backwards",
    "text": "Working Backwards\n\n\nSuppose someone has already constructed a detailed Markov model for the decision problem you are working on.\nHowever, this model was constructed for another country/region/context.\nRather than start from “scratch” with your own model, you might be able to adapt it!"
  },
  {
    "objectID": "lectures/lec_structure.html#working-backwards-2",
    "href": "lectures/lec_structure.html#working-backwards-2",
    "title": "5. Structuring the Markov Model",
    "section": "Working Backwards",
    "text": "Working Backwards\nEssentially, this means working backwards!"
  },
  {
    "objectID": "lectures/lec_structure.html#working-backwards-3",
    "href": "lectures/lec_structure.html#working-backwards-3",
    "title": "5. Structuring the Markov Model",
    "section": "Working Backwards",
    "text": "Working Backwards\nEssentially, this means working backwards!"
  },
  {
    "objectID": "lectures/lec_structure.html#working-backwards-4",
    "href": "lectures/lec_structure.html#working-backwards-4",
    "title": "5. Structuring the Markov Model",
    "section": "Working Backwards",
    "text": "Working Backwards\n\n\nWe won’t go into the (very mathematical) details, but we will show you how to do this!\nEssentially, we will “solve” for what is called the generator matrix for the (existing) transition probability matrix.\nThis is done through a process known as “eigenvalue decomposition.”\nNote that this is not always possible, depending on the matrix!"
  },
  {
    "objectID": "lectures/lec_structure.html#working-backwards-5",
    "href": "lectures/lec_structure.html#working-backwards-5",
    "title": "5. Structuring the Markov Model",
    "section": "Working Backwards",
    "text": "Working Backwards\nLet’s start with the example transition probability matrix from earlier:\nm_P =\n\n\n\n\n\n\nH\nS\nD\n\n\n\n\nH\n0.96\n0.03\n0.01\n\n\nS\n0.00\n0.95\n0.05\n\n\nD\n0.00\n0.00\n1.00"
  },
  {
    "objectID": "lectures/lec_structure.html#working-backwards-6",
    "href": "lectures/lec_structure.html#working-backwards-6",
    "title": "5. Structuring the Markov Model",
    "section": "Working Backwards",
    "text": "Working Backwards\nTo obtain the rate matrix (m_R) from an existing transition probability matrix (m_P):\nV  &lt;- eigen(m_P)$vectors\niV &lt;- solve(V)\nAp &lt;- iV %*% m_P %*% V\nlAp &lt;- diag(log(diag(Ap)), nrow(Ap), ncol(Ap))\nm_R  &lt;- V %*% lAp %*% iV"
  },
  {
    "objectID": "lectures/lec_structure.html#working-backwards-7",
    "href": "lectures/lec_structure.html#working-backwards-7",
    "title": "5. Structuring the Markov Model",
    "section": "Working Backwards",
    "text": "Working Backwards\nTo obtain the rate matrix (m_R) from an existing transition probability matrix (m_P):\nm_R =\n\n\n\n\n\n\nH\nS\nD\n\n\n\n\nH\n-0.040822\n0.0314139\n0.0094081\n\n\nS\n0.000000\n-0.0512933\n0.0512933\n\n\nD\n0.000000\n0.0000000\n0.0000000"
  },
  {
    "objectID": "lectures/lec_structure.html#working-backwards-8",
    "href": "lectures/lec_structure.html#working-backwards-8",
    "title": "5. Structuring the Markov Model",
    "section": "Working Backwards",
    "text": "Working Backwards\n\n\nWe now have the rate matrix that is the “hub” or “root” of the underlying Markov model!\nFrom here, we could adapt rates using country-specific parameters.\nFor example, we could adapt the rate of background mortality to match our country’s/region’s mortality rate.\nWe could also add additional states, or make other changes as needed."
  },
  {
    "objectID": "lectures/lec_structure.html#working-backwards-9",
    "href": "lectures/lec_structure.html#working-backwards-9",
    "title": "5. Structuring the Markov Model",
    "section": "Working Backwards",
    "text": "Working Backwards\n\n\nOnce we make the changes we need, we just go back to our usual process.\n“Embed” the new transition probability matrix using rate-to-probability conversion formulas, or using exponentiation."
  },
  {
    "objectID": "lectures/lec_structure.html#footnotes",
    "href": "lectures/lec_structure.html#footnotes",
    "title": "5. Structuring the Markov Model",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis often comes from separate vital statistics / life-table data sources.↩︎\nNote this is slightly higher than the corresponding probability in our natural history transition probability matrix (0.1172), reflecting the fact that randomized trial participants are not necessarily representative of the entire population!↩︎\nThough note this is an assumption, so we should incorporate a lot of uncertainty around it in our model!↩︎\nIf the incidence of the outcome is fairly rare (\\(p_0&lt;0.10\\)), you will often see people simply use the OR as a RR. Source for conversion formula: Zhang and Yu (1998)↩︎\nSee the workshop blog posting for R code!↩︎"
  },
  {
    "objectID": "lectures/exercise_ANS_structure.html",
    "href": "lectures/exercise_ANS_structure.html",
    "title": "Answer Key: Structuring the Markov Model Group Exercise",
    "section": "",
    "text": "m_R0 =\n\n\n\n\n\n\n\n\n\n\n\n\nAsymptomatic\nProgressive Disease\nDisease Mortality\nBackground Mortality\n\n\n\n\nAsymptomatic\n-(r_AP/10+r_Db)\nr_AP/10\n0 \\(\\quad \\quad \\quad\\)\nr_Db\n\n\nProgressive Disease\n0 \\(\\quad \\quad \\quad\\)\n-(HR_PDd * r_Db + r_Db)\nHR_PDd * r_Db\nr_Db\n\n\nDisease Mortality\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n\n\nBackground Mortality\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\n\n\n\n\n\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells"
  },
  {
    "objectID": "lectures/exercise_ANS_structure.html#answer-natural-history",
    "href": "lectures/exercise_ANS_structure.html#answer-natural-history",
    "title": "Answer Key: Structuring the Markov Model Group Exercise",
    "section": "",
    "text": "m_R0 =\n\n\n\n\n\n\n\n\n\n\n\n\nAsymptomatic\nProgressive Disease\nDisease Mortality\nBackground Mortality\n\n\n\n\nAsymptomatic\n-(r_AP/10+r_Db)\nr_AP/10\n0 \\(\\quad \\quad \\quad\\)\nr_Db\n\n\nProgressive Disease\n0 \\(\\quad \\quad \\quad\\)\n-(HR_PDd * r_Db + r_Db)\nHR_PDd * r_Db\nr_Db\n\n\nDisease Mortality\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n\n\nBackground Mortality\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\n\n\n\n\n\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells"
  },
  {
    "objectID": "lectures/exercise_ANS_structure.html#answer-natural-history-1",
    "href": "lectures/exercise_ANS_structure.html#answer-natural-history-1",
    "title": "Answer Key: Structuring the Markov Model Group Exercise",
    "section": "Answer: Natural History",
    "text": "Answer: Natural History\nm_P0 = exp(m_R0) =\n\n\n\n\n\n\n\n\n\n\n\n\nAsymptomatic\nProgressive Disease\nDisease Mortality\nBackground Mortality\n\n\n\n\nAsymptomatic\n1-p_AP-p_ADb\np_AP \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\np_ADb \\(\\quad \\quad \\quad\\)\n\n\nProgressive Disease\n0 \\(\\quad \\quad \\quad \\quad \\quad\\)\n1-p_PDd-p_PDb\np_PDd\\(\\quad \\quad \\quad \\quad \\quad\\)\np_PDb\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nDisease Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nBackground Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\n\n\n\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells"
  },
  {
    "objectID": "lectures/exercise_ANS_structure.html#answer-strategy-a",
    "href": "lectures/exercise_ANS_structure.html#answer-strategy-a",
    "title": "Answer Key: Structuring the Markov Model Group Exercise",
    "section": "Answer: Strategy A",
    "text": "Answer: Strategy A\nBasis is m_P0\nm_P_A =\n\n\n\n\n\n\n\n\n\n\n\n\nAsymptomatic\nProgressive Disease\nDisease Mortality\nBackground Mortality\n\n\n\n\nAsymptomatic\n1-RR_AP * p_AP-p_ADb\nRR_AP p_AP \\(\\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\np_ADb \\(\\quad \\quad \\quad\\)\n\n\nProgressive Disease\n0 \\(\\quad \\quad \\quad \\quad \\quad\\)\n1-p_PDd-p_PDb\np_PDd\\(\\quad \\quad \\quad \\quad \\quad\\)\np_PDb\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nDisease Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nBackground Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\n\n\n\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells"
  },
  {
    "objectID": "lectures/exercise_ANS_structure.html#answer-strategy-b",
    "href": "lectures/exercise_ANS_structure.html#answer-strategy-b",
    "title": "Answer Key: Structuring the Markov Model Group Exercise",
    "section": "Answer: Strategy B",
    "text": "Answer: Strategy B\nBasis is m_P0\nm_P_B =\n\n\n\n\n\n\n\n\n\n\n\n\nAsymptomatic\nProgressive Disease\nDisease Mortality\nBackground Mortality\n\n\n\n\nAsymptomatic\n1-p_AP-p_ADb\np_AP \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\np_ADb \\(\\quad \\quad \\quad\\)\n\n\nProgressive Disease\n0 \\(\\quad \\quad \\quad \\quad \\quad\\)\n1-((OR_PDd / (1 - p0_OR_PDd + (p0_OR_PDd * OR_PDd ))) * p_PDd)-p_PDb\n(OR_PDd / (1 - p0_OR_PDd + (p0_OR_PDd * OR_PDd )))  * p_PDd\np_PDb\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nDisease Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nBackground Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\n\n\n\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells"
  },
  {
    "objectID": "lectures/exercise_ANS_structure.html#answer-strategy-b-1",
    "href": "lectures/exercise_ANS_structure.html#answer-strategy-b-1",
    "title": "Answer Key: Structuring the Markov Model Group Exercise",
    "section": "Answer: Strategy B",
    "text": "Answer: Strategy B\nNote that because p0_OR_PDd is fairly low (i.e., 0.03), you could just use the odds ratio as a relative risk.\nBasis is m_P0\nm_P_B =\n\n\n\n\n\n\n\n\n\n\n\n\nAsymptomatic\nProgressive Disease\nDisease Mortality\nBackground Mortality\n\n\n\n\nAsymptomatic\n1-p_AP-p_ADb\np_AP \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\np_ADb \\(\\quad \\quad \\quad\\)\n\n\nProgressive Disease\n0 \\(\\quad \\quad \\quad \\quad \\quad\\)\n1- OR_PDd * p_PDd)-p_PDb\nOR_PDd  * p_PDd\np_PDb\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nDisease Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nBackground Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\n\n\n\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells"
  },
  {
    "objectID": "lectures/exercise_ANS_structure.html#answer-strategy-c",
    "href": "lectures/exercise_ANS_structure.html#answer-strategy-c",
    "title": "Answer Key: Structuring the Markov Model Group Exercise",
    "section": "Answer: Strategy C",
    "text": "Answer: Strategy C\nBasis is m_R0\nm_R_C =\n\n\n\n\n\n\n\n\n\n\n\n\nAsymptomatic\nProgressive Disease\nDisease Mortality\nBackground Mortality\n\n\n\n\nAsymptomatic\n-(r_AP/10+r_Db)\nr_AP/10\n0 \\(\\quad \\quad \\quad\\)\nr_Db\n\n\nProgressive Disease\nr_PA_trtC/10\n-(r_PA_trtC/10 + HR_PDd * r_Db + r_Db)\nHR_PDd * r_Db\nr_Db\n\n\nDisease Mortality\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n\n\nBackground Mortality\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\n\n\n\n\n\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells"
  },
  {
    "objectID": "lectures/exercise_ANS_structure.html#answer-strategy-c-1",
    "href": "lectures/exercise_ANS_structure.html#answer-strategy-c-1",
    "title": "Answer Key: Structuring the Markov Model Group Exercise",
    "section": "Answer: Strategy C",
    "text": "Answer: Strategy C\nm_P_C = exp(m_R_C) =\n\n\n\n\n\n\n\n\n\n\n\n\nAsymptomatic\nProgressive Disease\nDisease Mortality\nBackground Mortality\n\n\n\n\nAsymptomatic\n1-p_AP-p_ADb\np_AP \\(\\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad\\)\np_ADb \\(\\quad \\quad \\quad\\)\n\n\nProgressive Disease\np_PA \\(\\quad \\quad \\quad \\quad\\)\n1-p_PDd-p_PDb\np_PDd\\(\\quad \\quad \\quad \\quad \\quad\\)\np_PDb\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nDisease Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0 \\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\nBackground Mortality\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n0\\(\\quad \\quad \\quad \\quad \\quad\\)\n1.0\\(\\quad \\quad \\quad \\quad \\quad\\)\n\n\n\n\n\n\n\n\nRate adjusted for timestep\n\n\nHazard Ratio\n\n\nProbability\n\n\nRelative Risk\n\n\nOdds Ratio\n\n\nConstructed from other cells"
  },
  {
    "objectID": "blog/posts/embedding/embedding-a-transition-probability-matrix.html",
    "href": "blog/posts/embedding/embedding-a-transition-probability-matrix.html",
    "title": "Embedding A Transition Probability Matrix for a Discrete Time Markov Model",
    "section": "",
    "text": "Define \\(r_{HS}\\) and \\(r_{HD}\\) as the hazard rate of two independent competing risks from a given (Healthy) health state (to Sick and Dead, respectively), and \\(\\Delta t\\) the cycle length (e.g., \\(1\\)=1 year, \\(1/12\\)=1 month, etc.). We can also define a third rate \\(r_{SD} = hr_{S}*r_{HD}\\) for transitioning from sick to dead, i.e., the standard (healthy-to-dead) rate multiplied by the hazard ratio \\(hr_{S}\\).\nThe underlying Markov model takes the following form:\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nHealthy\n\n Healthy   \n\nHealthy-&gt;Healthy\n\n    \n\nSick\n\n Sick   \n\nHealthy-&gt;Sick\n\n  r_HS   \n\nDead\n\n Dead   \n\nHealthy-&gt;Dead\n\n  r_HD   \n\nSick-&gt;Sick\n\n    \n\nSick-&gt;Dead\n\n  hr_S * r_HD   \n\nDead-&gt;Dead\n\n   \n\n\nFigure 1: Model Diagram\n\n\n\n\n\n\n\nCode\nlibrary(Matrix)\nlibrary(tidyverse)\nlibrary(expm)\nlibrary(knitr)\nlibrary(gt)\nlibrary(directlabels)\nlibrary(glue)\nlibrary(ggsci)\nlibrary(ggthemes)\n\n# Better accuracy that \"life-table\" aka trapezoidal method\nalt_simp_coef &lt;- function(i) c(17, 59, 43, 49, rep(48, i-8), 49, 43, 59, 17) / 48\nalt_simp      &lt;- function(x,h) h*sum(alt_simp_coef(length(x)) * x)\n\nr_HS &lt;- 0.15\nr_HD &lt;- .006\nhr_S &lt;- 10\nr_SD &lt;- hr_S*r_HD\ncycle &lt;- 1\n\n# 1-exp(-r_HS*cycle)\n# 1-exp(-r_HD*cycle)\n\nget_P &lt;- function(r_HS,r_HD,r_SD,cycle) {\n  P_st &lt;- \n  matrix(\n  c(exp(-r_HS*cycle) + exp(-r_HD*cycle) -1 ,  (1-exp(-r_HS*cycle)) ,  1-exp(-r_HD*cycle), \n  0, exp(-r_SD*cycle), 1-exp(-r_SD*cycle),\n  0,0,1),\n  nrow = 3, \n  ncol = 3,\n  byrow=TRUE,\n  dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) %&gt;% \n    data.frame() %&gt;% \n    rownames_to_column(var = \"from\") %&gt;% \n    mutate(name = \"P_st\")\n\n  P_eQ &lt;- matrix(\n    c(-(r_HS*cycle+r_HD*cycle),r_HS*cycle,r_HD*cycle,\n      0,-r_SD*cycle,r_SD*cycle,\n      0,0,0),\n      nrow=3,\n      ncol=3,\n      byrow=TRUE,\n    dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) %&gt;% expm() %&gt;% as.matrix() %&gt;% \n    data.frame() %&gt;% \n    rownames_to_column(var = \"from\") %&gt;% \n    mutate(name = \"P_eQ\")\n\n\n  P_cr &lt;- \n    matrix(\n    c(exp(-(r_HS+r_HD)*cycle) , (r_HS/(r_HS+r_HD)) * (1-exp(-(r_HS+r_HD)*cycle))   ,(r_HD/(r_HS+r_HD)) * (1-exp(-(r_HS+r_HD)*cycle))   , \n    0, exp(-r_SD*cycle), 1-exp(-r_SD*cycle),\n    0,0,1),\n    nrow = 3, \n    ncol = 3,\n    byrow=TRUE,\n    dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) %&gt;% \n    data.frame() %&gt;% \n    rownames_to_column(var = \"from\") %&gt;% mutate(name = \"P_cr\")\n  \n  \n  \n  out &lt;- bind_rows( P_st, P_cr , P_eQ)\n  return(out)\n}\n\n\n\n\nCode\ncheck_sens &lt;- function(r_HD,r_HS,r_SD,cycle) {\n  \nQ &lt;- matrix(\n    c(-(r_HS*cycle+r_HD*cycle),r_HS*cycle,r_HD*cycle,\n      0,-r_SD*cycle,r_SD*cycle,\n      0,0,0),\n      nrow=3,\n      ncol=3,\n      byrow=TRUE,\n    dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) \n\n# Q_ &lt;- rbind(cbind(Q,c(r_HS*cycle,0,0)),c(0,0,0,0)) \n# Q_ &lt;- rbind(cbind(Q_,c(r_HD*cycle,0,0,0)),c(0,0,0,0,0))\n# dimnames(Q_) = list(c(\"Healthy\",\"Sick\",\"Dead\",\"accS\",\"accHD\"),\n#                    c(\"Healthy\",\"Sick\",\"Dead\",\"accS\",\"accHD\"))\n\nQ_ &lt;- Q\n\nP &lt;- Q_ %&gt;% expm() %&gt;% as.matrix() \nres &lt;- get_P(r_HS=r_HS,r_HD=r_HD,r_SD=r_SD,cycle=cycle)\n\nP_cr &lt;- res %&gt;% filter(name==\"P_cr\") %&gt;% select(from,Healthy,Sick,Dead) %&gt;% \n  data.frame() %&gt;% \n  column_to_rownames(var = \"from\") %&gt;% \n  as.matrix()\n\nP_st &lt;- res %&gt;% filter(name==\"P_st\") %&gt;% select(from,Healthy,Sick,Dead) %&gt;% \n  data.frame() %&gt;% \n  column_to_rownames(var = \"from\") %&gt;% \n  as.matrix()\n\nle1 &lt;- \n  0:(60/cycle) %&gt;% map(~(c(1000,0,0) %*% (P[1:3,1:3] %^% (.x)))) %&gt;% \n  map(~(.x %&gt;% data.frame)) %&gt;% \n  bind_rows() %&gt;% \n  as.matrix() %&gt;%  \n  {.[,-3]} %&gt;% \n  alt_simp(.,1) %&gt;% \n  {. * cycle} %&gt;% {./1000} %&gt;% \n  data.frame() %&gt;% \n  set_names(\"life_exp\")\n\nres1 &lt;- 0:(60/cycle) %&gt;% map_df(~(c(1000,0,0) %*% (P %^%.x) %&gt;% data.frame())) %&gt;% \n  mutate(cycle = 0:(60/cycle)) %&gt;% \n  select(cycle, everything()) %&gt;% \n  tibble() %&gt;% \n  tail(n=1) %&gt;% \n  bind_cols(le1) %&gt;% \n  mutate(method = \"P_eQ\") \n\nle2 &lt;- \n  0:(60/cycle) %&gt;% map(~(c(1000,0,0) %*% (P_cr[1:3,1:3] %^% (.x)))) %&gt;% \n  map(~(.x %&gt;% data.frame)) %&gt;% \n  bind_rows() %&gt;% \n   as.matrix() %&gt;%  \n  {.[,-3]} %&gt;% \n  alt_simp(.,1) %&gt;% \n  {. * cycle} %&gt;% {./1000} %&gt;% \n  data.frame() %&gt;% \n  set_names(\"life_exp\")\n  \nres2 &lt;- 0:(60/cycle) %&gt;% map_df(~(c(1000,0,0) %*% (P_cr %^%.x) %&gt;% data.frame())) %&gt;% \n  mutate(cycle = 0:(60/cycle)) %&gt;% \n  select(cycle, everything()) %&gt;% \n  tibble() %&gt;% \n  tail(n=1) %&gt;% \n  bind_cols(le2) %&gt;% \n  mutate(method = \"P_cr\")\n\n\nle3 &lt;- \n 0:(60/cycle) %&gt;% map(~(c(1000,0,0) %*% (P_st[1:3,1:3] %^% (.x)))) %&gt;% \n  map(~(.x %&gt;% data.frame)) %&gt;% \n  bind_rows() %&gt;% \n   as.matrix() %&gt;%  \n  {.[,-3]} %&gt;% \n  alt_simp(.,1) %&gt;% \n  {. * cycle} %&gt;% {./1000} %&gt;% \n  data.frame() %&gt;% \n  set_names(\"life_exp\")\n\nres3 &lt;- 0:(60/cycle) %&gt;% map_df(~(c(1000,0,0) %*% (P_st %^%.x) %&gt;% data.frame())) %&gt;% \n  mutate(cycle = 0:(60/cycle)) %&gt;% \n  select(cycle, everything()) %&gt;% \n  tibble() %&gt;% \n  tail(n=1) %&gt;% \n  bind_cols(le3) %&gt;% \n  mutate(method = \"P_st\")\n  \n  out &lt;- res1 %&gt;% bind_rows(res2) %&gt;% bind_rows(res3)\n  return(out)\n\n}"
  },
  {
    "objectID": "blog/posts/embedding/embedding-a-transition-probability-matrix.html#standard-rate-to-transition-conversion",
    "href": "blog/posts/embedding/embedding-a-transition-probability-matrix.html#standard-rate-to-transition-conversion",
    "title": "Embedding A Transition Probability Matrix for a Discrete Time Markov Model",
    "section": "Standard Rate-to-Transition Conversion",
    "text": "Standard Rate-to-Transition Conversion\nLet’s first convert the supplied rates to probabilities using the same standard formulas, as above:\n\\[\np_{HS}= 1 - e^{-r_{HS}\\cdot \\Delta t}\n\\]\n\\[\np_{HD} = 1 - e^{-r_{HD}\\cdot \\Delta t}\n\\]\nWe can also define the probability of remaining healthy (i.e., transitioning to neither the sick or dead state) as:\n\\[\np_{HH} = 1 - p_{HS} - p_{HD}= e^{-r_{HS}\\Delta t}  + e^{-r_{HD}\\Delta t} - 1\n\\]\nAnd finally the probability of dying among sick people is defined as\n\\[\np_{SD} = 1 - e^{-hr_{HD}\\cdot r_{HD}\\cdot \\Delta t}\n\\]\nFigure 6 shows the corresponding transition probability matrix:\n\n\nCode\nr_HD &lt;- 0.006\nr_SD &lt;- 10*0.006\n\nget_P(r_HS=r_HS,r_HD=r_HD,r_SD=r_SD,cycle=cycle) %&gt;% \nfilter(name==\"P_st\") %&gt;% \nselect(-name) %&gt;% \n#column_to_rownames(\"from\") %&gt;% \nmutate_at(vars(-from), ~round(.,4)) %&gt;% \ngt() %&gt;% \n  cols_label(\"from\"=\"\")\n\n\n\n\n\n\n\n\n\n\n\nHealthy\nSick\nDead\n\n\n\n\nHealthy\n0.8547\n0.1393\n0.0060\n\n\nSick\n0.0000\n0.9418\n0.0582\n\n\nDead\n0.0000\n0.0000\n1.0000\n\n\n\n\n\nFigure 6: Transition Probability Matrix Using Standard Rate-to-Probability Conversion Formulas\n\n\n\nGiven this transition probability matrix, how many healthy, sick and dead individuals do we have in our cohort after a 60-year time horizon? Figure 7 summarizes state occupancy at the end of 60 years:\n\n\nCode\nres_60yst &lt;- \n  check_sens(r_HD= r_HD, r_HS = r_HS, r_SD = r_SD, cycle=1) %&gt;% \n  filter(method==\"P_st\") \nres_60yst %&gt;% \n  select(cycle,Healthy,Sick,Dead,life_exp) %&gt;% \n  gt::gt() %&gt;% \n  sub_missing(missing_text=\"-\") %&gt;% \n  fmt_number(columns = c(Healthy,Sick,Dead,life_exp),decimals=1) %&gt;% \n  cols_label(\"life_exp\" = \"Life Expectancy\")\n\n\n\n\n\n\n\n\n\n\ncycle\nHealthy\nSick\nDead\nLife Expectancy\n\n\n\n\n60\n0.1\n43.6\n956.3\n22.1\n\n\n\n\n\nFigure 7: 1-Year Cycle\n\n\n\nAs Figure 7 shows, after 60 years, 43.6 are recorded as being in the sick state and life expectancy has reduced to 22.1 years.\nAs above, let’s now repeat the same exercise using a daily cycle length:\n\n\nCode\nres_60yst_daily &lt;- \n  check_sens(r_HD= r_HD, r_HS = r_HS, r_SD = r_SD,cycle=1/365) %&gt;% \n  filter(method==\"P_st\") \n\nres_60yst_daily %&gt;% \n  select(cycle,Healthy,Sick,Dead,life_exp) %&gt;% \n  gt::gt() %&gt;% \n  sub_missing(missing_text=\"-\") %&gt;% \n  fmt_number(columns = c(Healthy,Sick,Dead,life_exp),decimals=1) %&gt;% \n  cols_label(\"life_exp\" = \"Life Expectancy\")\n\n\n\n\n\n\n\n\n\n\ncycle\nHealthy\nSick\nDead\nLife Expectancy\n\n\n\n\n21900\n0.1\n42.6\n957.4\n21.7\n\n\n\n\n\nFigure 8: Daily Cycle\n\n\n\nBy switching to a daily cycle we now have 42.6 recorded as being in the sick state after 60 years (=21,900 days) and life expectancy is 21.7 years.\n\nSigns of Trouble\nLet’s recap what we have found after introducing background mortality as a competing risk:\n\nUsing a 1-year cycle length, life expectancy is 22.11 years.\nUsing a daily cycle length, life expectancy is 21.73 years.\n\nThe only difference above is the cycle length used, yet we obtain a 0.38 year difference in life expectancy. What causes this difference?\n\n\nDiscretizing a Continuous Time Process\nThe answer boils down to the fact that with longer cycle lengths we “hide” some deaths that occur because a full healthy sick dead transition occurs within a single cycle.\nWhen we use the standard rate-to-probability conversion formula (i.e., \\(p_{HS}= 1 - e^{-r_{HS}\\Delta t}\\)) we obtain the marginal probability of transition. This marginal probability reflects the union of all possible transitions that start Healthy and then transition to and from the sick state in the cycle.\nThat is, \\(p_{HS}= 1 - e^{-r_{HS}\\Delta t}\\) captures the probability of following scenarios occurring in a cycle:\n\nIndividual transitions from healthy to sick.\nIndividual transitions from healthy to sick to dead.\n\nBy including case 2 in the healthy sick transition probability, we effectively rule out the possibility of becoming sick and dying within the same cycle. This implicit assumption means that we are no longer modeling a continuous time process, since we effectively “hide” some (quick) deaths that occur within a cycle due to the disease:\n\n\n\n\n\n\n\n\nG\n\n  \n\nHealthy\n\n Healthy   \n\nHealthy-&gt;Healthy\n\n    \n\nSick\n\n Sick   \n\nHealthy-&gt;Sick\n\n    \n\nDead\n\n Dead   \n\nHealthy-&gt;Dead\n\n    \n\nSick-&gt;Sick\n\n    \n\nSick-&gt;Dead\n\n    \n\nDead-&gt;Dead\n\n   \n\n\nFigure 9: compound Transition Patterns Using Standard Rate to Probability Conversion Formulas\n\n\n\n\nIn Figure 9, and using standard rate-to-probability conversion formulas, the recorded states of a healthy sick dead transition are recorded in blue; the “hidden” transition is shown in red.\n\nAlternative Rate-to-Probability Conversion\nAnother set of formulas often used to account for competing risks are as follows:\n\\[\np_{HS}= \\frac{r_{HS}}{r_{HS}+r_{HD}}\\big ( 1 - e^{-(r_{HS}+r_{HD})\\Delta t}\\big )\n\\]\n\\[\np_{HD}= \\frac{r_{HD}}{r_{HS}+r_{HD}}\\big ( 1 - e^{-(r_{HS}+r_{HD})\\Delta t}\\big )\n\\]\n\\[\np_{HH} = e^{-(r_{HS}+r_{HD})\\Delta t}\n\\]\nLet’s now use these formulas instead.\nFigure 10 shows the corresponding transition probability matrix:\n\n\nCode\nr_HD &lt;- 0.006\nr_SD &lt;- 10*0.006\n\nget_P(r_HS=r_HS,r_HD=r_HD,r_SD=r_SD,cycle=cycle) %&gt;% \nfilter(name==\"P_cr\") %&gt;% \nselect(-name) %&gt;% \n#column_to_rownames(\"from\") %&gt;% \nmutate_at(vars(-from), ~round(.,4)) %&gt;% \ngt() %&gt;% \n  cols_label(\"from\"=\"\")\n\n\n\n\n\n\n\n\n\n\n\nHealthy\nSick\nDead\n\n\n\n\nHealthy\n0.8556\n0.1389\n0.0056\n\n\nSick\n0.0000\n0.9418\n0.0582\n\n\nDead\n0.0000\n0.0000\n1.0000\n\n\n\n\n\nFigure 10: Transition Probability Matrix Using Alternative Rate-to-Probability Conversion Formulas\n\n\n\nComparing Figure 6 and Figure 10, notice that a few things have changed. First, the probability of Healthy Sick transition declined. This would seem to be consistent with a world in which there are fewer alive sick individuals observed at the end of the cycle–which we would expect if acute illness results in a nontrivial number of quick deaths after illness onset in a cycle.\nHowever, look at the Healthy Dead transition probability change; it went down, too. If we were recording more acute deaths from the disease, we should see more Healthy Dead transitions from individuals sojourning through the Sick state on their way to death in a single cycle.\nWhat about state occupancy and life expectancy under different cycle lengths?\n\n\nCode\nres_60yst_cr &lt;- \n  check_sens(r_HD= r_HD, r_HS = r_HS, r_SD = r_SD, cycle=1) %&gt;% \n  filter(method==\"P_cr\") %&gt;% \n  mutate(cycle = \"1y\") %&gt;% \n  mutate(cycle_t = 60)\n\nres_60yst_daily_cr &lt;- \n  check_sens(r_HD= r_HD, r_HS = r_HS, r_SD = r_SD,cycle=1/365) %&gt;% \n  filter(method==\"P_cr\") %&gt;% \n  mutate(cycle_t = cycle) %&gt;% \n  mutate(cycle = \"Daily\")\n\nres_60yst_cr %&gt;% \n  bind_rows(res_60yst_daily_cr) %&gt;% \n  select(cycle,cycle_t,Healthy,Sick,Dead,life_exp) %&gt;% \n  gt::gt() %&gt;% \n  sub_missing(missing_text=\"-\") %&gt;% \n  fmt_number(columns = c(Healthy,Sick,Dead,life_exp),decimals=1) %&gt;% \n  cols_label(\"life_exp\" = \"Life Expectancy\")\n\n\n\n\n\n\n\n\n\n\ncycle\ncycle_t\nHealthy\nSick\nDead\nLife Expectancy\n\n\n\n\n1y\n60\n0.1\n43.9\n956.0\n22.2\n\n\nDaily\n21900\n0.1\n42.6\n957.4\n21.7\n\n\n\n\n\nFigure 11: 1-Year vs. Daily Cycle\n\n\n\nCode\ndiff_st_cr &lt;- \n  res_60yst_cr %&gt;% \n    bind_rows(res_60yst_daily_cr) %&gt;% mutate(life_exp = life_exp-lead(life_exp)) %&gt;% pull(life_exp) %&gt;% na.omit() %&gt;% as.vector()\n\n\nAgain, we have a difference in life expectancy of 0.462 years. So switching to the alternative formulas has not fundamentally solved our problem.\n\n\nHow do transition probabilities change as the Likelihood of Disease-related death varies?\nAnother way to see the issue is to plot how the transition probabilities change (or not) at different levels of disease acuity. Figure 12 plots the relevant transition probabilities under a yearly time cycle, and while allowing the underlying hazard rate of death from the disease (hr_S) to vary.\nAs the hazard rate increases, the likelihood of ending up dead within a given cycle increases. Indeed, in the most extreme case, imagine the disease has a near instantaneous death rate. In that case we should see almost no Healthy Sick transitions within a yearly cycle, because nearly everyone who became sick within the cycle died within 1 day.\nWe see in Figure 12 that the Healthy Sick probabilities remain flat for transitions under which background mortality is a competing event. However, the Sick Dead transition probabilities rise as the likelihood of fatal disease increases.\n\n\nCode\n1:10 %&gt;% map(~get_P(r_HS=.15,r_HD=.006,r_SD=.006*.x,cycle=1) %&gt;% mutate(hr_S=.x)) %&gt;% \n  bind_rows() %&gt;% \n  gather(transition,value,-from,-name,-hr_S) %&gt;% \n  spread(name,value) %&gt;% \n  filter(P_cr!=1 & P_cr!=0) %&gt;% \n  gather(method,value,-from,-hr_S,-transition) %&gt;% \n    filter(method!=\"P_eQ\") %&gt;% \n  tibble() %&gt;% \n  mutate_at(vars(transition), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  mutate_at(vars(from), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"),\n                                           labels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  filter(from!=transition) %&gt;% \n  ggplot(aes(x = hr_S, y = value)) + \n  geom_point(aes(colour=method, shape=method),size=3) + \n  scale_shape_manual(values = c(19,17)) +\n  scale_color_manual(values= c(\"blue\",\"red\")) +\n  facet_wrap(from~transition, scales=\"free\") + \n  ggthemes::theme_base() + \n  scale_x_continuous(expand = expansion(mult=.5))+\n  scale_y_continuous(expand = expansion(mult=.5))+\n  theme(legend.position = \"bottom\") +\n  directlabels::geom_dl(aes(label = glue::glue(\"  {method}\")), method=\"last.bumpup\",hjust=1) + \n  labs(x = \"hr_S (Hazard Ratio for Sick-to-Dead)\",y = \"Value\")\n\n\n\n\n\nFigure 12: Yearly Cycle - Transition Probabilities by Sick-to-Dead Hazard Rate (P_st uses standard conversion formula; P_cr uses the formula that accounts for competing risks.)\n\n\n\n\nIt is common practice to address these issues using the following guidelines:\n\nSelect a cycle length where the probability of remaining in a given state is at least 95%.\nPick a cycle length that aligns with the clinical/disease timelines of the decision problem.\n\nTreatment schedules.\nAcute vs. chronic condition.\n\n\nBut do these actually solve the issue? No. Figure 13 shows how the transition probabilities change when we switch to a daily cycle length. Again, we see the problem: as disease acuity increases, the probability of a Healthy Dead transition does not change; even though we shortened the cycle length, we have not fundamentally addressed the issue.\n\n\nCode\n1:10 %&gt;% map(~get_P(r_HS=.15,r_HD=.006,r_SD=.006*.x,cycle=1/365) %&gt;% mutate(hr_S=.x)) %&gt;% \n  bind_rows() %&gt;% \n  gather(transition,value,-from,-name,-hr_S) %&gt;% \n  spread(name,value) %&gt;% \n  filter(P_cr!=1 & P_cr!=0) %&gt;% \n  gather(method,value,-from,-hr_S,-transition) %&gt;% \n  filter(method!=\"P_eQ\") %&gt;% \n  tibble() %&gt;% \n  mutate_at(vars(transition), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  mutate_at(vars(from), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"),\n                                           labels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  filter(from!=transition) %&gt;% \n  ggplot(aes(x = hr_S, y = value)) + \n  geom_point(aes(colour=method, shape=method),size=3) + \n    scale_shape_manual(values = c(19,17)) +\n  scale_color_manual(values= c(\"blue\",\"red\")) +\n  facet_wrap(from~transition, scales=\"free\") + \n  ggthemes::theme_base() + \n  scale_x_continuous(expand = expansion(mult=.5))+\n  scale_y_continuous(expand = expansion(mult=.5))+\n  theme(legend.position = \"bottom\") +\n  directlabels::geom_dl(aes(label = glue::glue(\"  {method}\")), method=\"last.bumpup\",hjust=1) + \n  labs(x = \"hr_S (Hazard Ratio for Sick-to-Dead)\",y = \"Value\")\n\n\n\n\n\nFigure 13: Daily Cycle - Transition Probabilities by Sick-to-Dead Hazard Rate (P_st uses standard conversion formula; P_cr uses the formula that accounts for competing risks.)\n\n\n\n\nHow does this all translate into model outputs, such as life expectancy? Figure 14 plots life-expectancy (y-axis) against the underlying disease hazard rate for death. Each line provides the life-expectancy curve under a different cycle length, with everything else in the model held fixed.\nNot surprisingly, we see that as the likelihood of fatal disease increases, life expectancy declines.\nBut the most important takeaway is that the modeled life expectancy differs depending on the cycle length used. For a given hazard rate the underlying disease process is exactly the same – but we get different answers depending on our cycle length.\nThe pattern of results is instructive, too. Essentially, with longer cycle lengths and incorrect transition probabilities, we will “miss” more compound within-cycle Healthy Sick Dead transitions and instead record them as Healthy Sick transitions. This has a net effect of “hiding” more disease-related death in our model – and life-expectancy is inflated as a result.\n\n\n\n\n\nFigure 14: Life Expectancy by Sick-to-Dead Hazard Rate and Cycle Length. The left panel uses the formula that accounts for competing risks. The right panel uses standard conversion formula."
  },
  {
    "objectID": "blog/posts/embedding/embedding-a-transition-probability-matrix.html#embed-the-transition-probability-matrix",
    "href": "blog/posts/embedding/embedding-a-transition-probability-matrix.html#embed-the-transition-probability-matrix",
    "title": "Embedding A Transition Probability Matrix for a Discrete Time Markov Model",
    "section": "1. Embed the Transition Probability Matrix",
    "text": "1. Embed the Transition Probability Matrix\nOur rate matrix Q is constructed by including the relevant transition rates in the off-diagonal cells. The diagonal of Q is the negative sum of off-diagonal elements in the same row:\n\n\n\n\n\n\n\n\n\n\nHealthy\nSick\nDead\n\n\n\n\nHealthy\n-(\\(r_{HS}\\) + \\(r_{HD}\\))\n\\(r_{HS}\\)\n\\(r_{HD}\\)\n\n\nSick\n0\n-(\\(hr_{S} \\cdot r_{HD}\\))\n\\(hr_{S} \\cdot r_{HD}\\)\n\n\nDead\n0\n0\n0\n\n\n\nHere is the rate matrix for the Healthy-Sick-Dead model:\n\n\nCode\nparams &lt;- \n  list(r_HS = 0.15,\n       r_HD = 0.006,\n       hr_S = 10,\n       cycle = 1)\n\nQ &lt;- \n  with(params,{\n    matrix(\n    c(-(r_HS*cycle+r_HD*cycle),r_HS*cycle,r_HD*cycle,\n      0,-r_SD*cycle,r_SD*cycle,\n      0,0,0),\n      nrow=3,\n      ncol=3,\n      byrow=TRUE,\n    dimnames = list(c(\"Healthy\",\"Sick\",\"Dead\"), c(\"Healthy\",\"Sick\",\"Dead\"))\n  ) \n  })\nQ\n\n\n        Healthy  Sick  Dead\nHealthy  -0.156  0.15 0.006\nSick      0.000 -0.06 0.060\nDead      0.000  0.00 0.000\n\n\nWe next embed the transition probability matrix P by taking the matrix exponential of Q:\n\nlibrary(expm)\nP &lt;- expm(Q)\nP\n\n          Healthy      Sick        Dead\nHealthy 0.8555592 0.1346958 0.009744961\nSick    0.0000000 0.9417645 0.058235466\nDead    0.0000000 0.0000000 1.000000000\n\n\nAn alternative way of exponentiating a matrix is to perform a Taylor series expansion:\n\n# Identity matrix with same dimensions and names as Q \nQ_I &lt;- diag(3)\ndimnames(Q_I) = dimnames(Q)\n\n# Note the %^% operator is in the expm package. \n\nQ2 = Q %^% 2   # Q-squared\nQ3 = Q %^% 3   # Q-cubed\nQ4 = Q %^% 4   # etc.\n\nQ_I + Q + (1/factorial(2))*Q2 + (1/factorial(3))*Q3 + (1/factorial(4))*Q4 \n\n          Healthy      Sick        Dead\nHealthy 0.8555599 0.1346947 0.009745373\nSick    0.0000000 0.9417645 0.058235460\nDead    0.0000000 0.0000000 1.000000000\n\n\nHow does this approach (P_eQ) perform relative to the other transition probability matrices (P_st and P_cr)? Figure 15 shows how the transition probabilities vary by hazard rate.\nWe can now see we’ve achieved what we need: Healthy Dead transition probabilities that rise as the hazard rate of death from disease increases. Again, this occurs because as the likelihood of death after becoming ill increases, we increase the likelihood of a compound Healthy Sick Dead transition within a cycle. We need these to be recorded (accurately) as Healthy Dead transitions, rather than Healthy Sick transitions. Correspondingly, as the probability of a compound transition increases with an increasing hazard rate, the probability of a single Healthy Sick transition declines; we see this in Figure 15 as well.\n\n\nCode\n1:10 %&gt;% map(~get_P(r_HS=.15,r_HD=.006,r_SD=.006*.x,cycle=1) %&gt;% mutate(hr_S=.x)) %&gt;% \n  bind_rows() %&gt;% \n  gather(transition,value,-from,-name,-hr_S) %&gt;% \n  spread(name,value) %&gt;% \n  filter(P_cr!=1 & P_cr!=0) %&gt;% \n  gather(method,value,-from,-hr_S,-transition) %&gt;% \n  #filter(method!=\"P_eQ\") %&gt;% \n  tibble() %&gt;% \n  mutate_at(vars(transition), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  mutate_at(vars(from), function(x) factor(x,levels=c(\"Healthy\",\"Sick\",\"Dead\"),\n                                           labels=c(\"Healthy\",\"Sick\",\"Dead\"))) %&gt;% \n  filter(from!=transition) %&gt;% \n  ggplot(aes(x = hr_S, y = value)) + \n  geom_point(aes(colour=method, shape=method),size=3) + \n  scale_shape_manual(values = c(19,17,3)) +\n  facet_wrap(from~transition, scales=\"free\") + \n  ggthemes::theme_base() + \n  scale_x_continuous(expand = expansion(mult=.5))+\n  scale_y_continuous(expand = expansion(mult=.5))+\n  theme(legend.position = \"bottom\") +\n  scale_color_manual(values= c(\"blue\",\"darkgreen\",\"red\")) +\n  directlabels::geom_dl(aes(label = glue::glue(\"  {method}\")), method=\"last.bumpup\",hjust=1) + \n  labs(x = \"hr_S (Hazard Ratio for Sick-to-Dead)\",y = \"Value\")\n\n\n\n\n\nFigure 15: 1-Year Cycle - Transition Probabilities by Sick-to-Dead Hazard Rate (P_st uses standard conversion formula; P_cr uses the formula that accounts for competing risks, and P_eQ is embedded using the transition rate matrix Q.)\n\n\n\n\nWe also see that regardless of the cycle length used, we always end up with the same calculated life expectancy:\n\n\n\n\n\nFigure 16: Life Expectancy by Sick-to-Dead Hazard Rate and Cycle Length\n\n\n\n\nWe have thus “fixed” our problem of hidden disease-related deaths!\n\nWhy is this important?\nThe use of an embedded transition probability matrix is important for a number of reasons:\n\nThe Markov model accurately reflects the underlying continuous time process.\nWe get an accurate accounting of disease-related deaths.\nWe can use whatever cycle length we need – this facilitates computationally intensive processes such as probabilistic sensitivity analyses, which may not be feasible with a short (e.g., daily) cycle length.\nWe also avoid “state explosion” in the event our model has tunnel states. For example, if there is a one-year tunnel state for costs or utilities following disease onset, if we switched to a monthly or daily cycle we’d have to build in dozens or more health states into our Markov model. Beacuse we can stick with a one-year cycle, this makes use of tunnel states much more feasible.\n\nThe primary “cost” of using this approach over standard rate-to-probability conversion formulas is that we must be a bit more careful in structuring our transition probability matrix to include accumulators used to aggregate model outputs. We will cover this process in the section directly below."
  },
  {
    "objectID": "blog/posts/embedding/embedding-a-transition-probability-matrix.html#include-non-markovian-accumulators-to-record-event-transitions",
    "href": "blog/posts/embedding/embedding-a-transition-probability-matrix.html#include-non-markovian-accumulators-to-record-event-transitions",
    "title": "Embedding A Transition Probability Matrix for a Discrete Time Markov Model",
    "section": "2. Include Non-Markovian Accumulators to Record Event Transitions",
    "text": "2. Include Non-Markovian Accumulators to Record Event Transitions\nWe now have the correct transition probabilities to model the underlying continuous-time process, but how do we account for these compound transitions in our aggregation of model outputs?\nFundamentally, what we have now is a model that will correctly records the “true” number of deaths at the end of the cycle, because all the compound Healthy Sick Dead transitions are included in the Healthy Dead transition probability.\nTo track the total number of transitions to Sick, we must augment our transition probability matrix with non-Markovian accumulators. This accumulator shows up as a purple edge in our model diagram below:\n\n\n\n\n\n\n\nG\n\n  \n\nHealthy\n\n Healthy   \n\nHealthy-&gt;Healthy\n\n    \n\nSick\n\n Sick   \n\nHealthy-&gt;Sick\n\n    \n\nDead\n\n Dead   \n\nHealthy-&gt;Dead\n\n    \n\nSick-&gt;Sick\n\n    \n\nSick-&gt;Dead\n\n    \n\nDead-&gt;Dead\n\n   \n\n\n\n\n\nFortunately, accumulators are easy to build in. We simply add the relevant transition rate in a new column in the transition rate matrix Q, while leaving everything else the same.\nSuppose we want to count up all the Healthy Sick transitions in the model. To do this we simply add the appropriate transition rate (\\(r_{HS}\\)) in as an accumulator column:\n\n\n\n\n\n\n\n\n\n\n\nHealthy\nSick\nDead\naccHS\n\n\n\n\nHealthy\n-(\\(r_{HS}\\) + \\(r_{HD}\\))\n\\(r_{HS}\\)\n\\(r_{HD}\\)\n\\(r_{HS}\\)\n\n\nSick\n0\n-(\\(hr_{S} \\cdot r_{HD}\\))\n\\(hr_{S} \\cdot r_{HD}\\)\n0\n\n\nDead\n0\n0\n0\n0\n\n\naccHS\n0\n0\n0\n0\n\n\n\nNote the following:\n\nAn extra row of 0’s was added so that we balance the matrix, and ensure that we do not lose (or create!) anyone who becomes Sick.\nWe did not update the diagonal elements (i.e., the negative sum of transition rates); these stay the same as before.\nIf we wanted to add additional accumulators, we can just expand the matrix with more columns and rows as needed.\n\nHere is the augmented transition rate matrix for our example:\n\n\nCode\nQ_ &lt;- data.frame(Q)\nQ_[\"Healthy\",\"accHS\"] &lt;- params$r_HS\nQ_[\"accHS\",\"accHS\"] &lt;- 0\nQ_[is.na(Q_)] &lt;- 0\nQ_ &lt;- as.matrix(Q_)\nQ_ \n\n\n        Healthy  Sick  Dead accHS\nHealthy  -0.156  0.15 0.006  0.15\nSick      0.000 -0.06 0.060  0.00\nDead      0.000  0.00 0.000  0.00\naccHS     0.000  0.00 0.000  0.00\n\n\nWe next embed the transition probability matrix, as before:Notice that the accumulator (accHS) value is identical to the Healthy Sick transition probability we obtained using the alternative rate-to-probability conversion formula that accounted for competing risks (e.g., see Figure 10).\n\nP_ &lt;- expm(Q_)\nP_\n\n          Healthy      Sick        Dead     accHS\nHealthy 0.8555592 0.1346958 0.009744961 0.1388854\nSick    0.0000000 0.9417645 0.058235466 0.0000000\nDead    0.0000000 0.0000000 1.000000000 0.0000000\naccHS   0.0000000 0.0000000 0.000000000 1.0000000\n\n\nUsing the accumulator we can accurately count up how many individuals transition to the Sick state over our time horizon:\n\nm_trace &lt;- \n  0:(horizon/cycle) %&gt;% \n  map_df(~(c(1000,0,0,0) %*% (P_%^%.x) %&gt;% data.frame()))\n\n\n\nCode\nm_trace[3,] %&gt;% \n  round(.,2) %&gt;% \n  rownames_to_column(var=\"cycle\") %&gt;% \n  select(-cycle) %&gt;% \n  kable() %&gt;% \n  kableExtra::kable_styling()\n\n\n\n\n\n\n\n\nHealthy\n\n\nSick\n\n\nDead\n\n\naccHS\n\n\n\n\n\n\n731.98\n\n\n242.09\n\n\n25.93\n\n\n257.71\n\n\n\n\n\nFigure 17: State Occupancy after Two Years\n\n\n\nWe see in Figure 17 that after 2 years, 257.7 people (out of 1,000) have become sick, which is slightly less than the 259 who became sick after 2 years in our world without death as a competing risk. Moreover, we see that state occupancy in the Sick category is lower, at 242.1. This lower value reflects the fact some people had a compound transition through Sick and ended up dead in the same cycle. The difference (15.6) amounts to the total number of individual deaths we “hid” in the model when we used the incorrect rate-to-probability conversion formulas.This, of course, makes sense, since there are a small number of people who die before they could become ill once we add background mortality to the model"
  },
  {
    "objectID": "blog/posts/psa-quantiles/index.html",
    "href": "blog/posts/psa-quantiles/index.html",
    "title": "Parameters for Distributions",
    "section": "",
    "text": "Source Another source Excel Functions\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\nNormal Distribution\n\\[\n\\sigma = \\frac{x_2 - x_1}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\tag{1}\\]\n\\[\n\\mu = \\frac{x_1\\Phi^{-1}(p_2)-x_2\\Phi^{-1}(p_1)}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\]\n\nx1 &lt;- qnorm(0.1,1.3,.2)\np1 &lt;- 0.1\n\nx2 &lt;- qnorm(0.9,1.3,.2)\np2 &lt;- 0.9\n\nparam_normal &lt;- function(x1,x2,p1,p2) {\n    sigma = (x2 - x1) / (qnorm(p2,0,1)-qnorm(p1,0,1)); sigma\n    mu &lt;- (x1*qnorm(p2,0,1)-x2*qnorm(p1,0,1))/(qnorm(p2,0,1)-qnorm(p1,0,1)); mu\n    \n    c(\"mu\" = mu, \"sigma\" = sigma)\n}\n\n\n\nGamma\n\nx1 &lt;- 0.6\nx2 &lt;- 0.8\np1 &lt;- 0.1\np2 &lt;- 0.9\n\ngamma_fn &lt;- function(alpha) {\n    x1*qgamma(p2,shape = alpha, scale =1) - x2 * qgamma(p1, shape = alpha, scale = 1)\n}\n\ncalc_beta &lt;- function(x1,p1,alpha) {\n    x1 / qgamma(p1,alpha,1)\n}\n\ncurve(gamma_fn, xlim = c(1,100), col = \"blue\", lwd = 1.5, lty=2)\nabline(a=0,b=0)\n\n\n\nalpha_ &lt;- uniroot(gamma_fn,c(70,85))$root; alpha_\n\n[1] 79.74756\n\nbeta_ &lt;- calc_beta(x1 = x1,  p1 = p1, alpha = alpha_); beta_\n\n[1] 0.008754199\n\n# Check the answer\nqgamma(0.1,shape = alpha_, scale = beta_)\n\n[1] 0.6\n\nqgamma(0.9,shape = alpha_, scale = beta_)\n\n[1] 0.8\n\nparam_gamma &lt;- function(x1,x2,p1,p2,range) {\n    alpha_ &lt;- uniroot(gamma_fn,range)$root; alpha_\n    beta_ &lt;- calc_beta(x1 = x1,  p1 = p1, alpha = alpha_); beta_\n    \n    c(\"alpha\" = alpha_, \"beta\" = beta_)\n}\nparam_gamma(x1= x1, x2 = x2, p1 = p1, p2 = p2, range = c(60,100))\n\n       alpha         beta \n79.747557736  0.008754199 \n\n\n\n\nBeta Distribution\n\n# Source: https://stats.stackexchange.com/questions/112614/determining-beta-distribution-parameters-alpha-and-beta-from-two-arbitrary\n\nx1 &lt;- 0.6\nx2 &lt;- 0.8\np1 &lt;- 0.1\np2 &lt;- 0.9\n\n# Logistic transformation of the Beta CDF.\nf.beta &lt;- function(alpha, beta, x, lower=0, upper=1) {\n  p &lt;- pbeta((x-lower)/(upper-lower), alpha, beta)\n  log(p/(1-p))\n}\n\n# Sums of squares.\ndelta &lt;- function(fit, actual) sum((fit-actual)^2)\n\n# The objective function handles the transformed parameters `theta` and\n# uses `f.beta` and `delta` to fit the values and measure their discrepancies.\nobjective &lt;- function(theta, x, prob, ...) {\n  ab &lt;- exp(theta) # Parameters are the *logs* of alpha and beta\n  fit &lt;- f.beta(ab[1], ab[2], x, ...)\n  return (delta(fit, prob))\n}\n\nx.p &lt;- (function(p) log(p/(1-p)))(c(p1, p2))\nstart &lt;- log(c(1e1, 1e1))\nsol &lt;- nlm(objective, start, x=c(x1,x2), prob=x.p, lower=0, upper=1, typsize=c(1,1), fscale=1e-12, gradtol=1e-12)\n\nWarning in nlm(objective, start, x = c(x1, x2), prob = x.p, lower = 0, upper =\n1, : NA/Inf replaced by maximum positive value\n\nWarning in nlm(objective, start, x = c(x1, x2), prob = x.p, lower = 0, upper =\n1, : NA/Inf replaced by maximum positive value\n\nparams &lt;- exp(sol$estimate); params\n\n[1] 23.70741 10.03106\n\nqbeta(p = c(p1, p2), params[1], params[2])\n\n[1] 0.6000000 0.8000001\n\n\n\n# Step 1: Define the parameters and uncertainty distributions.\n\nw1 = 2\nw1.low = 1.75\nw1.hi = 2.25\np1.low = 0.1\np1.hi = 0.9\n\nc1 = 1\nc1.low = 1\nc1.hi = 1\np1.low = 0.1\np1.hi = 0.9\n\nw2 = 1\nw2.low = 1\nw2.hi = 1\n\nc2 = 0.85\nc2.low = 0.75\nc2.hi = 0.95\np2.low = 0.1\np2.hi = 0.9\n\nx1 = c2.low\nx2 = c2.hi\np1 = p2.low\np2 = p2.hi\ndist = \"unif\"\n\nget_dist_params &lt;- function(x1, x2, p1, p2, dist = \"unif\", range = NULL) {\n    \n    if (dist==\"unif\") {\n        get_min_unif &lt;- function(x1, x2, p1, p2) {\n            (p2*x1-p1*x2) / (p2 - p1) \n        }\n        get_max_unif &lt;- function(x1, x2, p1 , p2) {\n            ((1-p1)*x2-(1-p2)*x1)/(p2-p1)\n        }\n        get_avg_unif &lt;- function(x1, x2, p1, p2) {\n            mean(c(get_min_unif(x1 = x1, x2 = x2, p1 = p1, p2 = p2),\n                   get_max_unif(x1 = x1, x2 = x2, p1 = p1, p2 = p2)))\n        }\n        \n        params &lt;- c(mean = get_avg_unif(x1 = x1, x2 = x2, p1 = p1, p2 = p2), \n                    median = get_avg_unif(x1 = x1, x2 = x2, p1 = p1, p2 = p2),\n                    min = get_min_unif(x1 = x1, x2 = x2, p1 = p1, p2 = p2),\n                    max = get_max_unif(x1 = x1, x2 = x2, p1 = p1, p2 = p2))\n        attr(params,\"dist\") = \"uniform\"\n    }\n    \n    if (dist == \"norm\") {\n        param_norm &lt;- function(x1,x2,p1,p2) {\n            sigma = (x2 - x1) / (qnorm(p2,0,1)-qnorm(p1,0,1)); sigma\n            mu &lt;- (x1*qnorm(p2,0,1)-x2*qnorm(p1,0,1))/(qnorm(p2,0,1)-qnorm(p1,0,1)); mu\n            \n            c(\"mean\" = mu, \"sd\" = sigma)\n        }\n        \n        params = param_norm(x1 = x1, x2 = x2, p1 = p1, p2 = p2)\n        attr(params,\"dist\") = \"normal\"\n    }\n    \n    if (dist == \"lognorm\") {\n        get_mean_of_log &lt;- function(x1, x2, p1, p2) {\n            (qnorm(p2,0,1)*log(x1)-qnorm(p1,0,1)*log(x2)) / (qnorm(p2,0,1)-qnorm(p1,0,1))\n        }\n        mean_of_log &lt;- get_mean_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2)\n        \n        get_sd_of_log &lt;- function(x1, x2, p1 , p2) {\n            (log(x2) - log(x1)) / (qnorm(p2,0,1) - qnorm(p1,0,1))\n        }\n        sd_of_log &lt;- get_sd_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2)\n        \n        # params &lt;- c(\"mean\" = exp(get_mean_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2) + 0.5 * get_sd_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2)^2),\n        #   \"median\" = exp(get_mean_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2)),\n        #   \"sd\" = sqrt((exp(get_sd_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2)^2)-1) * exp(2 * get_mean_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2) + \n        #                                                                                      get_sd_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2)^2)))\n        \n        params &lt;- c(\"mean_log\" = get_mean_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2), \n                    \"sd_log\" = get_sd_of_log(x1 = x1, x2 = x2, p1 = p1, p2 = p2))\n        attr(params,\"dist\") = \"lognormal\"\n\n    }\n    \n    if (dist == \"gamma\") {\n        gamma_fn &lt;- function(alpha) {\n            x1*qgamma(p2,shape = alpha, scale =1) - x2 * qgamma(p1, shape = alpha, scale = 1)\n        }\n        \n        calc_beta &lt;- function(x1,p1,alpha) {\n            x1 / qgamma(p1,alpha,1)\n        }\n        \n        #curve(gamma_fn, xlim = c(1,100), col = \"blue\", lwd = 1.5, lty=2)\n        #abline(a=0,b=0)\n        \n        alpha_ &lt;- uniroot(gamma_fn,c(1,100))$root; alpha_\n        beta_ &lt;- calc_beta(x1 = x1,  p1 = p1, alpha = alpha_); beta_\n    }\n    return(params)\n    \n}\n\n\nget_dist_params(x1 = w1.low, x2 = w1.hi, p1 = p1.low, p2 = p1.hi, dist = \"lognorm\" )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndisc_power &lt;- function(fit) {\n    beta.hat &lt;- fit[\"W\",]\n    accept &lt;- 1-as.integer(dplyr::between(0,beta.hat[,2],beta.hat[,3]))\n    return(accept)\n}\n\nX_W(n_=1000, p_treat=0.5, tau=60) %&gt;% \n    est() %&gt;% \n    disc_power()\n\n\nval.stat.life = 9600000\n\nsurv.1 &lt;- 0.987\nsurv.0 &lt;- 0.97\n\nval.stat.life*(surv.1-surv.0)\n\n\nw.eitc &lt;- 1\nc.eitc &lt;- rgamma(1e3,rate = 89,shape=1); mean(c.eitc)\n\nhttps://www.johndcook.com/quantiles_parameters.pdf\n\n\nqnorm(0.1, mean = 1, sd = 1)\n\nx1 &lt;- qnorm(0.1,1.3,.2)\np1 &lt;- 0.1\n\nx2 &lt;- qnorm(0.9,1.3,.2)\np2 &lt;- 0.9\n\nparam_normal &lt;- function(x1,x2,p1,p2) {\n    sigma = (x2 - x1) / (qnorm(p2,0,1)-qnorm(p1,0,1)); sigma\n    mu &lt;- (x1*qnorm(p2,0,1)-x2*qnorm(p1,0,1))/(qnorm(p2,0,1)-qnorm(p1,0,1)); mu\n    \n    c(\"mu\" = mu, \"sigma\" = sigma)\n}\n\nparam_normal(x1 = 3, p1 = .1, x2 = 5, p2 = .9)"
  },
  {
    "objectID": "blog/posts/appendix/index.html",
    "href": "blog/posts/appendix/index.html",
    "title": "Supplemental Appendix",
    "section": "",
    "text": "This section provides advice on best practices for embedding literature-based parameters into discrete-time Markov models so that the final transition probabilities accurately represent the underlying continuous time process.\n\n\nIt is common to draw upon literature-based parameters when constructing a Markov model. A key first step is to assess the parameters of interest in a published study. For a given paper with published rates, thsi means determining whether they report a percentrage affected in a given time step, or continuous rates. While the units of both of these are essentially equivalent (by a factor of 100), the interpretation is different. It is a subtle but important difference.\nFor example, let’s assume that a stochastic event occurs to a group of individuals with a rate of 1/unit time. This follows an exponential distribution. We first create a sample of 20000 individuals.\n\nx &lt;- rexp(20000)\n\nhist(x)\n\n\n\nmean(x)\n\n[1] 1.011341\n\nmedian(x)\n\n[1] 0.7090352\n\n# Percentage in first time cycle\nsum(x &lt; 1) / length(x)\n\n[1] 0.62495\n\n\nThe mean is close to 1, but the percentage observed in the first time cycle is close to the theoretical 63.2%. This appears counter-intuitive but the long tail of the exponential distribution creates a situation where the continuous rate is not the observed percentage in a time cycle.\nThis leads to the widely-used rate-to-probability conversion formula:\n\\[p = 1 - e^{-r}\\] \\[r = -log(1-p)\\] where \\(p\\) represents the probability in a unit of time and \\(r\\) represents the continuous rate.\nWhen constructing a Markov model, it is best to start with the continuous rate when aggregating from many sources and embed this continuous rate into a timestep—thus creating probability transitions for each time step.\nTo find the probability transition matrix of a timestep in Markov modeling from the continuous the following formula is used:\n\\[ T_{prob} = e^{R} \\]\nWhere \\(R\\) is the continuous rate matrix, and each diagonal is the negative sum of the rest of the row elements. \\(T_{prob}\\) is the transition probability for a single time step, where each diagonal is 1 - the sum of the other row elements.\nOne could have rates that change at each time step and this would return the proper embedding of the rates allowing for them to compete.\n\n\n\nWhat if a given source of data provides observed transition probabilities and these are exclusionary states, i.e., competing? How could one reverse these probabilities and embed other competing events into the model?\nTo do this, one must solve for the generator matrix of the transition probability matrix using eigenvalue decomposition. Note that this is not always possible, as it is trivial to construct a transition probability matrix that has no generator.\nConsider the following, which builds on the example provided in the main text. We wish to approximate a continuous time process using a discrete-time Markov model with three distinct states: A (healthy), B (sick/intervention), and C (complication from intervention). Moreover, in continuous time, this process proceeds sequentially, i.e., A-&gt;B-&gt;C.\nA (naively) specified model has transitions from A-&gt;B and from B-&gt;C specified as probabilities within the selected time step. As noted in the main text, this model cannot truly approximate continuous time process, as within a given time step there is a non-zero probability of transitioning from healthy to complication (i.e., A-&gt;C, with an implied sojourn through B). That is, during a timestep it is possible to transition from A-&gt;C.\nBy incorrectly specifying all transitions, it makes it impossible to find a proper generator—though eigenvalue decomposition can be used to get as close as possible. If negative rates of transition are found using eigenvalue decomposition, then probabilities inconsistent with continuous rates have been specified.\nIn mathematical terms, the generator matrix is the matrix logarithm of the transition probability matrix. A matrix has a logarithm if and only if if it is invertible.\n\\[ A = \\log T_{prob} \\]\nThe \\(\\log\\) can be found using spectral or eigenvalue decomposition. If \\(V\\) is a matrix where equal column is an eigenvector of \\(T_{prob}\\), then,\n\\[A' = V^{-1} A V\\] \\[\\log T_{prob} = V (\\log A') V^{-1}\\]\n\n\nAs an example, we’ll consider a model from “Decision Modelling for Heath Economic Evaluation” by Briggs, Clatxon, and Sculpher. In Table 2.2, they define a transition probability matrix for HIV monotherapy that was derived from observed percent transitions in a patient cohort.\n\nhiv_monotherapy_tp &lt;- matrix(c(0.721, 0.202, 0.067, 0.010,\n                               0.000, 0.581, 0.407, 0.012,\n                               0.000, 0.000, 0.750, 0.250,\n                               0.000, 0.000, 0.000, 1.000), \n                               nrow=4, byrow=TRUE,\n                               dimnames=list(c(\"A\", \"B\", \"C\", \"D\"),\n                                             c(\"A\", \"B\", \"C\", \"D\")))\nhiv_monotherapy_tp                                          \n\n      A     B     C     D\nA 0.721 0.202 0.067 0.010\nB 0.000 0.581 0.407 0.012\nC 0.000 0.000 0.750 0.250\nD 0.000 0.000 0.000 1.000\n\n\nThe bottom diagonal was corrected to be a Markov absorbing state by having 1 on the diagonal. For the purposes of example, we’ll assume we wish to add an additional state “E”, which has a continuous rate of 0.2 that competes with other transitions.\nTo accomplish this we must find the continuous generator.\n\nV  &lt;- eigen(hiv_monotherapy_tp)$vectors\niV &lt;- solve(V)\nAp &lt;- iV %*% hiv_monotherapy_tp %*% V\n\nAp\n\n              [,1]          [,2]          [,3]          [,4]\n[1,]  1.000000e+00 -1.138759e-17  0.000000e+00  1.625347e-17\n[2,]  1.724225e-16  7.500000e-01  0.000000e+00 -1.565421e-16\n[3,] -1.054209e-15 -1.977467e-16  7.210000e-01  3.654408e-17\n[4,] -6.257371e-17 -1.879313e-17 -5.963692e-18  5.810000e-01\n\n\nDue to the numeric probabilities not being exactly correct, the off-diagonal elements of \\(A'\\) are not zero, but they are quite close. We will zero these off diagonal elements and assume that the non-zero elements are numerical error. Then continue by taking the log of the diagonal.\n\nlAp &lt;- diag(log(diag(Ap)), nrow(Ap), ncol(Ap))\n\nR  &lt;- V %*% lAp %*% iV\n\nR \n\n              [,1]          [,2]         [,3]        [,4]\n[1,] -3.271161e-01  3.114961e-01  0.002439536  0.01318051\n[2,]  2.558460e-18 -5.430045e-01  0.614888976 -0.07188445\n[3,]  0.000000e+00  7.064112e-18 -0.287682072  0.28768207\n[4,]  0.000000e+00  0.000000e+00  0.000000000  0.00000000\n\n\nAn now we have the continuous time rate generator for the Markov Model. There is still some numerical error—for example the bottom row, has values very near to zero, and the diagonal is not exactly the negative sum of the rest of the row. We can clean this up by tweaking the numbers numerical towards their constraints.\n\nR[abs(R) &lt; 1e-6 ] &lt;- 0\n\n\nrownames(R) &lt;- c(\"A\", \"B\", \"C\", \"D\")\ncolnames(R) &lt;- c(\"A\", \"B\", \"C\", \"D\")\n\nround(R, 3)\n\n       A      B      C      D\nA -0.327  0.311  0.002  0.013\nB  0.000 -0.543  0.615 -0.072\nC  0.000  0.000 -0.288  0.288\nD  0.000  0.000  0.000  0.000\n\n\nSome numerical error is inevitable in this process and cannot be avoided. However, even cleaning up the small and obvious errors, the transition from B -&gt; D is impossible since it’s negative. Rates are relative to the occupancy of the source state, in this case B. Having a negative rate implies that B would have some transitions in which the dead come alive into B based upon the occupancy of B. Obviously, this is not possible. The problem now is how to adjust the model’s rates to be physically possible, while as faithful to the original data as possible. B is a sicker state, so it should have a higher death rate.\nFirst, let’s double check it recapitulates the original rates.\n\nexpm(R)\n\n4 x 4 Matrix of class \"dgeMatrix\"\n      A     B     C     D\nA 0.721 0.202 0.067 0.010\nB 0.000 0.581 0.407 0.012\nC 0.000 0.000 0.750 0.250\nD 0.000 0.000 0.000 1.000\n\n\nWhich exactly matches the original transition probability table given.\nNext, lets’ assume that one has to pass into state C to die and the original data didn’t have frequent enough measurements to detect all the transitions.\n\n# A more plausible death rate for 'A', 'B'\nR['A', 'D'] &lt;- 0\nR['B', 'D'] &lt;- 0\n\ndiag(R) &lt;- diag(R) - rowSums(R) # Keep it Markovian\nround(expm(R), 3)\n\n4 x 4 Matrix of class \"dgeMatrix\"\n      A     B     C     D\nA 0.731 0.197 0.066 0.007\nB 0.000 0.541 0.393 0.066\nC 0.000 0.000 0.750 0.250\nD 0.000 0.000 0.000 1.000\n\n\nThe rate from A-&gt;D is within error of the original study. However, deaths from B are at a much higher rate. This is all under the assumption that one must pass through C to die, and the adjusted transitions reflect this.\nNow one could add a competing event to to the model as a rate adding a new row column with it’s defined rates and compute the updated transition probability matrix.\nThese difficulties of working backward from probabilities unscore the importance of having the original estimates be rates that have been adjusted to be the non-competing rate (e.g., based on survival models).\n\n\n\n\nThe above examples also illustrate another difficulty: correctly summarizing costs and utilities in the presence of implied “jumpover” states. For example, we zeroed the rate of A-&gt;D, yet the final transition matrix contains that transition.\nAssume that the transition B-&gt;C entailed a cost, given that some of the population goes A-&gt;B-&gt;C-&gt;D these transitions are hidden in the embedded transition matrix, yet a summary of the number of B-&gt;C transitions is needed for a time step. One can solve this by adding non-Markovian states or accumulator states to track these transitions.\nThe diagonal term of the transition intensity matrix is the negative sum of all Markovian states. Additional rows and columns can be added that violate the principal that total state occupancy cannot be created or destroyed, by simply leaving them out of the balancing term of the diagonal.\n\nRwAcc &lt;- cbind(rbind(R, rep(0, 4)), rep(0, 5))\nrownames(RwAcc) &lt;- c(\"A\", \"B\", \"C\", \"D\", \"AccBC\")\ncolnames(RwAcc) &lt;- c(\"A\", \"B\", \"C\", \"D\", \"AccBC\")\n\nRwAcc['B', 'AccBC'] &lt;- RwAcc['B', 'C']\nround(expm(RwAcc), 3)\n\n5 x 5 Matrix of class \"dgeMatrix\"\n          A     B     C     D AccBC\nA     0.731 0.197 0.066 0.007 0.071\nB     0.000 0.541 0.393 0.066 0.459\nC     0.000 0.000 0.750 0.250 0.000\nD     0.000 0.000 0.000 1.000 0.000\nAccBC 0.000 0.000 0.000 0.000 1.000\n\n\nNote that once embedded into probabilities, there is a transition from A-&gt;AccBC which tracks how many transitions from A-&gt;B-&gt;C and B-&gt;C occur. The original rate specified was zero for A-&gt;AccBC, but due to jumping states this now has a non-zero probability and the accumulator is able to track this.\nIdealy the original rate estimates would have assumed a structural model that was sensible and rates could be estimated to match the data. This is a statistical modeling problem outside the scope of this appendix.\nFor the sake of organization, it is recommended that the upper left matrix remain the original Markov and all the non-Markovian rows be to the bottom and right of the matrix.\n\n\n\nAnother problem that occurs is that of non-stationary rates. What if a rate is changing over an interval time step? How is this best modeled? A first order approach would be to simply take the mean of the rates at either time point. A higher order approach is to integrate the total risk exposure over the time interval.\n\\[r_{e} = \\int_{t_1}^{t_2} r(t) dt\\] This computes the effective rate \\(r_e\\) from a time varying rate, \\(r(t)\\).\nFor example, in our applications the probability of death from outside causes could be modeled based on mortality tables using a Gompertz distribution with a shape \\(a\\) and rate \\(b\\) parameter. The hazard function of a distribution is the continuous rate function. The hazard function can be derived from the probability density function (PDF) divided by 1 minus cumulative probability function (CDF). For the Gompertz this is,\n\\[h(t) = \\frac{f(t)}{1-F(t)} = \\frac{b e^{at} e^{-b/a(e^{at}-1)}}{e^{-b/a (e^{at}-1)}} = b e^{at}\\]\nFrom this the effective rate over a timestep of a discrete Markov simulation can be computed.\n\\[r_{e} = \\int_{t_1}^{t_2} b e^{at} dt = \\frac{b}{a} (e^{at_2} - e^{at_1})\\]\nWhile this exists as an anayltical result, in general it’s better to use the effective risk over a time interval as this leads to improved accuracy of a simulation."
  },
  {
    "objectID": "blog/posts/appendix/index.html#rates-vs.-percentages",
    "href": "blog/posts/appendix/index.html#rates-vs.-percentages",
    "title": "Supplemental Appendix",
    "section": "",
    "text": "It is common to draw upon literature-based parameters when constructing a Markov model. A key first step is to assess the parameters of interest in a published study. For a given paper with published rates, thsi means determining whether they report a percentrage affected in a given time step, or continuous rates. While the units of both of these are essentially equivalent (by a factor of 100), the interpretation is different. It is a subtle but important difference.\nFor example, let’s assume that a stochastic event occurs to a group of individuals with a rate of 1/unit time. This follows an exponential distribution. We first create a sample of 20000 individuals.\n\nx &lt;- rexp(20000)\n\nhist(x)\n\n\n\nmean(x)\n\n[1] 1.011341\n\nmedian(x)\n\n[1] 0.7090352\n\n# Percentage in first time cycle\nsum(x &lt; 1) / length(x)\n\n[1] 0.62495\n\n\nThe mean is close to 1, but the percentage observed in the first time cycle is close to the theoretical 63.2%. This appears counter-intuitive but the long tail of the exponential distribution creates a situation where the continuous rate is not the observed percentage in a time cycle.\nThis leads to the widely-used rate-to-probability conversion formula:\n\\[p = 1 - e^{-r}\\] \\[r = -log(1-p)\\] where \\(p\\) represents the probability in a unit of time and \\(r\\) represents the continuous rate.\nWhen constructing a Markov model, it is best to start with the continuous rate when aggregating from many sources and embed this continuous rate into a timestep—thus creating probability transitions for each time step.\nTo find the probability transition matrix of a timestep in Markov modeling from the continuous the following formula is used:\n\\[ T_{prob} = e^{R} \\]\nWhere \\(R\\) is the continuous rate matrix, and each diagonal is the negative sum of the rest of the row elements. \\(T_{prob}\\) is the transition probability for a single time step, where each diagonal is 1 - the sum of the other row elements.\nOne could have rates that change at each time step and this would return the proper embedding of the rates allowing for them to compete."
  },
  {
    "objectID": "blog/posts/appendix/index.html#competing-events",
    "href": "blog/posts/appendix/index.html#competing-events",
    "title": "Supplemental Appendix",
    "section": "",
    "text": "What if a given source of data provides observed transition probabilities and these are exclusionary states, i.e., competing? How could one reverse these probabilities and embed other competing events into the model?\nTo do this, one must solve for the generator matrix of the transition probability matrix using eigenvalue decomposition. Note that this is not always possible, as it is trivial to construct a transition probability matrix that has no generator.\nConsider the following, which builds on the example provided in the main text. We wish to approximate a continuous time process using a discrete-time Markov model with three distinct states: A (healthy), B (sick/intervention), and C (complication from intervention). Moreover, in continuous time, this process proceeds sequentially, i.e., A-&gt;B-&gt;C.\nA (naively) specified model has transitions from A-&gt;B and from B-&gt;C specified as probabilities within the selected time step. As noted in the main text, this model cannot truly approximate continuous time process, as within a given time step there is a non-zero probability of transitioning from healthy to complication (i.e., A-&gt;C, with an implied sojourn through B). That is, during a timestep it is possible to transition from A-&gt;C.\nBy incorrectly specifying all transitions, it makes it impossible to find a proper generator—though eigenvalue decomposition can be used to get as close as possible. If negative rates of transition are found using eigenvalue decomposition, then probabilities inconsistent with continuous rates have been specified.\nIn mathematical terms, the generator matrix is the matrix logarithm of the transition probability matrix. A matrix has a logarithm if and only if if it is invertible.\n\\[ A = \\log T_{prob} \\]\nThe \\(\\log\\) can be found using spectral or eigenvalue decomposition. If \\(V\\) is a matrix where equal column is an eigenvector of \\(T_{prob}\\), then,\n\\[A' = V^{-1} A V\\] \\[\\log T_{prob} = V (\\log A') V^{-1}\\]\n\n\nAs an example, we’ll consider a model from “Decision Modelling for Heath Economic Evaluation” by Briggs, Clatxon, and Sculpher. In Table 2.2, they define a transition probability matrix for HIV monotherapy that was derived from observed percent transitions in a patient cohort.\n\nhiv_monotherapy_tp &lt;- matrix(c(0.721, 0.202, 0.067, 0.010,\n                               0.000, 0.581, 0.407, 0.012,\n                               0.000, 0.000, 0.750, 0.250,\n                               0.000, 0.000, 0.000, 1.000), \n                               nrow=4, byrow=TRUE,\n                               dimnames=list(c(\"A\", \"B\", \"C\", \"D\"),\n                                             c(\"A\", \"B\", \"C\", \"D\")))\nhiv_monotherapy_tp                                          \n\n      A     B     C     D\nA 0.721 0.202 0.067 0.010\nB 0.000 0.581 0.407 0.012\nC 0.000 0.000 0.750 0.250\nD 0.000 0.000 0.000 1.000\n\n\nThe bottom diagonal was corrected to be a Markov absorbing state by having 1 on the diagonal. For the purposes of example, we’ll assume we wish to add an additional state “E”, which has a continuous rate of 0.2 that competes with other transitions.\nTo accomplish this we must find the continuous generator.\n\nV  &lt;- eigen(hiv_monotherapy_tp)$vectors\niV &lt;- solve(V)\nAp &lt;- iV %*% hiv_monotherapy_tp %*% V\n\nAp\n\n              [,1]          [,2]          [,3]          [,4]\n[1,]  1.000000e+00 -1.138759e-17  0.000000e+00  1.625347e-17\n[2,]  1.724225e-16  7.500000e-01  0.000000e+00 -1.565421e-16\n[3,] -1.054209e-15 -1.977467e-16  7.210000e-01  3.654408e-17\n[4,] -6.257371e-17 -1.879313e-17 -5.963692e-18  5.810000e-01\n\n\nDue to the numeric probabilities not being exactly correct, the off-diagonal elements of \\(A'\\) are not zero, but they are quite close. We will zero these off diagonal elements and assume that the non-zero elements are numerical error. Then continue by taking the log of the diagonal.\n\nlAp &lt;- diag(log(diag(Ap)), nrow(Ap), ncol(Ap))\n\nR  &lt;- V %*% lAp %*% iV\n\nR \n\n              [,1]          [,2]         [,3]        [,4]\n[1,] -3.271161e-01  3.114961e-01  0.002439536  0.01318051\n[2,]  2.558460e-18 -5.430045e-01  0.614888976 -0.07188445\n[3,]  0.000000e+00  7.064112e-18 -0.287682072  0.28768207\n[4,]  0.000000e+00  0.000000e+00  0.000000000  0.00000000\n\n\nAn now we have the continuous time rate generator for the Markov Model. There is still some numerical error—for example the bottom row, has values very near to zero, and the diagonal is not exactly the negative sum of the rest of the row. We can clean this up by tweaking the numbers numerical towards their constraints.\n\nR[abs(R) &lt; 1e-6 ] &lt;- 0\n\n\nrownames(R) &lt;- c(\"A\", \"B\", \"C\", \"D\")\ncolnames(R) &lt;- c(\"A\", \"B\", \"C\", \"D\")\n\nround(R, 3)\n\n       A      B      C      D\nA -0.327  0.311  0.002  0.013\nB  0.000 -0.543  0.615 -0.072\nC  0.000  0.000 -0.288  0.288\nD  0.000  0.000  0.000  0.000\n\n\nSome numerical error is inevitable in this process and cannot be avoided. However, even cleaning up the small and obvious errors, the transition from B -&gt; D is impossible since it’s negative. Rates are relative to the occupancy of the source state, in this case B. Having a negative rate implies that B would have some transitions in which the dead come alive into B based upon the occupancy of B. Obviously, this is not possible. The problem now is how to adjust the model’s rates to be physically possible, while as faithful to the original data as possible. B is a sicker state, so it should have a higher death rate.\nFirst, let’s double check it recapitulates the original rates.\n\nexpm(R)\n\n4 x 4 Matrix of class \"dgeMatrix\"\n      A     B     C     D\nA 0.721 0.202 0.067 0.010\nB 0.000 0.581 0.407 0.012\nC 0.000 0.000 0.750 0.250\nD 0.000 0.000 0.000 1.000\n\n\nWhich exactly matches the original transition probability table given.\nNext, lets’ assume that one has to pass into state C to die and the original data didn’t have frequent enough measurements to detect all the transitions.\n\n# A more plausible death rate for 'A', 'B'\nR['A', 'D'] &lt;- 0\nR['B', 'D'] &lt;- 0\n\ndiag(R) &lt;- diag(R) - rowSums(R) # Keep it Markovian\nround(expm(R), 3)\n\n4 x 4 Matrix of class \"dgeMatrix\"\n      A     B     C     D\nA 0.731 0.197 0.066 0.007\nB 0.000 0.541 0.393 0.066\nC 0.000 0.000 0.750 0.250\nD 0.000 0.000 0.000 1.000\n\n\nThe rate from A-&gt;D is within error of the original study. However, deaths from B are at a much higher rate. This is all under the assumption that one must pass through C to die, and the adjusted transitions reflect this.\nNow one could add a competing event to to the model as a rate adding a new row column with it’s defined rates and compute the updated transition probability matrix.\nThese difficulties of working backward from probabilities unscore the importance of having the original estimates be rates that have been adjusted to be the non-competing rate (e.g., based on survival models)."
  },
  {
    "objectID": "blog/posts/appendix/index.html#state-jumping",
    "href": "blog/posts/appendix/index.html#state-jumping",
    "title": "Supplemental Appendix",
    "section": "",
    "text": "The above examples also illustrate another difficulty: correctly summarizing costs and utilities in the presence of implied “jumpover” states. For example, we zeroed the rate of A-&gt;D, yet the final transition matrix contains that transition.\nAssume that the transition B-&gt;C entailed a cost, given that some of the population goes A-&gt;B-&gt;C-&gt;D these transitions are hidden in the embedded transition matrix, yet a summary of the number of B-&gt;C transitions is needed for a time step. One can solve this by adding non-Markovian states or accumulator states to track these transitions.\nThe diagonal term of the transition intensity matrix is the negative sum of all Markovian states. Additional rows and columns can be added that violate the principal that total state occupancy cannot be created or destroyed, by simply leaving them out of the balancing term of the diagonal.\n\nRwAcc &lt;- cbind(rbind(R, rep(0, 4)), rep(0, 5))\nrownames(RwAcc) &lt;- c(\"A\", \"B\", \"C\", \"D\", \"AccBC\")\ncolnames(RwAcc) &lt;- c(\"A\", \"B\", \"C\", \"D\", \"AccBC\")\n\nRwAcc['B', 'AccBC'] &lt;- RwAcc['B', 'C']\nround(expm(RwAcc), 3)\n\n5 x 5 Matrix of class \"dgeMatrix\"\n          A     B     C     D AccBC\nA     0.731 0.197 0.066 0.007 0.071\nB     0.000 0.541 0.393 0.066 0.459\nC     0.000 0.000 0.750 0.250 0.000\nD     0.000 0.000 0.000 1.000 0.000\nAccBC 0.000 0.000 0.000 0.000 1.000\n\n\nNote that once embedded into probabilities, there is a transition from A-&gt;AccBC which tracks how many transitions from A-&gt;B-&gt;C and B-&gt;C occur. The original rate specified was zero for A-&gt;AccBC, but due to jumping states this now has a non-zero probability and the accumulator is able to track this.\nIdealy the original rate estimates would have assumed a structural model that was sensible and rates could be estimated to match the data. This is a statistical modeling problem outside the scope of this appendix.\nFor the sake of organization, it is recommended that the upper left matrix remain the original Markov and all the non-Markovian rows be to the bottom and right of the matrix."
  },
  {
    "objectID": "blog/posts/appendix/index.html#non-stationary-rates",
    "href": "blog/posts/appendix/index.html#non-stationary-rates",
    "title": "Supplemental Appendix",
    "section": "",
    "text": "Another problem that occurs is that of non-stationary rates. What if a rate is changing over an interval time step? How is this best modeled? A first order approach would be to simply take the mean of the rates at either time point. A higher order approach is to integrate the total risk exposure over the time interval.\n\\[r_{e} = \\int_{t_1}^{t_2} r(t) dt\\] This computes the effective rate \\(r_e\\) from a time varying rate, \\(r(t)\\).\nFor example, in our applications the probability of death from outside causes could be modeled based on mortality tables using a Gompertz distribution with a shape \\(a\\) and rate \\(b\\) parameter. The hazard function of a distribution is the continuous rate function. The hazard function can be derived from the probability density function (PDF) divided by 1 minus cumulative probability function (CDF). For the Gompertz this is,\n\\[h(t) = \\frac{f(t)}{1-F(t)} = \\frac{b e^{at} e^{-b/a(e^{at}-1)}}{e^{-b/a (e^{at}-1)}} = b e^{at}\\]\nFrom this the effective rate over a timestep of a discrete Markov simulation can be computed.\n\\[r_{e} = \\int_{t_1}^{t_2} b e^{at} dt = \\frac{b}{a} (e^{at_2} - e^{at_1})\\]\nWhile this exists as an anayltical result, in general it’s better to use the effective risk over a time interval as this leads to improved accuracy of a simulation."
  },
  {
    "objectID": "blog/posts/appendix/index.html#numerical-checkpoint",
    "href": "blog/posts/appendix/index.html#numerical-checkpoint",
    "title": "Supplemental Appendix",
    "section": "Numerical Checkpoint",
    "text": "Numerical Checkpoint\nA good check at this point is to see if the simulation kept the total population consistent, i.e., neither created nor destroyed occupants of the Markov simulation. If the plot strays far from zero, then something is wrong in constructing the model.\n\nplot(0:20, 1-rowSums(simulation[,c(\"H\", \"A\", \"DA\", \"DS\")]), xlab=\"time (years)\", \n     ylab=\"absolute error\", main=\"Total Population Numerical Error\")\n\n\n\n\nNow with the simulation complete and passing a simple check, one can proceed to integrate costs and qualities.\nFirst let’s define the alternate Simpson’s coefficient function for integration.\n\n# Better accuracy that \"life-table\" aka trapezoidal method\nalt_simp_coef &lt;- function(i) c(17, 59, 43, 49, rep(48, i-8), 49, 43, 59, 17) / 48\nalt_simp      &lt;- function(x,h) h*sum(alt_simp_coef(length(x)) * x)\n\n\nCosts\n\n1000*simulation[21,\"ACC\"] # The last point is the total\n\n     ACC \n554.7587 \n\n\n\n\nQuality-Adjusted Life Years\nTotal possible life years:\n\n  alt_simp(rowSums(simulation[,c(\"H\", \"A\")]), 1)\n\n[1] 6.943292\n\n\nTotal Disutility of ‘A’ (via the tunnel states):\n\n  alt_simp(rowSums(simulation[,c(\"T1\", \"T2\")]), 1)\n\n[1] 0.9392552\n\n\nFinal quality-adjusted life years:\n\n  alt_simp(rowSums(simulation[,c(\"H\", \"A\")]), 1) - \n  alt_simp(rowSums(simulation[,c(\"T1\", \"T2\")]), 1)\n\n[1] 6.004037"
  },
  {
    "objectID": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html",
    "href": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html",
    "title": "Cause-Deleted Life Tables",
    "section": "",
    "text": "All-Cause Life Table Data\n\n\nCause-Specific Deaths\nFirst, we use the CDC wonder engine to extract death by specific cause. This is extracted and stored in data/cardiovascular-deaths.txt.\n\n\n\n\n\nCardiovascular log(mortality) rates by age\n\n\n\n\nNote that the death rate per 100k population is not calculated above age 85 (but general life tables go to 100+), so we need to predict it. Luckily the (log) death rate is fairly linear:\n\n\n\n\n\nLet’s just fit a basic generalized additive model (GAM) in age.\nLet’s see how our imputed mortality rate (red) compares and extrapolates:\n\n\n\n\n\nlog mortality rate by age, with imputed values in red\n\n\n\n\nNow we can construct cause-deleted life tables (per 100k) with sufficient information to fit a mortality model.\nWe now fit the mortalitiy models.\n\n\n\n\n\n\n\n\n\n\n\n\nHistorical Mortality\nLet’s compare historical mortality rates in the US to the UK."
  },
  {
    "objectID": "blog/posts/gompertz-mortality/gompertz-mortality.html",
    "href": "blog/posts/gompertz-mortality/gompertz-mortality.html",
    "title": "Approaches for Modeling Mortality Using Life-Table Data",
    "section": "",
    "text": "This document outlines how to model mortality using a gompertz model fit to life table data.\n\nThe inspiration for much of the modeling code can be found here\nIn general, Gompertz and Gompertz-Makeham models only work for adults, given the wonkiness of mortality in younger ages.\n\nHere is a nice primer on mortality modeling using several mixtures.\nHere is one approach to model under-five mortality.\n\nFernando has a nice paper noting that clinical trials often estimate a hazard ratio for death for overall all-cause death, not disease specific death. What does that mean for modeling?\n\nSource\n\n\n\nlibrary(tidyverse)\nlibrary(flexsurv)\nlibrary(survival)\nlibrary(demography)\nlibrary(fmsb)\nlibrary(here)"
  },
  {
    "objectID": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#multiple-decrements",
    "href": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#multiple-decrements",
    "title": "Cause-Deleted Life Tables",
    "section": "Multiple Decrements",
    "text": "Multiple Decrements"
  },
  {
    "objectID": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#cause-deleted-life-tables",
    "href": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#cause-deleted-life-tables",
    "title": "Cause-Deleted Life Tables",
    "section": "Cause-Deleted Life Tables",
    "text": "Cause-Deleted Life Tables\nWhat would things look like if deaths due to neoplasms could be avoided?\n\n\nCalculate life expectancy without deaths due to neoplasms.\ndf_ &lt;- \n    df %&gt;% \n    mutate(Rd = (D - Di) / D, \n           md = m * Rd) %&gt;% \n    mutate( # now construct a survival function, but treating \n            # the hazard md as if its the only one operating\n        Hd = cumsum(n * md), \n        Sd = edit.na(exp(-lag(Hd)),1)\n    ) %&gt;% \n    mutate(Pd = edit.na((Sd - lead(Sd))/md, tail(Sd/md,1)))\n\n\nThis changes life-expectancy to 82.4 years. Note that this is under a (strong) assumption of independence among the competing causes."
  },
  {
    "objectID": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#cause-deleted-life-tables-approach-1",
    "href": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#cause-deleted-life-tables-approach-1",
    "title": "Cause-Deleted Life Tables",
    "section": "Cause-Deleted Life Tables: Approach 1",
    "text": "Cause-Deleted Life Tables: Approach 1\nWhat would things look like if deaths due to neoplasms could be avoided?\n\n\nCalculate life expectancy without deaths due to neoplasms.\ndf_ &lt;- \n    df %&gt;% \n    mutate(Rd = (D - Di) / D, \n           md = m * Rd) %&gt;% \n    mutate( # now construct a survival function, but treating \n            # the hazard md as if its the only one operating\n        Hd = cumsum(n * md), \n        Sd = edit.na(exp(-lag(Hd)),1)\n    ) %&gt;% \n    mutate(Pd = edit.na((Sd - lead(Sd))/md, tail(Sd/md,1)))\n\n\nThis changes life-expectancy to 82.39 years. Note that this is under a (strong) assumption of independence among the competing causes."
  },
  {
    "objectID": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#cause-deleted-life-tables-approach-2",
    "href": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#cause-deleted-life-tables-approach-2",
    "title": "Cause-Deleted Life Tables",
    "section": "Cause-Deleted Life Tables: Approach 2",
    "text": "Cause-Deleted Life Tables: Approach 2\nThis is based on Chiang’s method. This method assumps proportionality of cause-specific hazards within an age group (which as the textbook notes, is weaker than the constant risk assumption used above).\n\n\nCalculate life expectancy without deaths due to neoplasms.\ndf2_ &lt;-\n    df_ %&gt;%\n    mutate(pd = (1 - q) ^ Rd,\n           ld = 100000 * cumprod(c(1, pd[-length(pd)]))) %&gt;%\n    mutate(\n        dd = edit.na(ld - lead(ld), tail(ld, 1)),\n        qd = dd / ld,\n        ad = ifelse(\n            age &lt; 10 | age == 80,\n            n + Rd * (q / qd) * (a - n),\n            ifelse(age &gt;= 10 & age &lt;= 75,\n                   ((-5 / 24) * lag(dd) + 2.5 * dd + (5 / 24) * lead(dd)) / dd,\n                   a / Rd)\n        )\n    ) %&gt;% \n    mutate(\n        Ld = edit.na(dd * ad + (ld - dd) * n,  tail(ld * ad, 1))\n    )\n\n\nThis method yields a life expectancy of 82.46 years."
  },
  {
    "objectID": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#final-cause-deleted-life-table",
    "href": "blog/posts/cause-deleted-life-tables/cause-delented-life-tables.html#final-cause-deleted-life-table",
    "title": "Cause-Deleted Life Tables",
    "section": "Final Cause-Deleted Life Table",
    "text": "Final Cause-Deleted Life Table\n\n\nCreate Final Cause-Deleted Life Table.\nlt &lt;-\n    df2_ %&gt;%\n    mutate(\n        Td = sum(Ld) - cumsum(Ld) + Ld, \n        ed = Td / ld\n    ) #%&gt;% \n    #select(age,Rd,lx,a,ld,ad,ed)\n\nlt %&gt;% head(n=19) %&gt;% \n    kable() %&gt;% \n    kable_styling()\n\n\n\n\nTable 3: Cause-Deleted Life Table After Removing Deaths From Neoplasms (1991 US Females)\n\n\nage\nD\nDi\nlx\na\nq\nqi\nd\ndi\nn\nm\nH\nS\nP\nRd\nmd\nHd\nSd\nPd\npd\nld\ndd\nqd\nad\nLd\nTd\ned\n\n\n\n\n0\n15758\n63\n100000\n0.152\n0.00783\n0.00003\n783\n3.1304\n1\n0.00788\n0.00788\n1.00000\n0.99607\n0.99600\n0.00785\n0.00785\n1.00000\n0.99608\n0.99220\n100000\n779.882\n0.00780\n0.15201\n99339\n8245748\n82.4575\n\n\n1\n3169\n275\n99217\n1.605\n0.00168\n0.00015\n167\n14.4919\n4\n0.00042\n0.00957\n0.99215\n3.96525\n0.91322\n0.00038\n0.00939\n0.99218\n3.96567\n0.99846\n99220\n152.524\n0.00154\n1.60518\n396515\n8146410\n82.1044\n\n\n5\n1634\n268\n99050\n2.275\n0.00092\n0.00015\n91\n14.9253\n5\n0.00018\n0.01049\n0.99048\n4.95012\n0.83599\n0.00015\n0.01016\n0.99065\n4.95137\n0.99923\n99068\n76.094\n0.00077\n2.27521\n495131\n7749894\n78.2284\n\n\n10\n1573\n217\n98959\n2.843\n0.00090\n0.00012\n89\n12.2778\n5\n0.00018\n0.01139\n0.98957\n4.94562\n0.86205\n0.00016\n0.01093\n0.98989\n4.94755\n0.99922\n98992\n76.752\n0.00078\n2.87537\n494794\n7254764\n73.2867\n\n\n15\n3955\n318\n98870\n2.657\n0.00236\n0.00019\n233\n18.7343\n5\n0.00047\n0.01375\n0.98868\n4.93757\n0.91960\n0.00043\n0.01310\n0.98913\n4.94027\n0.99783\n98915\n214.383\n0.00217\n2.65264\n494071\n6759969\n68.3414\n\n\n20\n4948\n467\n98637\n2.547\n0.00262\n0.00025\n258\n24.3504\n5\n0.00052\n0.01636\n0.98635\n4.92529\n0.90562\n0.00047\n0.01547\n0.98698\n4.92906\n0.99763\n98700\n233.829\n0.00237\n2.54826\n492929\n6265899\n63.4841\n\n\n25\n6491\n856\n98379\n2.550\n0.00314\n0.00041\n309\n40.7493\n5\n0.00063\n0.01951\n0.98377\n4.91112\n0.86813\n0.00055\n0.01821\n0.98464\n4.91650\n0.99727\n98467\n268.545\n0.00273\n2.57653\n491682\n5772970\n58.6287\n\n\n30\n9428\n1924\n98070\n2.616\n0.00425\n0.00087\n417\n85.0984\n5\n0.00085\n0.02377\n0.98068\n4.89296\n0.79593\n0.00068\n0.02160\n0.98196\n4.90148\n0.99661\n98198\n332.479\n0.00339\n2.58477\n490187\n5281288\n53.7820\n\n\n35\n12027\n3532\n97653\n2.677\n0.00584\n0.00171\n570\n167.3934\n5\n0.00117\n0.02962\n0.97651\n4.86829\n0.70633\n0.00083\n0.02573\n0.97863\n4.88307\n0.99587\n97866\n403.829\n0.00413\n2.58246\n488351\n4791101\n48.9560\n\n\n40\n15543\n5958\n97083\n2.685\n0.00818\n0.00314\n794\n304.3590\n5\n0.00164\n0.03783\n0.97081\n4.83418\n0.61668\n0.00101\n0.03079\n0.97460\n4.86067\n0.99495\n97462\n492.324\n0.00505\n2.63691\n486145\n4302750\n44.1481\n\n\n45\n19264\n8434\n96289\n2.681\n0.01330\n0.00582\n1281\n560.8365\n5\n0.00268\n0.05122\n0.96287\n4.78229\n0.56219\n0.00151\n0.03832\n0.96968\n4.83018\n0.99250\n96969\n727.378\n0.00750\n2.67237\n483154\n3816605\n39.3589\n\n\n50\n25384\n11673\n95008\n2.655\n0.02095\n0.00963\n1990\n915.1146\n5\n0.00423\n0.07237\n0.95007\n4.70046\n0.54014\n0.00229\n0.04975\n0.96241\n4.78464\n0.98863\n96242\n1094.144\n0.01137\n2.69457\n478687\n3333451\n34.6362\n\n\n55\n37211\n17078\n93018\n2.647\n0.03371\n0.01547\n3136\n1439.2682\n5\n0.00685\n0.10663\n0.93018\n4.57216\n0.54105\n0.00371\n0.06828\n0.95147\n4.71354\n0.98162\n95148\n1749.234\n0.01838\n2.70304\n471721\n2854764\n30.0035\n\n\n60\n59431\n25263\n89882\n2.646\n0.05155\n0.02191\n4633\n1969.4011\n5\n0.01057\n0.15946\n0.89886\n4.37764\n0.57492\n0.00607\n0.09865\n0.93400\n4.59979\n0.97003\n93399\n2798.900\n0.02997\n2.69495\n460541\n2383043\n25.5148\n\n\n65\n88087\n33534\n85249\n2.631\n0.07669\n0.02920\n6538\n2488.9631\n5\n0.01592\n0.23904\n0.85261\n4.09781\n0.61931\n0.00986\n0.14794\n0.90606\n4.42046\n0.95178\n90600\n4368.320\n0.04822\n2.69590\n442933\n1922501\n21.2197\n\n\n70\n114693\n36695\n78711\n2.628\n0.11552\n0.03696\n9093\n2909.2241\n5\n0.02444\n0.36126\n0.78738\n3.70583\n0.68006\n0.01662\n0.23106\n0.86248\n4.13806\n0.91991\n86231\n6906.623\n0.08009\n2.68644\n415178\n1479568\n17.1581\n\n\n75\n143554\n36571\n69618\n2.618\n0.17427\n0.04439\n12132\n3090.6793\n5\n0.03801\n0.55131\n0.69679\n3.17293\n0.74525\n0.02833\n0.37269\n0.79369\n3.70026\n0.86701\n79325\n10549.135\n0.13299\n2.67576\n372105\n1064390\n13.4181\n\n\n80\n164986\n30220\n57486\n2.570\n0.27363\n0.05012\n15730\n2881.2178\n5\n0.06312\n0.86691\n0.57620\n2.47064\n0.81683\n0.05156\n0.63048\n0.68888\n3.03625\n0.77017\n68776\n15806.494\n0.22983\n2.63677\n306524\n692285\n10.0658\n\n\n85\n320578\n32739\n41756\n6.539\n1.00000\n0.10212\n41756\n4264.3278\nNA\n0.15293\nNA\n0.42025\n2.74800\n0.89788\n0.13731\nNA\n0.53234\n3.87687\n0.00000\n52969\n52969.130\n1.00000\n7.28275\n385761\n385761\n7.2828\n\n\n\n\n\n\n\n\n\n\n# A tibble: 83 × 2\n       x       qx\n   &lt;int&gt;    &lt;dbl&gt;\n 1    18 0.000949\n 2    19 0.00103 \n 3    20 0.00111 \n 4    21 0.00127 \n 5    22 0.00126 \n 6    23 0.00128 \n 7    24 0.00136 \n 8    25 0.00131 \n 9    26 0.00136 \n10    27 0.00133 \n# ℹ 73 more rows\n\n\n[1] 0.000019375 0.101511777 0.000869107 0.002996477 0.000000000\n\n\nTime Series:\nStart = 2010 \nEnd = 2010 \nFrequency = 1 \n[1] 38.523\n\n\n[1] 38.501"
  },
  {
    "objectID": "blog/posts/gompertz-mortality/gompertz-mortality.html#chatgpt",
    "href": "blog/posts/gompertz-mortality/gompertz-mortality.html#chatgpt",
    "title": "Modeling Mortality Using a Gompertz Model",
    "section": "",
    "text": "Note the following was generated by chatGPT to discuss various way to model mortality–it’s useful but will need to be vetted!\n\n\nLee-Carter (LC) forecasting is a popular method for projecting mortality rates over time. It was introduced by Ronald Lee and Lawrence Carter in 1992, and has since been widely used in actuarial science, demography, and public health research.\nThe LC method assumes that the logarithm of the mortality rate can be modeled as a linear function of age and a time-dependent factor:\nlog(mu(x,t)) = alpha(x) + beta(x)k(t) + epsilon(x,t)\nwhere mu(x,t) represents the mortality rate at age x and time t, alpha(x) and beta(x) are age-specific constants, k(t) is a time-dependent factor common to all ages, and epsilon(x,t) is a normally-distributed error term.\nTo estimate the LC model parameters, researchers typically use historical mortality data for a given population and age range. The parameters are estimated through a process called singular value decomposition, which involves breaking down the covariance matrix of the logarithms of the mortality rates into its component parts.\nOnce the LC model parameters have been estimated, they can be used to forecast future mortality rates by projecting the time-dependent factor k(t) into the future. This can be done using various methods, such as extrapolating historical trends or incorporating information from other sources, such as economic or demographic indicators.\nOne advantage of the LC method is that it can capture age-specific mortality trends and changes over time, which can be useful for analyzing the impact of interventions or policies on mortality rates. However, the method has some limitations, such as its assumption of a linear relationship between age and mortality rates, and its reliance on historical data for parameter estimation. As such, researchers may choose to use alternative models or methods in certain contexts or for certain populations.\n\n\n\nThe Lee-Carter (LC) model, Gompertz model, and Gompertz-Makeham model are all used for forecasting mortality rates, but they differ in their assumptions and applications.\nThe Gompertz model assumes that mortality rates increase exponentially with age, and has been widely used for modeling mortality in various contexts. The Gompertz-Makeham model extends the Gompertz model by adding a constant term (the Makeham term) to account for mortality risk factors that are independent of age, such as genetic or environmental factors. The Gompertz and Gompertz-Makeham models are relatively simple and computationally efficient, but they may not capture more complex mortality patterns, such as mortality trends or cohort effects.\nThe LC model, on the other hand, allows for more flexible and nuanced modeling of age-specific mortality trends over time. It assumes that a common factor, k(t), influences mortality rates at all ages, and estimates age-specific deviations from this factor using historical mortality data. This allows for capturing trends and changes in mortality rates that are not explained by age alone.\nIn terms of forecasting performance, studies have found that the LC model generally outperforms the Gompertz and Gompertz-Makeham models, particularly for longer forecast horizons and for populations with more complex mortality patterns. However, the choice of model may depend on the specific research question, the data available, and the trade-off between model complexity and forecasting accuracy.\nOverall, while the Gompertz and Gompertz-Makeham models are simpler and computationally efficient, the LC model offers more flexibility and accuracy for modeling and forecasting mortality rates, particularly in populations with complex mortality patterns."
  },
  {
    "objectID": "blog/posts/gompertz-mortality/gompertz-mortality.html#download-the-data-from-the-human-mortality-database",
    "href": "blog/posts/gompertz-mortality/gompertz-mortality.html#download-the-data-from-the-human-mortality-database",
    "title": "Approaches for Modeling Mortality Using Life-Table Data",
    "section": "Download the data from the Human Mortality Database",
    "text": "Download the data from the Human Mortality Database\n\nhmd.usa &lt;- demography::hmd.mx(\"USA\",\"&lt;USER NAME (email)&gt;\", \"&lt;PASSWORD&gt;\",\"USA\")\nwrite_rds(hmd.usa,file=here(\"blog/posts/cause-deleted-life-tables/data/usa-life-table.rds\"))\n\n\nhmd.usa &lt;- read_rds(here(\"blog/posts/cause-deleted-life-tables/data/usa-life-table.rds\"))\n\nlt &lt;-  # Construct a life-table for 2010 mortality \n  demography::lifetable(hmd.usa,series = \"male\", years = 2010) %&gt;% \n  as_tibble() %&gt;% \n  mutate_at(vars(lx,dx), function(x) x*100000)\n\n# Restrict the estimation sample to only 30-99 year olds. \nlt_a &lt;- lt  %&gt;% filter(x&lt;100) %&gt;% \n  filter(x&gt;30 & x&lt;100)"
  },
  {
    "objectID": "blog/posts/gompertz-mortality/gompertz-mortality.html#define-various-functions",
    "href": "blog/posts/gompertz-mortality/gompertz-mortality.html#define-various-functions",
    "title": "Approaches for Modeling Mortality Using Life-Table Data",
    "section": "Define various functions",
    "text": "Define various functions\n\n# SOURCE: https://github.com/scpatricio/bell_mortality\n# Here, however, I'm just using the negative binomial rather than the bell distribution code. \n\n# Gompertz\ngompertz = function(t, theta){\n    a = theta[1]\n    b = theta[2]\n    \n    return(a*exp(b*t))\n}\n\n\n  \n# Gompertz-Makeham\nmakeham = function(t, theta){\n    a = theta[1]\n    b = theta[2]\n    c = theta[3]\n    \n    return(a*exp(b*t)+c)\n}\n\nseries = function(j, phi){\n    out = NULL\n    \n    for(i in 1:length(j)){\n        out[i] = sum(log(0:(j[i]-1) + phi))\n    }\n    \n    return(out)\n}\n\nlogLike_NB = function(theta, Dx, Ex, mu, t){ # negative binomial\n    theta = abs(theta)\n    phi = theta[1]\n    \n    lamb = Ex*mu(t, theta[-1])\n    \n    log_lik = series(Dx, phi) +Dx*log(lamb)-(Dx+phi)*log(phi+lamb)+phi*log(phi)\n    \n    return(-sum(log_lik, na.rm = T))\n}\n\n# E1 function\nE1 = function(z){\n    integrate(function(t){\n        (exp(-t))/t\n    }, z, Inf)$value\n}\n\nex_gomp = function(t, a, b){\n    exp(a*exp(b*t)/b)*E1(a*exp(b*t)/b)/b\n}\n\n# Gompertz-Makeham\nGamma_Inc_sup = function(s, z){\n    integrate(function(t){\n        t^(s-1)*exp(-t)\n    }, z, Inf)$value\n}\n\nex_mak = function(t, a, b, c){\n    (exp(a*exp(b*t)/b)/b)*((a*exp(b*t)/b)^(c/b))*Gamma_Inc_sup(-c/b,a*exp(b*t)/b)\n}\n\n\nnb_estim_gompertz = abs(optim(par = c(1, 0.001, 0.2),\n                     fn = logLike_NB,\n                     Ex = lt_a$lx,\n                     Dx = lt_a$dx,\n                     mu = gompertz,\n                     t = lt_a$x-30)$par)\n\n\nnb_estim_makeham = abs(optim(par = c(1, 0.001, 0.1, 0.001),\n                     fn = logLike_NB,\n                       Ex = lt_a$lx,\n                       Dx = lt_a$dx,\n                       mu = makeham,\n                       t = lt_a$x-30)$par)\n\n\n  \n# Predicted Mortality Rates\n\nlt_a$pr_gomp_nb = log(gompertz(lt_a$x-30,nb_estim_gompertz[-1]))\nlt_a$pr_makeham_nb = log(makeham(lt_a$x-30,nb_estim_makeham[-1]))\n\nlt %&gt;% \n  ggplot(aes(x = x, y = log(qx))) + geom_point() +\n  hrbrthemes::theme_ipsum() + \n  geom_line(data = lt_a %&gt;% \n  select(x,starts_with(\"pr_\")) %&gt;% \n  gather(method,y,-x), aes(x=x,y=y,colour=method))"
  },
  {
    "objectID": "blog/posts/gompertz-mortality/gompertz-mortality.html#lee-carter-vs.-gompertz-gompertz-makeham",
    "href": "blog/posts/gompertz-mortality/gompertz-mortality.html#lee-carter-vs.-gompertz-gompertz-makeham",
    "title": "Approaches for Modeling Mortality Using Life-Table Data",
    "section": "Lee-Carter vs. Gompertz / Gompertz-Makeham",
    "text": "Lee-Carter vs. Gompertz / Gompertz-Makeham\nThe Lee-Carter (LC) model, Gompertz model, and Gompertz-Makeham model are all used for forecasting mortality rates, but they differ in their assumptions and applications.\nThe Gompertz model assumes that mortality rates increase exponentially with age, and has been widely used for modeling mortality in various contexts. The Gompertz-Makeham model extends the Gompertz model by adding a constant term (the Makeham term) to account for mortality risk factors that are independent of age, such as genetic or environmental factors. The Gompertz and Gompertz-Makeham models are relatively simple and computationally efficient, but they may not capture more complex mortality patterns, such as mortality trends or cohort effects.\nThe LC model, on the other hand, allows for more flexible and nuanced modeling of age-specific mortality trends over time. It assumes that a common factor, k(t), influences mortality rates at all ages, and estimates age-specific deviations from this factor using historical mortality data. This allows for capturing trends and changes in mortality rates that are not explained by age alone.\nIn terms of forecasting performance, studies have found that the LC model generally outperforms the Gompertz and Gompertz-Makeham models, particularly for longer forecast horizons and for populations with more complex mortality patterns. However, the choice of model may depend on the specific research question, the data available, and the trade-off between model complexity and forecasting accuracy.\nOverall, while the Gompertz and Gompertz-Makeham models are simpler and computationally efficient, the LC model offers more flexibility and accuracy for modeling and forecasting mortality rates, particularly in populations with complex mortality patterns.\nIn summary, Gompertz models, Gompertz-Makeham models, and Lee-Carter models are all used to model adult mortality, but they differ in their assumptions and complexity. The Gompertz model is the simplest but assumes that mortality rates increase indefinitely with age, while the Gompertz-Makeham model adds a constant term to account for other mortality risks but still assumes infinite mortality rates. The Lee-Carter model is non-parametric and can capture changes in mortality rates over time and age-specific and time-specific effects on mortality."
  },
  {
    "objectID": "blog/posts/gompertz-mortality/gompertz-mortality.html#heligman-pollard-model",
    "href": "blog/posts/gompertz-mortality/gompertz-mortality.html#heligman-pollard-model",
    "title": "Approaches for Modeling Mortality Using Life-Table Data",
    "section": "Heligman-Pollard model",
    "text": "Heligman-Pollard model\n(Description from ChatGPT)\nThe Heligman-Pollard model is a statistical model for mortality modeling that is widely used in actuarial science and demography. The model was first proposed by Nathan Keyfitz in 1977 and later extended by Kenneth Heligman and Edward Pollard in 1980.\nThe model expresses the relationship between mortality rates and age in a mathematical form, and it can be used to estimate the probability of death for individuals at different ages. The basic assumption of the model is that mortality rates decline at a decreasing rate with increasing age, and that there is a certain amount of randomness in the mortality data.\nThe Heligman-Pollard model can be expressed in the following form:\n\\[\nlog(m(x)) = a(x) + b(x)*k\n\\]\nwhere:\n\n\\(m(x)\\) is the mortality rate at age x.\n\\(a(x)\\) and \\(b(x)\\) are age-specific parameters that describe the level and shape of the mortality curve, respectively.\n\\(k\\) is a constant parameter that controls the rate at which the mortality curve declines with increasing age.\n\nThe model can be estimated using regression techniques, and the estimated parameters can be used to calculate the probability of death at different ages.\nThe Heligman-Pollard model has been widely used in actuarial science and demography for mortality forecasting, life insurance pricing, and pension plan design. It is a flexible and robust model that can be easily applied to different populations and time periods. However, like any statistical model, the Heligman-Pollard model has its limitations and should be used with caution.\n\nyear     &lt;- 2010\nages     &lt;- lt$x\ndeaths   &lt;- lt$dx\nexposure &lt;- lt$lx\nfit &lt;- MortalityLaw(x   = ages,\n                    Dx  = deaths,   # vector with death counts\n                    Ex  = exposure, # vector containing exposures\n                    law = \"HP2\",\n                    opt.method = \"LF2\")\nplot(fit)\n\n\n\nget_mort &lt;- function(x,params) {\n  with(as.list(params),{\n    mu1 &lt;-  A^((x + B)^C) + (G * H^x)/(1 + G * H^x)\n    mu2 &lt;-  D * exp(-E * (log(x/F_))^2)\n    ifelse(x == 0, mu1, mu1 + mu2)\n  })\n}\n\nplot(lt$x,log(lt$qx))\npoints(lt$x,log(get_mort(lt$x,fit$coefficients)),col=\"blue\")\n\n\n\n\n\nget_mort(lt$x,fit$coefficients)\n\n  [1] 0.0066864860 0.0005582469 0.0002885961 0.0002003338 0.0001602317\n  [6] 0.0001397381 0.0001292190 0.0001245984 0.0001239791 0.0001267321\n [11] 0.0001335566 0.0001468856 0.0001709979 0.0002113375 0.0002730405\n [16] 0.0003591946 0.0004695373 0.0006000746 0.0007436868 0.0008914307\n [21] 0.0010340905 0.0011635680 0.0012738498 0.0013614663 0.0014254900\n [26] 0.0014671988 0.0014895519 0.0014966070 0.0014929770 0.0014833808\n [31] 0.0014723136 0.0014638355 0.0014614635 0.0014681448 0.0014862880\n [36] 0.0015178311 0.0015643293 0.0016270496 0.0017070630 0.0018053301\n [41] 0.0019227758 0.0020603539 0.0022191009 0.0024001804 0.0026049204\n [46] 0.0028348439 0.0030916956 0.0033774656 0.0036944110 0.0040450775\n [51] 0.0044323206 0.0048593287 0.0053296466 0.0058472025 0.0064163357\n [56] 0.0070418283 0.0077289396 0.0084834424 0.0093116644 0.0102205308\n [61] 0.0112176119 0.0123111730 0.0135102275 0.0148245938 0.0162649540\n [66] 0.0178429163 0.0195710783 0.0214630928 0.0235337337 0.0257989620\n [71] 0.0282759903 0.0309833444 0.0339409200 0.0371700327 0.0406934588\n [76] 0.0445354625 0.0487218087 0.0532797540 0.0582380149 0.0636267047\n [81] 0.0694772366 0.0758221847 0.0826950989 0.0901302648 0.0981624054\n [86] 0.1068263163 0.1161564314 0.1261863140 0.1369480733 0.1484717061\n [91] 0.1607843674 0.1739095788 0.1878663864 0.2026684850 0.2183233315\n [96] 0.2348312738 0.2521847294 0.2703674475 0.2893538944 0.3091088018\n[101] 0.3295869150"
  },
  {
    "objectID": "blog/drafts/scratch/scratch.html",
    "href": "blog/drafts/scratch/scratch.html",
    "title": "Cause-Deleted Life Tables",
    "section": "",
    "text": "All-Cause Life Table Data\n\n\nModel All-Cause Mortality\n\n\nCause-Specific Deaths\n\n\n\n\n\nNote that the death rate per 100k population is not calculated above age 85, so we need to predict it. Luckily the (log) death rate is very linear:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistorical Mortality"
  },
  {
    "objectID": "lectures/lec_structure.html#common-advice-on-conversion",
    "href": "lectures/lec_structure.html#common-advice-on-conversion",
    "title": "5. Structuring the Markov Model",
    "section": "Common Advice on Conversion",
    "text": "Common Advice on Conversion\n\\(\\pi_{A \\rightarrow B} = 1 - e^{-r_{A \\rightarrow B} t}\\) to convert a rate, \\(r\\) to a probability, \\(\\pi\\).\n\\(r_{A \\rightarrow B} = -\\log(1 - (\\pi_{A \\rightarrow B} - 1) / t\\) to convert a probability, \\(\\pi\\), to a rate, \\(r\\).\nWhich is technically correct for a model with one rate."
  },
  {
    "objectID": "lectures/lec_structure.html#competing-rates",
    "href": "lectures/lec_structure.html#competing-rates",
    "title": "5. Structuring the Markov Model",
    "section": "Competing Rates",
    "text": "Competing Rates\nWhen 2 rates compete for a transition these formulas are mathematically wrong.\nWhat is correct is embedding the rate matrix, \\(X\\) into a time step, \\(Y = Y_0 e^{Xt}\\)."
  },
  {
    "objectID": "lectures/lec_structure.html#resulting-error",
    "href": "lectures/lec_structure.html#resulting-error",
    "title": "5. Structuring the Markov Model",
    "section": "Resulting Error",
    "text": "Resulting Error\n\nIf one has misapplied this in a publication, it’s okay."
  },
  {
    "objectID": "lectures/lec_structure.html#quantified-absolute-error",
    "href": "lectures/lec_structure.html#quantified-absolute-error",
    "title": "5. Structuring the Markov Model",
    "section": "Quantified Absolute Error",
    "text": "Quantified Absolute Error"
  },
  {
    "objectID": "lectures/lec_structure.html#quantified-relative-error",
    "href": "lectures/lec_structure.html#quantified-relative-error",
    "title": "5. Structuring the Markov Model",
    "section": "Quantified Relative Error",
    "text": "Quantified Relative Error\n\n\nFor rates &lt; 0.1 of the chosen time step the error is &lt;5%."
  },
  {
    "objectID": "lectures/lec_structure.html#comparison",
    "href": "lectures/lec_structure.html#comparison",
    "title": "5. Structuring the Markov Model",
    "section": "Comparison",
    "text": "Comparison\n\nCommon Economic Statistics are relative to a base or reference case.\n\nNet monetary benefit.\nNet health benefit.\nIncremental cost effectiveness ratio.\n\nThe bias introduced is generally of the same order of magnitude and cancels. Similar to the “difference in difference” method in statistics.\nThese decision thresholds are robust against this misspecification.\nAbsolute values in a single scenario will be biased relative to rates."
  },
  {
    "objectID": "lectures/lec_structure.html#rate-misspecification-conclusions",
    "href": "lectures/lec_structure.html#rate-misspecification-conclusions",
    "title": "5. Structuring the Markov Model",
    "section": "Rate Misspecification Conclusions",
    "text": "Rate Misspecification Conclusions\n\nExisting publications are generally okay if they misspecified rates via these formulas. Check the maximum rate of an event as a rough estimate of effect.\nPublished rates from clinical studies are usually adjusted for competing events."
  },
  {
    "objectID": "lectures/lec_structure.html#section",
    "href": "lectures/lec_structure.html#section",
    "title": "5. Structuring the Markov Model",
    "section": "",
    "text": "library(ggplot2); theme_set(theme_bw())\nlibrary(flexsurv) # For pgompertz\n\nLoading required package: survival\n\nlibrary(survival) # For fitting\nlibrary(readxl)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n# Read in Raw Lifetable Data\ndeaths.male &lt;- read.table(here::here(\"gompertz-mortality/data/mltper_1x1.txt\"),skip=2,header=T,as.is=TRUE)\ndeaths.female &lt;- read.table(here::here(\"gompertz-mortality/data/fltper_1x1.txt\"),skip=2,header=T,as.is=TRUE)\n\n# Make Some Edits\ndeaths.male[which(deaths.male$Age==\"110+\"),]$Age &lt;- 110\ndeaths.female[which(deaths.female$Age==\"110+\"),]$Age &lt;- 110\ndeaths.male$Age &lt;- as.numeric(deaths.male$Age)\ndeaths.female$Age &lt;- as.numeric(deaths.female$Age)\n\n# Isolate each file to 2010 deaths only\ndeaths.male.2010 &lt;- subset(deaths.male,Year==2010)\ndeaths.female.2010 &lt;- subset(deaths.female,Year==2010)\n\n# Generate the CDF ## CDF == 1-Survival = 1 - lx/10)\ndeaths.male.2010$cdf &lt;- with(deaths.male.2010,1-lx/100000)\ndeaths.female.2010$cdf &lt;- with(deaths.female.2010,1-lx/100000)\n\n# Expand to full data frame\ndeaths.male.long &lt;- data.frame(Age=rep(deaths.male.2010$Age, deaths.male.2010$dx))\ndeaths.male.long$Death &lt;- 1\n\ndeaths.female.long &lt;- data.frame(Age=rep(deaths.female.2010$Age, deaths.female.2010$dx))\ndeaths.female.long$Death &lt;- 1\n\nparameters = data.frame(\n  Age = 0:110,\n  male.shape=rep(NA,111),\n  male.rate=rep(NA,111),\n  female.shape=rep(NA,111),\n  female.rate=rep(NA,111)\n)\n\nparameters &lt;- read.csv(here::here(\"lectures/media/gompertz-mortality.csv\"))"
  },
  {
    "objectID": "scratch/scratch.html",
    "href": "scratch/scratch.html",
    "title": "Cause-Deleted Life Tables",
    "section": "",
    "text": "All-Cause Life Table Data\n\n\nModel All-Cause Mortality\n\n\nCause-Specific Deaths\n\n\n\n\n\nNote that the death rate per 100k population is not calculated above age 85, so we need to predict it. Luckily the (log) death rate is very linear:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistorical Mortality"
  },
  {
    "objectID": "blog/posts/green-et-al-replication/green-et-al-replication.html",
    "href": "blog/posts/green-et-al-replication/green-et-al-replication.html",
    "title": "Replication of Didactic Model",
    "section": "",
    "text": "Created on Sketchviz\n\nHere is a footnote reference,1 and another.2\nThis paragraph won’t be part of the note, because it isn’t indented.\n\n\nWe first define some necessary functions for bookkeeping later.\n\n1alt_simp_coef &lt;- function(i) c(17, 59, 43, 49, rep(48, i-8), 49, 43, 59, 17) / 48\n2cycle_adj      &lt;- function(x,h) h*sum(alt_simp_coef(length(x)) * x)\n\n\n1\n\nAlternative Simpson’s method coefficients\n\n2\n\nFunction to create cycle adjustment values\n\n\n\n\n\n\n\n\nparams = list(\n    t_names = c(\"without_drug\", \"with_drug\"),\n    n_treatments =2,\n    s_names  =c(\"Asymptomatic_disease\", \"Progressive_disease\", \"DeadCause\",\"Dead\"),\n    n_states =4,\n    a_names = c(\"accProgressive_disease\"),\n    tunnel_names = c(\"trProgressive\",\"trDeadCause\"),\n    \n    n_cohort =1000,\n    cycle =1,\n    \n    n_cycles = 46,\n    Initial_age =55,\n    effect =0.5, \n    \n    cAsymp =500,\n    cDeath =1000,\n    cDrug =1000,\n    cProg =3000,\n    uAsymp =0.95,\n    uProg =0.75,\n    oDr = 0,# 0.06,\n    cDr = 0, # 0.06,\n    tpDcm =0.15,\n    tpProg =0.01,\n    tpDn =0.0379 \n    \n)\n\n\n\n\n\nm_Pt &lt;- function(t) {\n    lapply(t, function(tt){\n        \n        current_age &lt;- params$Initial_age  + (tt) - 1\n        cycle = tt\n        \n        tpDn_lookup &lt;-\n            c(\"(34,44]\" = 0.0017,\n              \"(44,54]\" = 0.0044,\n              \"(54,64]\" = 0.0138,\n              \"(64,74]\" = 0.0379,\n              \"(74,84]\" = 0.0912,\n              \"(84,100]\" = 0.1958)\n        \n        age_grp &lt;- cut(current_age, \n                       breaks = c(34,44,54,64,74,84,100))\n        tpDn &lt;- tpDn_lookup[age_grp]\n\n        tpProg_ &lt;- params$tpProg * (cycle )\n        tpDcm_ &lt;- params$tpDcm \n        effect_ &lt;- params$effect\n        n_states_ &lt;- params$n_states\n        s_names_ &lt;- params$s_names\n        t_names_ &lt;- params$t_names\n        n_treatments_ &lt;- params$n_treatments\n        \n \n        m_P_ &lt;- \n            array(data = c(0, 0, 0,0,\n                           tpProg_, 0, 0,0,\n                           0,tpDcm_+tpDn,0,0,\n                           tpDn ,  0, 0,0,\n                           \n                           0, 0, 0,0,\n                           tpProg_*(1-effect_), 0, 0,0,\n                           0,tpDcm_+tpDn,0,0,\n                           tpDn,  0,0, 0),\n                  dim = c(n_states_, n_states_, n_treatments_),\n                  dimnames = list(from = s_names_,\n                                  to = s_names_,\n                                  t_names_))\n        diag(m_P_[,,1]) &lt;- 1 - rowSums(m_P_[,,1])\n        diag(m_P_[,,2]) &lt;- 1 - rowSums(m_P_[,,2])\n        m_P &lt;- list()\n        m_P[[1]] &lt;- m_P_[,,1]\n        m_P[[2]] &lt;- m_P_[,,2]\n\n        return(m_P)\n    })\n}\n\nm_P &lt;- m_Pt(1:(params$n_cycles-1))\n\n\nm_P[[1]]\n\n[[1]]\n                      to\nfrom                   Asymptomatic_disease Progressive_disease DeadCause\n  Asymptomatic_disease               0.9762              0.0100    0.0000\n  Progressive_disease                0.0000              0.8362    0.1638\n  DeadCause                          0.0000              0.0000    1.0000\n  Dead                               0.0000              0.0000    0.0000\n                      to\nfrom                     Dead\n  Asymptomatic_disease 0.0138\n  Progressive_disease  0.0000\n  DeadCause            0.0000\n  Dead                 1.0000\n\n[[2]]\n                      to\nfrom                   Asymptomatic_disease Progressive_disease DeadCause\n  Asymptomatic_disease               0.9812              0.0050    0.0000\n  Progressive_disease                0.0000              0.8362    0.1638\n  DeadCause                          0.0000              0.0000    1.0000\n  Dead                               0.0000              0.0000    0.0000\n                      to\nfrom                     Dead\n  Asymptomatic_disease 0.0138\n  Progressive_disease  0.0000\n  DeadCause            0.0000\n  Dead                 1.0000\n\n\n\n\n\n\nu_payoff &lt;- with(params,{\n    array(c(\"Asymptomatic_disease\" = uAsymp, \"Progressive_disease\" = uProg, \"DeadCause\" = 0, \"Dead\" = 0, \n            \"Asymptomatic_disease\" = uAsymp, \"Progressive_disease\" = uProg,  \"DeadCause\" = 0, \"Dead\" = 0 ),\n          dim = c(1, n_states, n_treatments),\n          dimnames = list(from = \"cost\",\n                          to = c(s_names),\n                          t_names))\n})\n\nc_payoff &lt;- with(params,{\n    array(c(\"Asymptomatic_disease\" = cAsymp, \"Progressive_disease\" = cProg, \"DeadCause\" = 0 , \"Dead\" = 0, \n            \"Asymptomatic_disease\" = cAsymp+cDrug, \"Progressive_disease\" = cProg, \"DeadCause\" = 0 , \"Dead\" = 0 ),\n          dim = c(1, n_states, n_treatments),\n          dimnames = list(from = \"cost\",\n                          to = c(s_names),\n                          t_names))\n})\n\nc_transition_payoff &lt;- with(params,{\n    array(c(\"Asymptomatic_disease\" = 0, \"Progressive_disease\" = 0, \"DeadCause\" = cDeath , \"Dead\" = 0, \n            \"Asymptomatic_disease\" = 0, \"Progressive_disease\" = 0, \"DeadCause\" = cDeath , \"Dead\" = 0 ),\n          dim = c(1, n_states, n_treatments),\n          dimnames = list(from = \"cost\",\n                          to = c(s_names),\n                          t_names))\n})\n\n\nsim_cohort &lt;- function(params) {\n    \n    m_P &lt;- m_Pt(1:(params$n_cycles-1))\n    \n    tr &lt;- \n        m_P %&gt;% transpose() %&gt;% \n        map(~({\n            tr_ &lt;- t(c(\"Asymptomatic_disease\" = 1000, \"Progressive_disease\" = 0, \"DeadCause\" = 0, \"Dead\" = 0))\n            do.call(rbind,lapply(.x, function(tp) {\n                tr_ &lt;&lt;- tr_ %*% tp\n            }))\n        }))\n    tr &lt;- \n        tr %&gt;% \n        map(~({\n            .x &lt;- rbind(t(c(1000,0,0,0)),.x)\n        }))\n    \n    return(tr)\n}\n\nmarkov_trace &lt;- \n    markov_trace &lt;- sim_cohort(params)\n\nstate_costs_without &lt;- markov_trace[[1]] %*% c_payoff[,,1]\ntransition_costs_without &lt;- matrix(c(0,diff(markov_trace[[1]][,\"DeadCause\"]))) * params$cDeath\ncosts_without &lt;- state_costs_without + transition_costs_without\nqalys_without &lt;- markov_trace[[1]] %*% u_payoff[,,1]\n\nstate_costs_with &lt;- markov_trace[[2]] %*% c_payoff[,,2]\ntransition_costs_with &lt;- matrix(c(0,diff(markov_trace[[2]][,\"DeadCause\"]))) * params$cDeath\ncosts_with &lt;- state_costs_with + transition_costs_with\nqalys_with &lt;- markov_trace[[2]] %*% u_payoff[,,2]\n\ncycle_adj &lt;- alt_simp_coef(params$n_cycles)\ndiscounting &lt;- 1/(1+params$oDr)^(0:(params$n_cycles-1))\n\ntot_costs_without &lt;- sum(as.vector(costs_without[-1]) * discounting[-1])\ntot_costs_with &lt;- sum(as.vector(costs_with[-1])  * discounting[-1])\n\ntot_qalys_without &lt;- sum(as.vector(qalys_without) *  discounting)\ntot_qalys_with &lt;- sum(as.vector(qalys_with) *  discounting)\n\n#inc_cost &lt;- (tot_costs_with - tot_costs_without) \ninc_qaly &lt;- (tot_qalys_with - tot_qalys_without); inc_qaly\n\n[1] 2243.8\n\ninc_cost &lt;- (tot_costs_with - tot_costs_without); inc_cost\n\n[1] 11380568\n\nicer = inc_cost / inc_qaly ; icer\n\n[1] 5071.9"
  },
  {
    "objectID": "blog/posts/green-et-al-replication/green-et-al-replication.html#functions",
    "href": "blog/posts/green-et-al-replication/green-et-al-replication.html#functions",
    "title": "Replication of Didactic Model",
    "section": "",
    "text": "1alt_simp_coef &lt;- function(i) c(17, 59, 43, 49, rep(48, i-8), 49, 43, 59, 17) / 48\n2cycle_adj      &lt;- function(x,h) h*sum(alt_simp_coef(length(x)) * x)\n\n\n1\n\nAlternative Simpson’s method coefficients\n\n2\n\nFunction to create cycle adjustment values"
  },
  {
    "objectID": "blog/posts/green-et-al-replication/green-et-al-replication.html#model-parameters",
    "href": "blog/posts/green-et-al-replication/green-et-al-replication.html#model-parameters",
    "title": "Replication of Didactic Model",
    "section": "",
    "text": "params = list(\n    t_names = c(\"without_drug\", \"with_drug\"),\n    n_treatments =2,\n    s_names  =c(\"Asymptomatic_disease\", \"Progressive_disease\", \"DeadCause\",\"Dead\"),\n    n_states =4,\n    a_names = c(\"accProgressive_disease\"),\n    tunnel_names = c(\"trProgressive\",\"trDeadCause\"),\n    \n    n_cohort =1000,\n    cycle =1,\n    \n    n_cycles = 46,\n    Initial_age =55,\n    effect =0.5, \n    \n    cAsymp =500,\n    cDeath =1000,\n    cDrug =1000,\n    cProg =3000,\n    uAsymp =0.95,\n    uProg =0.75,\n    oDr = 0,# 0.06,\n    cDr = 0, # 0.06,\n    tpDcm =0.15,\n    tpProg =0.01,\n    tpDn =0.0379 \n    \n)"
  },
  {
    "objectID": "blog/posts/green-et-al-replication/green-et-al-replication.html#cycle-adjustment",
    "href": "blog/posts/green-et-al-replication/green-et-al-replication.html#cycle-adjustment",
    "title": "Replication of Didactic Model",
    "section": "",
    "text": "We first define some necessary functions for bookkeeping later.\n\n1alt_simp_coef &lt;- function(i) c(17, 59, 43, 49, rep(48, i-8), 49, 43, 59, 17) / 48\n2cycle_adj      &lt;- function(x,h) h*sum(alt_simp_coef(length(x)) * x)\n\n\n1\n\nAlternative Simpson’s method coefficients\n\n2\n\nFunction to create cycle adjustment values"
  },
  {
    "objectID": "blog/posts/green-et-al-replication/green-et-al-replication.html#transition-probability-matrices",
    "href": "blog/posts/green-et-al-replication/green-et-al-replication.html#transition-probability-matrices",
    "title": "Replication of Didactic Model",
    "section": "",
    "text": "m_Pt &lt;- function(t) {\n    lapply(t, function(tt){\n        \n        current_age &lt;- params$Initial_age  + (tt) - 1\n        cycle = tt\n        \n        tpDn_lookup &lt;-\n            c(\"(34,44]\" = 0.0017,\n              \"(44,54]\" = 0.0044,\n              \"(54,64]\" = 0.0138,\n              \"(64,74]\" = 0.0379,\n              \"(74,84]\" = 0.0912,\n              \"(84,100]\" = 0.1958)\n        \n        age_grp &lt;- cut(current_age, \n                       breaks = c(34,44,54,64,74,84,100))\n        tpDn &lt;- tpDn_lookup[age_grp]\n\n        tpProg_ &lt;- params$tpProg * (cycle )\n        tpDcm_ &lt;- params$tpDcm \n        effect_ &lt;- params$effect\n        n_states_ &lt;- params$n_states\n        s_names_ &lt;- params$s_names\n        t_names_ &lt;- params$t_names\n        n_treatments_ &lt;- params$n_treatments\n        \n \n        m_P_ &lt;- \n            array(data = c(0, 0, 0,0,\n                           tpProg_, 0, 0,0,\n                           0,tpDcm_+tpDn,0,0,\n                           tpDn ,  0, 0,0,\n                           \n                           0, 0, 0,0,\n                           tpProg_*(1-effect_), 0, 0,0,\n                           0,tpDcm_+tpDn,0,0,\n                           tpDn,  0,0, 0),\n                  dim = c(n_states_, n_states_, n_treatments_),\n                  dimnames = list(from = s_names_,\n                                  to = s_names_,\n                                  t_names_))\n        diag(m_P_[,,1]) &lt;- 1 - rowSums(m_P_[,,1])\n        diag(m_P_[,,2]) &lt;- 1 - rowSums(m_P_[,,2])\n        m_P &lt;- list()\n        m_P[[1]] &lt;- m_P_[,,1]\n        m_P[[2]] &lt;- m_P_[,,2]\n\n        return(m_P)\n    })\n}\n\nm_P &lt;- m_Pt(1:(params$n_cycles-1))\n\n\nm_P[[1]]\n\n[[1]]\n                      to\nfrom                   Asymptomatic_disease Progressive_disease DeadCause\n  Asymptomatic_disease               0.9762              0.0100    0.0000\n  Progressive_disease                0.0000              0.8362    0.1638\n  DeadCause                          0.0000              0.0000    1.0000\n  Dead                               0.0000              0.0000    0.0000\n                      to\nfrom                     Dead\n  Asymptomatic_disease 0.0138\n  Progressive_disease  0.0000\n  DeadCause            0.0000\n  Dead                 1.0000\n\n[[2]]\n                      to\nfrom                   Asymptomatic_disease Progressive_disease DeadCause\n  Asymptomatic_disease               0.9812              0.0050    0.0000\n  Progressive_disease                0.0000              0.8362    0.1638\n  DeadCause                          0.0000              0.0000    1.0000\n  Dead                               0.0000              0.0000    0.0000\n                      to\nfrom                     Dead\n  Asymptomatic_disease 0.0138\n  Progressive_disease  0.0000\n  DeadCause            0.0000\n  Dead                 1.0000"
  },
  {
    "objectID": "blog/posts/green-et-al-replication/green-et-al-replication.html#payoffs",
    "href": "blog/posts/green-et-al-replication/green-et-al-replication.html#payoffs",
    "title": "Replication of Didactic Model",
    "section": "",
    "text": "u_payoff &lt;- with(params,{\n    array(c(\"Asymptomatic_disease\" = uAsymp, \"Progressive_disease\" = uProg, \"DeadCause\" = 0, \"Dead\" = 0, \n            \"Asymptomatic_disease\" = uAsymp, \"Progressive_disease\" = uProg,  \"DeadCause\" = 0, \"Dead\" = 0 ),\n          dim = c(1, n_states, n_treatments),\n          dimnames = list(from = \"cost\",\n                          to = c(s_names),\n                          t_names))\n})\n\nc_payoff &lt;- with(params,{\n    array(c(\"Asymptomatic_disease\" = cAsymp, \"Progressive_disease\" = cProg, \"DeadCause\" = 0 , \"Dead\" = 0, \n            \"Asymptomatic_disease\" = cAsymp+cDrug, \"Progressive_disease\" = cProg, \"DeadCause\" = 0 , \"Dead\" = 0 ),\n          dim = c(1, n_states, n_treatments),\n          dimnames = list(from = \"cost\",\n                          to = c(s_names),\n                          t_names))\n})\n\nc_transition_payoff &lt;- with(params,{\n    array(c(\"Asymptomatic_disease\" = 0, \"Progressive_disease\" = 0, \"DeadCause\" = cDeath , \"Dead\" = 0, \n            \"Asymptomatic_disease\" = 0, \"Progressive_disease\" = 0, \"DeadCause\" = cDeath , \"Dead\" = 0 ),\n          dim = c(1, n_states, n_treatments),\n          dimnames = list(from = \"cost\",\n                          to = c(s_names),\n                          t_names))\n})\n\n\nsim_cohort &lt;- function(params) {\n    \n    m_P &lt;- m_Pt(1:(params$n_cycles-1))\n    \n    tr &lt;- \n        m_P %&gt;% transpose() %&gt;% \n        map(~({\n            tr_ &lt;- t(c(\"Asymptomatic_disease\" = 1000, \"Progressive_disease\" = 0, \"DeadCause\" = 0, \"Dead\" = 0))\n            do.call(rbind,lapply(.x, function(tp) {\n                tr_ &lt;&lt;- tr_ %*% tp\n            }))\n        }))\n    tr &lt;- \n        tr %&gt;% \n        map(~({\n            .x &lt;- rbind(t(c(1000,0,0,0)),.x)\n        }))\n    \n    return(tr)\n}\n\nmarkov_trace &lt;- \n    markov_trace &lt;- sim_cohort(params)\n\nstate_costs_without &lt;- markov_trace[[1]] %*% c_payoff[,,1]\ntransition_costs_without &lt;- matrix(c(0,diff(markov_trace[[1]][,\"DeadCause\"]))) * params$cDeath\ncosts_without &lt;- state_costs_without + transition_costs_without\nqalys_without &lt;- markov_trace[[1]] %*% u_payoff[,,1]\n\nstate_costs_with &lt;- markov_trace[[2]] %*% c_payoff[,,2]\ntransition_costs_with &lt;- matrix(c(0,diff(markov_trace[[2]][,\"DeadCause\"]))) * params$cDeath\ncosts_with &lt;- state_costs_with + transition_costs_with\nqalys_with &lt;- markov_trace[[2]] %*% u_payoff[,,2]\n\ncycle_adj &lt;- alt_simp_coef(params$n_cycles)\ndiscounting &lt;- 1/(1+params$oDr)^(0:(params$n_cycles-1))\n\ntot_costs_without &lt;- sum(as.vector(costs_without[-1]) * discounting[-1])\ntot_costs_with &lt;- sum(as.vector(costs_with[-1])  * discounting[-1])\n\ntot_qalys_without &lt;- sum(as.vector(qalys_without) *  discounting)\ntot_qalys_with &lt;- sum(as.vector(qalys_with) *  discounting)\n\n#inc_cost &lt;- (tot_costs_with - tot_costs_without) \ninc_qaly &lt;- (tot_qalys_with - tot_qalys_without); inc_qaly\n\n[1] 2243.8\n\ninc_cost &lt;- (tot_costs_with - tot_costs_without); inc_cost\n\n[1] 11380568\n\nicer = inc_cost / inc_qaly ; icer\n\n[1] 5071.9"
  },
  {
    "objectID": "blog/posts/green-et-al-replication/green-et-al-replication.html#footnotes",
    "href": "blog/posts/green-et-al-replication/green-et-al-replication.html#footnotes",
    "title": "Replication of Didactic Model",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere is the footnote.↩︎\nHere’s one with multiple blocks.\nSubsequent paragraphs are indented to show that they belong to the previous footnote.\n{ some.code }\nThe whole paragraph can be indented, or just the first line. In this way, multi-paragraph footnotes work like multi-paragraph list items.↩︎"
  }
]